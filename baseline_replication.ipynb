{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOREbgFgZiknOab8M8yeZCS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "59a6aa0154074fba8eaa223ae334a857": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0e93bc0da3e47d5909ee27c2f30505d",
              "IPY_MODEL_16ad6b8178554a4ab7dd7aaaf97799f0",
              "IPY_MODEL_76ed8d04db9b4039b55b4c0efb2da419"
            ],
            "layout": "IPY_MODEL_d38aa751fefc4c68913bb7fc32bb4c42"
          }
        },
        "c0e93bc0da3e47d5909ee27c2f30505d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56e704b9bf4440628c5daf2f36fe5ac3",
            "placeholder": "​",
            "style": "IPY_MODEL_67e01c8a850846da8eac2d0d34ad12d6",
            "value": "100%"
          }
        },
        "16ad6b8178554a4ab7dd7aaaf97799f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0dc820ffde0e467e92068b3c278ce33e",
            "max": 114,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_26bad87aaa9248a2a3ec7066626b262a",
            "value": 114
          }
        },
        "76ed8d04db9b4039b55b4c0efb2da419": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02c5a0c6465b41c99e96d89dc7aa2b95",
            "placeholder": "​",
            "style": "IPY_MODEL_4d723aef81d34be4a98d85b3b112942b",
            "value": " 114/114 [00:00&lt;00:00, 283.02it/s]"
          }
        },
        "d38aa751fefc4c68913bb7fc32bb4c42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56e704b9bf4440628c5daf2f36fe5ac3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67e01c8a850846da8eac2d0d34ad12d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0dc820ffde0e467e92068b3c278ce33e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26bad87aaa9248a2a3ec7066626b262a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02c5a0c6465b41c99e96d89dc7aa2b95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d723aef81d34be4a98d85b3b112942b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a38ecf4614048c68b1102fb3f7b87a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8b0f05ba2cc442e9ef0816a43938218",
              "IPY_MODEL_7f592e7f16e045c894d4867a1460af5d",
              "IPY_MODEL_f9999eaa4571419d83af11480ba03462"
            ],
            "layout": "IPY_MODEL_992574e032514d43b3d662d1ade38217"
          }
        },
        "a8b0f05ba2cc442e9ef0816a43938218": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1453550fc384d048189b3e9e05868a3",
            "placeholder": "​",
            "style": "IPY_MODEL_cff82e6f04534990afb25c2c53f1f285",
            "value": "100%"
          }
        },
        "7f592e7f16e045c894d4867a1460af5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65556c90e11346739f1946885dca1865",
            "max": 114,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9691c61c0f942fa89eb2a022694aa48",
            "value": 114
          }
        },
        "f9999eaa4571419d83af11480ba03462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3d7531b353349deae20ce864c8a3b99",
            "placeholder": "​",
            "style": "IPY_MODEL_1949b10a15924d789acddeda2e675f2b",
            "value": " 114/114 [00:00&lt;00:00, 337.60it/s]"
          }
        },
        "992574e032514d43b3d662d1ade38217": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1453550fc384d048189b3e9e05868a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cff82e6f04534990afb25c2c53f1f285": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65556c90e11346739f1946885dca1865": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9691c61c0f942fa89eb2a022694aa48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3d7531b353349deae20ce864c8a3b99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1949b10a15924d789acddeda2e675f2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18044c2439014ab3be5b45e39708cf83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b7776b604d94931a00052a2bb12e4ed",
              "IPY_MODEL_04c1f4469be5460c8e1b9b652072f833",
              "IPY_MODEL_d49238fd707a43a6bdee2d5138010e0f"
            ],
            "layout": "IPY_MODEL_1234ade2e17140cc81c884372802c96e"
          }
        },
        "1b7776b604d94931a00052a2bb12e4ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74b5e1a29bb9447084bd4564ca1619fe",
            "placeholder": "​",
            "style": "IPY_MODEL_6269a3d37be94aab95c96d96dbbb5012",
            "value": "100%"
          }
        },
        "04c1f4469be5460c8e1b9b652072f833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98e161e244854c668f407cc8ed7259d1",
            "max": 169,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd778d621a0b45c48f6d9972bec56fa6",
            "value": 169
          }
        },
        "d49238fd707a43a6bdee2d5138010e0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ce0c486df2a44279996d8a77d60c0bf",
            "placeholder": "​",
            "style": "IPY_MODEL_a431861e10594643b38adafa0b0c86eb",
            "value": " 169/169 [01:35&lt;00:00,  1.66it/s]"
          }
        },
        "1234ade2e17140cc81c884372802c96e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74b5e1a29bb9447084bd4564ca1619fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6269a3d37be94aab95c96d96dbbb5012": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98e161e244854c668f407cc8ed7259d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd778d621a0b45c48f6d9972bec56fa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ce0c486df2a44279996d8a77d60c0bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a431861e10594643b38adafa0b0c86eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1d2b6104af041efaa985fc874b70441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f5053b6450394036b71e10ee5a12448b",
              "IPY_MODEL_5b34bd8734574566b92f77a3e3372dd2",
              "IPY_MODEL_973be57269914856a1a9404748cb09b1"
            ],
            "layout": "IPY_MODEL_e5af0c9c38334e24bb9316356565eb67"
          }
        },
        "f5053b6450394036b71e10ee5a12448b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cacb71dc6ce443d28ef664a46bea291e",
            "placeholder": "​",
            "style": "IPY_MODEL_e0daa4f236de4aa4b044be80b7385a56",
            "value": " 50%"
          }
        },
        "5b34bd8734574566b92f77a3e3372dd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b88ee866030445ca5ed00ecba9bf6a9",
            "max": 169,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_07781d19e6a84d8b8c2a21a77f31fe71",
            "value": 85
          }
        },
        "973be57269914856a1a9404748cb09b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2deaa285010e4c608b922d3b1f7383bd",
            "placeholder": "​",
            "style": "IPY_MODEL_0d2104cc44ed4058a83d7ad7787460ec",
            "value": " 85/169 [00:40&lt;00:45,  1.86it/s]"
          }
        },
        "e5af0c9c38334e24bb9316356565eb67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cacb71dc6ce443d28ef664a46bea291e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0daa4f236de4aa4b044be80b7385a56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b88ee866030445ca5ed00ecba9bf6a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07781d19e6a84d8b8c2a21a77f31fe71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2deaa285010e4c608b922d3b1f7383bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d2104cc44ed4058a83d7ad7787460ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "444ac9c047d348a7a743e719d34d5357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69bacb88b3854f6e97ab039a3325b641",
              "IPY_MODEL_23355b514bb5445ea7cc98db021cd983",
              "IPY_MODEL_e8820441c56940cea37d2576066351e1"
            ],
            "layout": "IPY_MODEL_8b4fea35e89243b4b3ce74e16375bb74"
          }
        },
        "69bacb88b3854f6e97ab039a3325b641": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7114c0e18b35411b9996742fa0507283",
            "placeholder": "​",
            "style": "IPY_MODEL_a8cb1ce9b0ee4960a6a8df991c6e7a03",
            "value": "100%"
          }
        },
        "23355b514bb5445ea7cc98db021cd983": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efc451e52ea54afda02d3a43a454afe6",
            "max": 114,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_46e0c7ae81164d808276f1c012bf9b72",
            "value": 114
          }
        },
        "e8820441c56940cea37d2576066351e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_969a402499fa445ba4ee86e1b77beab5",
            "placeholder": "​",
            "style": "IPY_MODEL_1957c7190f824f6b99b6ecd06678335c",
            "value": " 114/114 [04:24&lt;00:00,  2.18s/it]"
          }
        },
        "8b4fea35e89243b4b3ce74e16375bb74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7114c0e18b35411b9996742fa0507283": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8cb1ce9b0ee4960a6a8df991c6e7a03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efc451e52ea54afda02d3a43a454afe6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46e0c7ae81164d808276f1c012bf9b72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "969a402499fa445ba4ee86e1b77beab5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1957c7190f824f6b99b6ecd06678335c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9166a6768d6646659927f127514db35f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5d19865740540edb94a1f0aa2565161",
              "IPY_MODEL_803cf4f39e02434a9c47fb9b3dc88e94",
              "IPY_MODEL_3f5c0ecc39854b1a9e59b9819a1a004f"
            ],
            "layout": "IPY_MODEL_dfcb3c129bb4474795b5ff39854676d2"
          }
        },
        "b5d19865740540edb94a1f0aa2565161": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ec9a908a012446ab8b152bba9ccb7ce",
            "placeholder": "​",
            "style": "IPY_MODEL_a1d540f250754fb2b68a7a583ddc5ac9",
            "value": "100%"
          }
        },
        "803cf4f39e02434a9c47fb9b3dc88e94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88966dffcdb746dd9f9e60a6d547b9f9",
            "max": 114,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_408fcd226c45469a944cb52b3ef73b70",
            "value": 114
          }
        },
        "3f5c0ecc39854b1a9e59b9819a1a004f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d87ba61bdd146f2b8ef8f63e6a09101",
            "placeholder": "​",
            "style": "IPY_MODEL_19b039bc15ed4981be05c2663d4a6afb",
            "value": " 114/114 [04:43&lt;00:00,  2.24s/it]"
          }
        },
        "dfcb3c129bb4474795b5ff39854676d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ec9a908a012446ab8b152bba9ccb7ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1d540f250754fb2b68a7a583ddc5ac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88966dffcdb746dd9f9e60a6d547b9f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "408fcd226c45469a944cb52b3ef73b70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d87ba61bdd146f2b8ef8f63e6a09101": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19b039bc15ed4981be05c2663d4a6afb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tabaraei/depression-detection/blob/master/baseline_replication.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- They merge all the existing data, and perform a Kfold (k=3) to distribute train/test sets.\n",
        "- This code is designed to augment or resample data points based on certain conditions (whether an index is in audio_dep_idxs_tmp) by generating permutations of features and adding them to audio_features and corresponding labels (audio_targets). The augmented data points are then tracked using train_idxs. This approach likely aims to increase the diversity of training data by creating variations of existing data points."
      ],
      "metadata": {
        "id": "t58p0xF3dolt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "\n",
        "DATASET_DIR = '/content/drive/MyDrive/Data/DepressionDetection/EATD-Corpus'\n",
        "BASELINE_DIR = '/content/drive/MyDrive/Data/DepressionDetection/Baseline'\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LecNXSaQ3Erq",
        "outputId": "84cdfea4-8e7e-4018-c221-4bda6d036a12"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Audio"
      ],
      "metadata": {
        "id": "nIROExnrl8Ws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `NetVLAD`\n",
        "Used to enforce same-length audio features extracted as clusters"
      ],
      "metadata": {
        "id": "MJjTgX832YRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import tensorflow as tf\n",
        "# import tensorflow.contrib.slim as slim\n",
        "import numpy as np\n",
        "from keras import initializers, layers\n",
        "import keras.backend as K\n",
        "import sys"
      ],
      "metadata": {
        "id": "2OJgYzeH20vK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NetVLAD(layers.Layer):\n",
        "    \"\"\"Creates a NetVLAD class.\n",
        "    \"\"\"\n",
        "    def __init__(self, feature_size, max_samples, cluster_size, output_dim, **kwargs):\n",
        "\n",
        "        self.feature_size = feature_size\n",
        "        self.max_samples = max_samples\n",
        "        self.output_dim = output_dim\n",
        "        self.cluster_size = cluster_size\n",
        "        super(NetVLAD, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "    # Create a trainable weight variable for this layer.\n",
        "        self.cluster_weights = self.add_weight(name='kernel_W1',\n",
        "                                      shape=(self.feature_size, self.cluster_size),\n",
        "                                      initializer=tf.random_normal_initializer(stddev=1 / math.sqrt(self.feature_size)),\n",
        "                                      trainable=True)\n",
        "        self.cluster_biases = self.add_weight(name='kernel_B1',\n",
        "                                      shape=(self.cluster_size,),\n",
        "                                      initializer=tf.random_normal_initializer(stddev=1 / math.sqrt(self.feature_size)),\n",
        "                                      trainable=True)\n",
        "        self.cluster_weights2 = self.add_weight(name='kernel_W2',\n",
        "                                      shape=(1,self.feature_size, self.cluster_size),\n",
        "                                      initializer=tf.random_normal_initializer(stddev=1 / math.sqrt(self.feature_size)),\n",
        "                                      trainable=True)\n",
        "        self.hidden1_weights = self.add_weight(name='kernel_H1',\n",
        "                                      shape=(self.cluster_size*self.feature_size, self.output_dim),\n",
        "                                      initializer=tf.random_normal_initializer(stddev=1 / math.sqrt(self.cluster_size)),\n",
        "                                      trainable=True)\n",
        "\n",
        "        super(NetVLAD, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, reshaped_input):\n",
        "        \"\"\"Forward pass of a NetVLAD block.\n",
        "\n",
        "        Args:\n",
        "        reshaped_input: If your input is in that form:\n",
        "        'batch_size' x 'max_samples' x 'feature_size'\n",
        "        It should be reshaped in the following form:\n",
        "        'batch_size*max_samples' x 'feature_size'\n",
        "        by performing:\n",
        "        reshaped_input = tf.reshape(input, [-1, features_size])\n",
        "\n",
        "        Returns:\n",
        "        vlad: the pooled vector of size: 'batch_size' x 'output_dim'\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        In Keras, there are two way to do matrix multiplication (dot product)\n",
        "        1) K.dot : AxB -> when A has batchsize and B doesn't, use K.dot\n",
        "        2) tf.matmul: AxB -> when A and B both have batchsize, use tf.matmul\n",
        "\n",
        "        Error example: Use tf.matmul when A has batchsize (3 dim) and B doesn't (2 dim)\n",
        "        ValueError: Shape must be rank 2 but is rank 3 for 'net_vlad_1/MatMul' (op: 'MatMul') with input shapes: [?,21,64], [64,3]\n",
        "\n",
        "        tf.matmul might still work when the dim of A is (?,64), but this is too confusing.\n",
        "        Just follow the above rules.\n",
        "        \"\"\"\n",
        "        activation = K.dot(reshaped_input, self.cluster_weights)\n",
        "\n",
        "        activation += self.cluster_biases\n",
        "\n",
        "        activation = tf.nn.softmax(activation)\n",
        "\n",
        "        activation = tf.reshape(activation,\n",
        "                [-1, self.max_samples, self.cluster_size])\n",
        "\n",
        "        a_sum = tf.reduce_sum(activation,-2,keep_dims=True)\n",
        "\n",
        "        a = tf.multiply(a_sum,self.cluster_weights2)\n",
        "\n",
        "        activation = tf.transpose(activation,perm=[0,2,1])\n",
        "\n",
        "        reshaped_input = tf.reshape(reshaped_input,[-1,\n",
        "            self.max_samples, self.feature_size])\n",
        "\n",
        "        vlad = tf.matmul(activation,reshaped_input)\n",
        "        vlad = tf.transpose(vlad,perm=[0,2,1])\n",
        "        vlad = tf.subtract(vlad,a)\n",
        "        vlad = tf.nn.l2_normalize(vlad,1)\n",
        "        vlad = tf.reshape(vlad,[-1, self.cluster_size*self.feature_size])\n",
        "        vlad = tf.nn.l2_normalize(vlad,1)\n",
        "        vlad = K.dot(vlad, self.hidden1_weights)\n",
        "\n",
        "        return vlad\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return tuple([None, self.output_dim])"
      ],
      "metadata": {
        "id": "ewYLYHXw2ljN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `audio_features_whole.py`\n",
        "Extracts the audio features and stores them"
      ],
      "metadata": {
        "id": "5ITC9B9Sx1nZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import wave\n",
        "import librosa\n",
        "# from python_speech_features import *\n",
        "import sys\n",
        "import pickle\n",
        "import tensorflow.compat.v1 as tf\n",
        "# import vggish.vggish_input as vggish_input\n",
        "# import vggish.vggish_params as vggish_params\n",
        "# import vggish.vggish_postprocess as vggish_postprocess\n",
        "# import vggish.vggish_slim as vggish_slim\n",
        "# import loupe_keras as lpk\n",
        "# from allennlp.commands.elmo import ElmoEmbedder\n",
        "from tqdm.notebook import trange, tqdm"
      ],
      "metadata": {
        "id": "XKhG1D4myDLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sys.path.append('/Users/linlin/Desktop/depression/classfication')\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "# elmo = ElmoEmbedder()\n",
        "\n",
        "# os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "\n",
        "# prefix = os.path.abspath(os.path.join(os.getcwd(), \".\"))\n",
        "\n",
        "# # Paths to downloaded VGGish files.\n",
        "# checkpoint_path =os.path.join(os.getcwd(),  'vggish/vggish_model.ckpt')\n",
        "# pca_params_path = os.path.join(os.getcwd(), 'vggish/vggish_pca_params.npz')\n",
        "\n",
        "cluster_size = 16\n",
        "min_len = 100\n",
        "max_len = -1"
      ],
      "metadata": {
        "id": "PhuQ6C29yATF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def to_vggish_embedds(x, sr):\n",
        "#     # x为输入的音频，sr为sample_rate\n",
        "#     input_batch = vggish_input.waveform_to_examples(x, sr)\n",
        "#     with tf.Graph().as_default(), tf.Session() as sess:\n",
        "#       vggish_slim.define_vggish_slim()\n",
        "#       vggish_slim.load_vggish_slim_checkpoint(sess, checkpoint_path)\n",
        "\n",
        "#       features_tensor = sess.graph.get_tensor_by_name(vggish_params.INPUT_TENSOR_NAME)\n",
        "#       embedding_tensor = sess.graph.get_tensor_by_name(vggish_params.OUTPUT_TENSOR_NAME)\n",
        "#       [embedding_batch] = sess.run([embedding_tensor],\n",
        "#                                    feed_dict={features_tensor: input_batch})\n",
        "\n",
        "#     # Postprocess the results to produce whitened quantized embeddings.\n",
        "#     pproc = vggish_postprocess.Postprocessor(pca_params_path)\n",
        "#     postprocessed_batch = pproc.postprocess(embedding_batch)\n",
        "\n",
        "#     return tf.cast(postprocessed_batch, dtype='float32')"
      ],
      "metadata": {
        "id": "Jv8hHK__yFcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wav2vlad(wave_data, sr):\n",
        "    global cluster_size\n",
        "    signal = wave_data\n",
        "    melspec = librosa.feature.melspectrogram(y=signal, n_mels=80,sr=sr).astype(np.float32).T\n",
        "    melspec = np.log(np.maximum(1e-6, melspec))\n",
        "    feature_size = melspec.shape[1]\n",
        "    max_samples = melspec.shape[0]\n",
        "    output_dim = cluster_size * 16\n",
        "    feat = NetVLAD(feature_size=feature_size, max_samples=max_samples, \\\n",
        "                            cluster_size=cluster_size, output_dim=output_dim) \\\n",
        "                                (tf.convert_to_tensor(melspec))\n",
        "    with tf.Session() as sess:\n",
        "        init = tf.global_variables_initializer()\n",
        "        sess.run(init)\n",
        "        r = feat.numpy()\n",
        "    return r"
      ],
      "metadata": {
        "id": "5BimqtP7yI50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(audio_features, targets, folder):\n",
        "    global max_len, min_len\n",
        "    if not os.path.exists(f'{DATASET_DIR}/{folder}/positive_out.wav'):\n",
        "        return\n",
        "    positive_file = wave.open(f'{DATASET_DIR}/{folder}/positive_out.wav')\n",
        "    sr1 = positive_file.getframerate()\n",
        "    nframes1 = positive_file.getnframes()\n",
        "    wave_data1 = np.frombuffer(positive_file.readframes(nframes1), dtype=np.short).astype(float)\n",
        "    len1 = nframes1 / sr1\n",
        "\n",
        "    neutral_file = wave.open(f'{DATASET_DIR}/{folder}/neutral_out.wav')\n",
        "    sr2 = neutral_file.getframerate()\n",
        "    nframes2 = neutral_file.getnframes()\n",
        "    wave_data2 = np.frombuffer(neutral_file.readframes(nframes2), dtype=np.short).astype(float)\n",
        "    len2 = nframes2 / sr2\n",
        "\n",
        "    negative_file = wave.open(f'{DATASET_DIR}/{folder}/negative_out.wav')\n",
        "    sr3 = negative_file.getframerate()\n",
        "    nframes3 = negative_file.getnframes()\n",
        "    wave_data3 = np.frombuffer(negative_file.readframes(nframes3), dtype=np.short).astype(float)\n",
        "    len3 = nframes3/sr3\n",
        "\n",
        "    for l in [len1, len2, len3]:\n",
        "        if l > max_len:\n",
        "            max_len = l\n",
        "        if l < min_len:\n",
        "            min_len = l\n",
        "\n",
        "    with open(f'{DATASET_DIR}/{folder}/new_label.txt') as fli:\n",
        "        target = float(fli.readline())\n",
        "\n",
        "    if wave_data1.shape[0] < 1:\n",
        "        wave_data1 = np.array([1e-4]*sr1*5)\n",
        "    if wave_data2.shape[0] < 1:\n",
        "        wave_data2 = np.array([1e-4]*sr2*5)\n",
        "    if wave_data3.shape[0] < 1:\n",
        "        wave_data3 = np.array([1e-4]*sr3*5)\n",
        "    audio_features.append([wav2vlad(wave_data1, sr1), wav2vlad(wave_data2, sr2), \\\n",
        "        wav2vlad(wave_data3, sr3)])\n",
        "    targets.append(1 if target >= 53 else 0)\n",
        "    # targets.append(target)"
      ],
      "metadata": {
        "id": "Iq2MxbheyMtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_features = []\n",
        "audio_targets = []\n",
        "\n",
        "for index in trange(114):\n",
        "    extract_features(audio_features, audio_targets, f't_{index+1}')\n",
        "\n",
        "for index in trange(114):\n",
        "    extract_features(audio_features, audio_targets, f'v_{index+1}')"
      ],
      "metadata": {
        "id": "m5Zs9wf33IUS",
        "outputId": "924d8c0f-426b-484b-9cb0-81a32f948ae9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "59a6aa0154074fba8eaa223ae334a857",
            "c0e93bc0da3e47d5909ee27c2f30505d",
            "16ad6b8178554a4ab7dd7aaaf97799f0",
            "76ed8d04db9b4039b55b4c0efb2da419",
            "d38aa751fefc4c68913bb7fc32bb4c42",
            "56e704b9bf4440628c5daf2f36fe5ac3",
            "67e01c8a850846da8eac2d0d34ad12d6",
            "0dc820ffde0e467e92068b3c278ce33e",
            "26bad87aaa9248a2a3ec7066626b262a",
            "02c5a0c6465b41c99e96d89dc7aa2b95",
            "4d723aef81d34be4a98d85b3b112942b",
            "6a38ecf4614048c68b1102fb3f7b87a1",
            "a8b0f05ba2cc442e9ef0816a43938218",
            "7f592e7f16e045c894d4867a1460af5d",
            "f9999eaa4571419d83af11480ba03462",
            "992574e032514d43b3d662d1ade38217",
            "d1453550fc384d048189b3e9e05868a3",
            "cff82e6f04534990afb25c2c53f1f285",
            "65556c90e11346739f1946885dca1865",
            "a9691c61c0f942fa89eb2a022694aa48",
            "b3d7531b353349deae20ce864c8a3b99",
            "1949b10a15924d789acddeda2e675f2b"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/114 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59a6aa0154074fba8eaa223ae334a857"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/114 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a38ecf4614048c68b1102fb3f7b87a1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Saving npz file locally...\")\n",
        "np.savez(f'{BASELINE_DIR}/Features/AudioWhole/whole_samples_clf_{cluster_size*16}.npz', audio_features)\n",
        "np.savez(f'{BASELINE_DIR}/Features/AudioWhole/whole_labels_clf_{cluster_size*16}.npz', audio_targets)\n",
        "\n",
        "print(max_len, min_len)"
      ],
      "metadata": {
        "id": "_ltZj3Og70vU",
        "outputId": "1ebaa825-0ce1-4b00-e931-0d75f7f2c513",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving npz file locally...\n",
            "111.02 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(audio_features), np.array(audio_features[0]).shape"
      ],
      "metadata": {
        "id": "mTIwtawa-nnL",
        "outputId": "9b4348da-746b-4294-89c2-45e5a4838d64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(162, (3, 1, 256))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `audio_gru_whole.py`\n",
        "The main learning algorithm and network architecture of BiLSTM for audio"
      ],
      "metadata": {
        "id": "4FCt050ZBfg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import itertools\n",
        "from tqdm.notebook import trange, tqdm"
      ],
      "metadata": {
        "id": "h1M_irA2DySP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_features = np.squeeze(np.load(f'{BASELINE_DIR}/Features/AudioWhole/whole_samples_clf_256.npz')['arr_0'], axis=2)\n",
        "audio_targets = np.load(f'{BASELINE_DIR}/Features/AudioWhole/whole_labels_clf_256.npz')['arr_0']\n",
        "audio_dep_idxs_tmp = np.where(audio_targets == 1)[0]\n",
        "audio_non_idxs = np.where(audio_targets == 0)[0]\n",
        "audio_features.shape, audio_targets.shape"
      ],
      "metadata": {
        "id": "w3Jx_J5JD0qh",
        "outputId": "01d21d18-3afb-41de-88b3-23dd9cf617de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((162, 3, 256), (162,))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AudioBiLSTM(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(AudioBiLSTM, self).__init__()\n",
        "        self.num_classes = config['num_classes']\n",
        "        self.learning_rate = config['learning_rate']\n",
        "        self.dropout = config['dropout']\n",
        "        self.hidden_dims = config['hidden_dims']\n",
        "        self.rnn_layers = config['rnn_layers']\n",
        "        self.embedding_size = config['embedding_size']\n",
        "        self.bidirectional = config['bidirectional']\n",
        "\n",
        "        self.build_model()\n",
        "        # self.init_weight()\n",
        "\n",
        "    def init_weight(net):\n",
        "        for name, param in net.named_parameters():\n",
        "            if not 'ln' in name:\n",
        "                if 'bias' in name:\n",
        "                    nn.init.constant_(param, 0.0)\n",
        "                elif 'weight' in name:\n",
        "                    nn.init.xavier_uniform_(param)\n",
        "\n",
        "    def build_model(self):\n",
        "        # attention layer\n",
        "        self.attention_layer = nn.Sequential(\n",
        "            nn.Linear(self.hidden_dims, self.hidden_dims),\n",
        "            nn.ReLU(inplace=True))\n",
        "        # self.attention_weights = self.attention_weights.view(self.hidden_dims, 1)\n",
        "\n",
        "        # self.lstm_net_audio = nn.LSTM(self.embedding_size,\n",
        "        #                         self.hidden_dims,\n",
        "        #                         num_layers=self.rnn_layers,\n",
        "        #                         dropout=self.dropout,\n",
        "        #                         bidirectional=self.bidirectional,\n",
        "        #                         batch_first=True)\n",
        "        self.lstm_net_audio = nn.GRU(self.embedding_size, self.hidden_dims,\n",
        "                                num_layers=self.rnn_layers, dropout=self.dropout, batch_first=True)\n",
        "\n",
        "        self.ln = nn.LayerNorm(self.embedding_size)\n",
        "\n",
        "        # FC层\n",
        "        self.fc_audio = nn.Sequential(\n",
        "            nn.Dropout(self.dropout),\n",
        "            nn.Linear(self.hidden_dims, self.hidden_dims),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(self.dropout),\n",
        "            nn.Linear(self.hidden_dims, self.num_classes),\n",
        "            # nn.ReLU(),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def attention_net_with_w(self, lstm_out, lstm_hidden):\n",
        "        '''\n",
        "        :param lstm_out:    [batch_size, len_seq, n_hidden * 2]\n",
        "        :param lstm_hidden: [batch_size, num_layers * num_directions, n_hidden]\n",
        "        :return: [batch_size, n_hidden]\n",
        "        '''\n",
        "        lstm_tmp_out = torch.chunk(lstm_out, 2, -1)\n",
        "        # h [batch_size, time_step, hidden_dims]\n",
        "        h = lstm_tmp_out[0] + lstm_tmp_out[1]\n",
        "        #         h = lstm_out\n",
        "        # [batch_size, num_layers * num_directions, n_hidden]\n",
        "        lstm_hidden = torch.sum(lstm_hidden, dim=1)\n",
        "        # [batch_size, 1, n_hidden]\n",
        "        lstm_hidden = lstm_hidden.unsqueeze(1)\n",
        "        # atten_w [batch_size, 1, hidden_dims]\n",
        "        atten_w = self.attention_layer(lstm_hidden)\n",
        "        # m [batch_size, time_step, hidden_dims]\n",
        "        m = nn.Tanh()(h)\n",
        "        # atten_context [batch_size, 1, time_step]\n",
        "       # print(atten_w.shape, m.transpose(1, 2).shape)\n",
        "        atten_context = torch.bmm(atten_w, m.transpose(1, 2))\n",
        "        # softmax_w [batch_size, 1, time_step]\n",
        "        softmax_w = F.softmax(atten_context, dim=-1)\n",
        "        # context [batch_size, 1, hidden_dims]\n",
        "        context = torch.bmm(softmax_w, h)\n",
        "        result = context.squeeze(1)\n",
        "        return result\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln(x)\n",
        "        x, _ = self.lstm_net_audio(x)\n",
        "        x = x.mean(dim=1)\n",
        "        out = self.fc_audio(x)\n",
        "        return out"
      ],
      "metadata": {
        "id": "q0FdDXtDD7oG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'num_classes': 2,\n",
        "    'dropout': 0.5,\n",
        "    'rnn_layers': 2,\n",
        "    'embedding_size': 256,\n",
        "    'batch_size': 8,\n",
        "    'epochs': 170,\n",
        "    'learning_rate': 6e-6,\n",
        "    'hidden_dims': 256,\n",
        "    'bidirectional': False,\n",
        "    'cuda': False\n",
        "}"
      ],
      "metadata": {
        "id": "65RKaAA0HHgM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save(model, filename):\n",
        "    save_filename = '{}.pt'.format(filename)\n",
        "    torch.save(model, save_filename)\n",
        "    print('Saved as %s' % save_filename)\n",
        "\n",
        "def standard_confusion_matrix(y_test, y_test_pred):\n",
        "    \"\"\"\n",
        "    Make confusion matrix with format:\n",
        "                  -----------\n",
        "                  | TP | FP |\n",
        "                  -----------\n",
        "                  | FN | TN |\n",
        "                  -----------\n",
        "    Parameters\n",
        "    ----------\n",
        "    y_true : ndarray - 1D\n",
        "    y_pred : ndarray - 1D\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    ndarray - 2D\n",
        "    \"\"\"\n",
        "    [[tn, fp], [fn, tp]] = confusion_matrix(y_test.cpu().numpy(), y_test_pred)\n",
        "    return np.array([[tp, fp], [fn, tn]])\n",
        "\n",
        "def model_performance(y_test, y_test_pred_proba):\n",
        "    \"\"\"\n",
        "    Evaluation metrics for network performance.\n",
        "    \"\"\"\n",
        "    y_test_pred = y_test_pred_proba.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    # Computing confusion matrix for test dataset\n",
        "    conf_matrix = standard_confusion_matrix(y_test, y_test_pred.numpy())\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "    return y_test_pred, conf_matrix\n",
        "\n",
        "def train(epoch, train_idxs):\n",
        "    global lr, train_acc\n",
        "    model.train()\n",
        "    batch_idx = 1\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    pred = np.array([])\n",
        "    X_train = audio_features[train_idxs]\n",
        "    Y_train = audio_targets[train_idxs]\n",
        "    for i in range(0, X_train.shape[0], config['batch_size']):\n",
        "        if i + config['batch_size'] > X_train.shape[0]:\n",
        "            x, y = X_train[i:], Y_train[i:]\n",
        "        else:\n",
        "            x, y = X_train[i:(i + config['batch_size'])], Y_train[i:(\n",
        "                i + config['batch_size'])]\n",
        "        if config['cuda']:\n",
        "            x, y = Variable(torch.from_numpy(x).type(torch.FloatTensor), requires_grad=True).cuda(), Variable(torch.from_numpy(y)).cuda()\n",
        "        else:\n",
        "            x, y = Variable(torch.from_numpy(x).type(torch.FloatTensor), requires_grad=True), \\\n",
        "                Variable(torch.from_numpy(y))\n",
        "\n",
        "        # 将模型的参数梯度设置为0\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x)\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        #print(pred.shape, y.shape)\n",
        "        correct += pred.eq(y.data.view_as(pred)).cpu().sum()\n",
        "        loss = criterion(output, y)\n",
        "        # 后向传播调整参数\n",
        "        loss.backward()\n",
        "        # 根据梯度更新网络参数\n",
        "        optimizer.step()\n",
        "        batch_idx += 1\n",
        "        # loss.item()能够得到张量中的元素值\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    train_acc = correct\n",
        "    print(\n",
        "        'Train Epoch: {:2d}\\t Learning rate: {:.4f}\\tLoss: {:.6f}\\t Accuracy: {}/{} ({:.0f}%)\\n '\n",
        "        .format(epoch + 1, config['learning_rate'], total_loss, correct,\n",
        "                X_train.shape[0], 100. * correct / X_train.shape[0]))\n",
        "\n",
        "\n",
        "def evaluate(model, test_idxs, fold, train_idxs_tmp, train_idxs):\n",
        "    model.eval()\n",
        "    batch_idx = 1\n",
        "    total_loss = 0\n",
        "    global max_f1, max_acc, min_mae, X_test_lens, max_prec, max_rec\n",
        "    pred = np.array([])\n",
        "    with torch.no_grad():\n",
        "        if config['cuda']:\n",
        "            x, y = Variable(torch.from_numpy(audio_features[test_idxs]).type(torch.FloatTensor), requires_grad=True).cuda(),\\\n",
        "                Variable(torch.from_numpy(audio_targets[test_idxs])).cuda()\n",
        "        else:\n",
        "            x, y = Variable(torch.from_numpy(audio_features[test_idxs]).type(torch.FloatTensor), requires_grad=True), \\\n",
        "                Variable(torch.from_numpy(audio_targets[test_idxs])).type(torch.LongTensor)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x)\n",
        "        loss = criterion(output, y)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        y_test_pred, conf_matrix = model_performance(y, output.cpu())\n",
        "        accuracy = float(conf_matrix[0][0] + conf_matrix[1][1]) / np.sum(conf_matrix)\n",
        "        precision = float(conf_matrix[0][0]) / (conf_matrix[0][0] + conf_matrix[0][1])\n",
        "        recall = float(conf_matrix[0][0]) / (conf_matrix[0][0] + conf_matrix[1][0])\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "        print(\"Accuracy: {}\".format(accuracy))\n",
        "        print(\"Precision: {}\".format(precision))\n",
        "        print(\"Recall: {}\".format(recall))\n",
        "        print(\"F1-Score: {}\\n\".format(f1_score))\n",
        "        print('=' * 89)\n",
        "\n",
        "        if max_f1 <= f1_score and train_acc > len(train_idxs)*0.90  and f1_score > 0.5:\n",
        "            max_f1 = f1_score\n",
        "            max_acc = accuracy\n",
        "            max_rec = recall\n",
        "            max_prec = precision\n",
        "            mode ='gru'\n",
        "            save(model, f\"{BASELINE_DIR}/Model/ClassificationWhole/Audio/BiLSTM_{mode}_vlad{config['embedding_size']}_{config['hidden_dims']}_{max_f1:.2f}_{fold}\")\n",
        "            np.save(f'{BASELINE_DIR}/Features/TextWhole/train_idxs_{f1_score:.2f}_{fold}.npy', train_idxs_tmp)\n",
        "            print('*' * 64)\n",
        "            print('model saved: f1: {}\\tacc: {}'.format(max_f1, max_acc))\n",
        "            print('*' * 64)\n",
        "\n",
        "    return total_loss\n",
        "\n",
        "def get_param_group(model):\n",
        "    nd_list = []\n",
        "    param_list = []\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'ln' in name:\n",
        "            nd_list.append(param)\n",
        "        else:\n",
        "            param_list.append(param)\n",
        "    return [{'params': param_list, 'weight_decay': 1e-5}, {'params': nd_list, 'weight_decay': 0}]"
      ],
      "metadata": {
        "id": "f8ezUxy-Bhrd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits=3, shuffle=True)\n",
        "fold = 1\n",
        "for train_idxs_tmp, test_idxs_tmp in kf.split(audio_features):\n",
        "# train_idxs_tmps = [\n",
        "#     np.load(f'{BASELINE_DIR}/Features/TextWhole/train_idxs_0.63_1.npy', allow_pickle=True),\n",
        "#     np.load(f'{BASELINE_DIR}/Features/TextWhole/train_idxs_0.60_2.npy', allow_pickle=True),\n",
        "#     np.load(f'{BASELINE_DIR}/Features/TextWhole/train_idxs_0.60_3.npy', allow_pickle=True)\n",
        "# ]\n",
        "# for idx_idx, train_idxs_tmp in enumerate(train_idxs_tmps):\n",
        "#     fold = idx_idx + 1\n",
        "#     # if idx_idx != 1:\n",
        "#     #     continue\n",
        "#     test_idxs_tmp = list(set(list(audio_dep_idxs_tmp)+list(audio_non_idxs)) - set(train_idxs_tmp))\n",
        "    train_idxs, test_idxs = [], []\n",
        "    resample_idxs = [0,1,2,3,4,5]\n",
        "    # depression data augmentation\n",
        "    for idx in train_idxs_tmp:\n",
        "        if idx in audio_dep_idxs_tmp:\n",
        "            feat = audio_features[idx]\n",
        "            count = 0\n",
        "            for i in itertools.permutations(feat, feat.shape[0]):\n",
        "                if count in resample_idxs:\n",
        "                    audio_features = np.vstack((audio_features, np.expand_dims(list(i), 0)))\n",
        "                    audio_targets = np.hstack((audio_targets, 1))\n",
        "                    train_idxs.append(len(audio_features)-1)\n",
        "                count += 1\n",
        "        else:\n",
        "            train_idxs.append(idx)\n",
        "\n",
        "    for idx in test_idxs_tmp:\n",
        "        if idx in audio_dep_idxs_tmp:\n",
        "            feat = audio_features[idx]\n",
        "            count = 0\n",
        "            # resample_idxs = random.sample(range(6), 4)\n",
        "            resample_idxs = [0,1,4,5]\n",
        "            for i in itertools.permutations(feat, feat.shape[0]):\n",
        "                if count in resample_idxs:\n",
        "                    audio_features = np.vstack((audio_features, np.expand_dims(list(i), 0)))\n",
        "                    audio_targets = np.hstack((audio_targets, 1))\n",
        "                    test_idxs.append(len(audio_features)-1)\n",
        "                count += 1\n",
        "        else:\n",
        "            test_idxs.append(idx)\n",
        "        # test_idxs.append(idx)\n",
        "\n",
        "    model = AudioBiLSTM(config)\n",
        "\n",
        "    if config['cuda']:\n",
        "        model = model.cuda()\n",
        "\n",
        "    param_group = get_param_group(model)\n",
        "    optimizer = optim.AdamW(param_group, lr=config['learning_rate'])\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    # criterion = FocalLoss(class_num=2)\n",
        "    max_f1 = -1\n",
        "    max_acc = -1\n",
        "    max_rec = -1\n",
        "    max_prec = -1\n",
        "    train_acc = -1\n",
        "\n",
        "    for ep in trange(1, config['epochs']):\n",
        "        train(ep, train_idxs)\n",
        "        tloss = evaluate(model, test_idxs, fold, train_idxs_tmp, train_idxs)\n",
        "    fold += 1"
      ],
      "metadata": {
        "id": "Vtbb_0C6HPfB",
        "outputId": "934ed12a-f86f-465d-ab2f-abf9bf95962a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "18044c2439014ab3be5b45e39708cf83",
            "1b7776b604d94931a00052a2bb12e4ed",
            "04c1f4469be5460c8e1b9b652072f833",
            "d49238fd707a43a6bdee2d5138010e0f",
            "1234ade2e17140cc81c884372802c96e",
            "74b5e1a29bb9447084bd4564ca1619fe",
            "6269a3d37be94aab95c96d96dbbb5012",
            "98e161e244854c668f407cc8ed7259d1",
            "dd778d621a0b45c48f6d9972bec56fa6",
            "5ce0c486df2a44279996d8a77d60c0bf",
            "a431861e10594643b38adafa0b0c86eb",
            "a1d2b6104af041efaa985fc874b70441",
            "f5053b6450394036b71e10ee5a12448b",
            "5b34bd8734574566b92f77a3e3372dd2",
            "973be57269914856a1a9404748cb09b1",
            "e5af0c9c38334e24bb9316356565eb67",
            "cacb71dc6ce443d28ef664a46bea291e",
            "e0daa4f236de4aa4b044be80b7385a56",
            "1b88ee866030445ca5ed00ecba9bf6a9",
            "07781d19e6a84d8b8c2a21a77f31fe71",
            "2deaa285010e4c608b922d3b1f7383bd",
            "0d2104cc44ed4058a83d7ad7787460ec"
          ]
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/169 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18044c2439014ab3be5b45e39708cf83"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  2\t Learning rate: 0.0000\tLoss: 18.679538\t Accuracy: 115/213 (54%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[28 37]\n",
            " [ 8  8]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4307692307692308\n",
            "Recall: 0.7777777777777778\n",
            "F1-Score: 0.5544554455445544\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  3\t Learning rate: 0.0000\tLoss: 18.641906\t Accuracy: 124/213 (58%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[28 37]\n",
            " [ 8  8]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4307692307692308\n",
            "Recall: 0.7777777777777778\n",
            "F1-Score: 0.5544554455445544\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  4\t Learning rate: 0.0000\tLoss: 18.631377\t Accuracy: 123/213 (58%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[29 38]\n",
            " [ 7  7]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.43283582089552236\n",
            "Recall: 0.8055555555555556\n",
            "F1-Score: 0.5631067961165048\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  5\t Learning rate: 0.0000\tLoss: 18.675354\t Accuracy: 106/213 (50%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[29 39]\n",
            " [ 7  6]]\n",
            "Accuracy: 0.43209876543209874\n",
            "Precision: 0.4264705882352941\n",
            "Recall: 0.8055555555555556\n",
            "F1-Score: 0.5576923076923077\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  6\t Learning rate: 0.0000\tLoss: 18.632745\t Accuracy: 119/213 (56%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[30 40]\n",
            " [ 6  5]]\n",
            "Accuracy: 0.43209876543209874\n",
            "Precision: 0.42857142857142855\n",
            "Recall: 0.8333333333333334\n",
            "F1-Score: 0.5660377358490566\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  7\t Learning rate: 0.0000\tLoss: 18.638671\t Accuracy: 120/213 (56%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[30 40]\n",
            " [ 6  5]]\n",
            "Accuracy: 0.43209876543209874\n",
            "Precision: 0.42857142857142855\n",
            "Recall: 0.8333333333333334\n",
            "F1-Score: 0.5660377358490566\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  8\t Learning rate: 0.0000\tLoss: 18.676998\t Accuracy: 111/213 (52%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[30 41]\n",
            " [ 6  4]]\n",
            "Accuracy: 0.41975308641975306\n",
            "Precision: 0.4225352112676056\n",
            "Recall: 0.8333333333333334\n",
            "F1-Score: 0.5607476635514019\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  9\t Learning rate: 0.0000\tLoss: 18.614396\t Accuracy: 126/213 (59%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[32 41]\n",
            " [ 4  4]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4383561643835616\n",
            "Recall: 0.8888888888888888\n",
            "F1-Score: 0.5871559633027523\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 10\t Learning rate: 0.0000\tLoss: 18.605064\t Accuracy: 125/213 (59%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[32 41]\n",
            " [ 4  4]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4383561643835616\n",
            "Recall: 0.8888888888888888\n",
            "F1-Score: 0.5871559633027523\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 11\t Learning rate: 0.0000\tLoss: 18.594436\t Accuracy: 128/213 (60%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[33 41]\n",
            " [ 3  4]]\n",
            "Accuracy: 0.4567901234567901\n",
            "Precision: 0.44594594594594594\n",
            "Recall: 0.9166666666666666\n",
            "F1-Score: 0.6\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 12\t Learning rate: 0.0000\tLoss: 18.575516\t Accuracy: 132/213 (62%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[33 41]\n",
            " [ 3  4]]\n",
            "Accuracy: 0.4567901234567901\n",
            "Precision: 0.44594594594594594\n",
            "Recall: 0.9166666666666666\n",
            "F1-Score: 0.6\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 13\t Learning rate: 0.0000\tLoss: 18.567929\t Accuracy: 132/213 (62%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[33 41]\n",
            " [ 3  4]]\n",
            "Accuracy: 0.4567901234567901\n",
            "Precision: 0.44594594594594594\n",
            "Recall: 0.9166666666666666\n",
            "F1-Score: 0.6\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 14\t Learning rate: 0.0000\tLoss: 18.546418\t Accuracy: 133/213 (62%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[33 42]\n",
            " [ 3  3]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.44\n",
            "Recall: 0.9166666666666666\n",
            "F1-Score: 0.5945945945945945\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 15\t Learning rate: 0.0000\tLoss: 18.554481\t Accuracy: 122/213 (57%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[34 42]\n",
            " [ 2  3]]\n",
            "Accuracy: 0.4567901234567901\n",
            "Precision: 0.4473684210526316\n",
            "Recall: 0.9444444444444444\n",
            "F1-Score: 0.6071428571428572\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 16\t Learning rate: 0.0000\tLoss: 18.556660\t Accuracy: 129/213 (61%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[35 42]\n",
            " [ 1  3]]\n",
            "Accuracy: 0.4691358024691358\n",
            "Precision: 0.45454545454545453\n",
            "Recall: 0.9722222222222222\n",
            "F1-Score: 0.6194690265486725\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 17\t Learning rate: 0.0000\tLoss: 18.574503\t Accuracy: 130/213 (61%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[35 42]\n",
            " [ 1  3]]\n",
            "Accuracy: 0.4691358024691358\n",
            "Precision: 0.45454545454545453\n",
            "Recall: 0.9722222222222222\n",
            "F1-Score: 0.6194690265486725\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 18\t Learning rate: 0.0000\tLoss: 18.588923\t Accuracy: 130/213 (61%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[35 42]\n",
            " [ 1  3]]\n",
            "Accuracy: 0.4691358024691358\n",
            "Precision: 0.45454545454545453\n",
            "Recall: 0.9722222222222222\n",
            "F1-Score: 0.6194690265486725\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 19\t Learning rate: 0.0000\tLoss: 18.539356\t Accuracy: 128/213 (60%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[35 42]\n",
            " [ 1  3]]\n",
            "Accuracy: 0.4691358024691358\n",
            "Precision: 0.45454545454545453\n",
            "Recall: 0.9722222222222222\n",
            "F1-Score: 0.6194690265486725\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 20\t Learning rate: 0.0000\tLoss: 18.513553\t Accuracy: 126/213 (59%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[35 42]\n",
            " [ 1  3]]\n",
            "Accuracy: 0.4691358024691358\n",
            "Precision: 0.45454545454545453\n",
            "Recall: 0.9722222222222222\n",
            "F1-Score: 0.6194690265486725\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 21\t Learning rate: 0.0000\tLoss: 18.507085\t Accuracy: 136/213 (64%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[35 42]\n",
            " [ 1  3]]\n",
            "Accuracy: 0.4691358024691358\n",
            "Precision: 0.45454545454545453\n",
            "Recall: 0.9722222222222222\n",
            "F1-Score: 0.6194690265486725\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 22\t Learning rate: 0.0000\tLoss: 18.474886\t Accuracy: 138/213 (65%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[35 42]\n",
            " [ 1  3]]\n",
            "Accuracy: 0.4691358024691358\n",
            "Precision: 0.45454545454545453\n",
            "Recall: 0.9722222222222222\n",
            "F1-Score: 0.6194690265486725\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 23\t Learning rate: 0.0000\tLoss: 18.506043\t Accuracy: 129/213 (61%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[35 42]\n",
            " [ 1  3]]\n",
            "Accuracy: 0.4691358024691358\n",
            "Precision: 0.45454545454545453\n",
            "Recall: 0.9722222222222222\n",
            "F1-Score: 0.6194690265486725\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 24\t Learning rate: 0.0000\tLoss: 18.496235\t Accuracy: 134/213 (63%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 43]\n",
            " [ 0  2]]\n",
            "Accuracy: 0.4691358024691358\n",
            "Precision: 0.45569620253164556\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6260869565217391\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 25\t Learning rate: 0.0000\tLoss: 18.467569\t Accuracy: 139/213 (65%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 43]\n",
            " [ 0  2]]\n",
            "Accuracy: 0.4691358024691358\n",
            "Precision: 0.45569620253164556\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6260869565217391\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 26\t Learning rate: 0.0000\tLoss: 18.484252\t Accuracy: 144/213 (68%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 43]\n",
            " [ 0  2]]\n",
            "Accuracy: 0.4691358024691358\n",
            "Precision: 0.45569620253164556\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6260869565217391\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 27\t Learning rate: 0.0000\tLoss: 18.459062\t Accuracy: 131/213 (62%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 43]\n",
            " [ 0  2]]\n",
            "Accuracy: 0.4691358024691358\n",
            "Precision: 0.45569620253164556\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6260869565217391\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 28\t Learning rate: 0.0000\tLoss: 18.445112\t Accuracy: 134/213 (63%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 43]\n",
            " [ 0  2]]\n",
            "Accuracy: 0.4691358024691358\n",
            "Precision: 0.45569620253164556\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6260869565217391\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 29\t Learning rate: 0.0000\tLoss: 18.399972\t Accuracy: 139/213 (65%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 43]\n",
            " [ 0  2]]\n",
            "Accuracy: 0.4691358024691358\n",
            "Precision: 0.45569620253164556\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6260869565217391\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 30\t Learning rate: 0.0000\tLoss: 18.393268\t Accuracy: 136/213 (64%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 44]\n",
            " [ 0  1]]\n",
            "Accuracy: 0.4567901234567901\n",
            "Precision: 0.45\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6206896551724138\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 31\t Learning rate: 0.0000\tLoss: 18.467071\t Accuracy: 131/213 (62%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 44]\n",
            " [ 0  1]]\n",
            "Accuracy: 0.4567901234567901\n",
            "Precision: 0.45\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6206896551724138\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 32\t Learning rate: 0.0000\tLoss: 18.441367\t Accuracy: 136/213 (64%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 44]\n",
            " [ 0  1]]\n",
            "Accuracy: 0.4567901234567901\n",
            "Precision: 0.45\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6206896551724138\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 33\t Learning rate: 0.0000\tLoss: 18.403816\t Accuracy: 136/213 (64%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 44]\n",
            " [ 0  1]]\n",
            "Accuracy: 0.4567901234567901\n",
            "Precision: 0.45\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6206896551724138\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 34\t Learning rate: 0.0000\tLoss: 18.328713\t Accuracy: 142/213 (67%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 45]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4444444444444444\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6153846153846153\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 35\t Learning rate: 0.0000\tLoss: 18.328918\t Accuracy: 141/213 (66%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 45]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4444444444444444\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6153846153846153\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 36\t Learning rate: 0.0000\tLoss: 18.357035\t Accuracy: 137/213 (64%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 45]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4444444444444444\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6153846153846153\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 37\t Learning rate: 0.0000\tLoss: 18.356122\t Accuracy: 143/213 (67%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 45]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4444444444444444\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6153846153846153\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 38\t Learning rate: 0.0000\tLoss: 18.340981\t Accuracy: 137/213 (64%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 45]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4444444444444444\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6153846153846153\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 39\t Learning rate: 0.0000\tLoss: 18.298867\t Accuracy: 142/213 (67%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 45]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4444444444444444\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6153846153846153\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 40\t Learning rate: 0.0000\tLoss: 18.315129\t Accuracy: 143/213 (67%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 45]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4444444444444444\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6153846153846153\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 41\t Learning rate: 0.0000\tLoss: 18.293872\t Accuracy: 138/213 (65%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 45]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4444444444444444\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6153846153846153\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 42\t Learning rate: 0.0000\tLoss: 18.270572\t Accuracy: 138/213 (65%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 45]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4444444444444444\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6153846153846153\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 43\t Learning rate: 0.0000\tLoss: 18.244200\t Accuracy: 140/213 (66%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 45]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4444444444444444\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6153846153846153\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 44\t Learning rate: 0.0000\tLoss: 18.279220\t Accuracy: 133/213 (62%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 45]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4444444444444444\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6153846153846153\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 45\t Learning rate: 0.0000\tLoss: 18.247932\t Accuracy: 135/213 (63%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 45]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4444444444444444\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6153846153846153\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 46\t Learning rate: 0.0000\tLoss: 18.214901\t Accuracy: 141/213 (66%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 45]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4444444444444444\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6153846153846153\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 47\t Learning rate: 0.0000\tLoss: 18.241518\t Accuracy: 134/213 (63%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 45]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4444444444444444\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6153846153846153\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 48\t Learning rate: 0.0000\tLoss: 18.142025\t Accuracy: 139/213 (65%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 45]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4444444444444444\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6153846153846153\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 49\t Learning rate: 0.0000\tLoss: 18.230820\t Accuracy: 137/213 (64%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 45]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4444444444444444\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6153846153846153\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 50\t Learning rate: 0.0000\tLoss: 18.189558\t Accuracy: 135/213 (63%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 45]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4444444444444444\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6153846153846153\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 51\t Learning rate: 0.0000\tLoss: 18.182343\t Accuracy: 136/213 (64%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 45]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4444444444444444\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6153846153846153\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 52\t Learning rate: 0.0000\tLoss: 18.085943\t Accuracy: 139/213 (65%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 45]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4444444444444444\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6153846153846153\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 53\t Learning rate: 0.0000\tLoss: 18.082034\t Accuracy: 141/213 (66%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 45]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4444444444444444\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6153846153846153\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 54\t Learning rate: 0.0000\tLoss: 18.082856\t Accuracy: 139/213 (65%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 45]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4444444444444444\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6153846153846153\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 55\t Learning rate: 0.0000\tLoss: 18.061088\t Accuracy: 144/213 (68%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 45]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4444444444444444\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6153846153846153\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 56\t Learning rate: 0.0000\tLoss: 18.038645\t Accuracy: 143/213 (67%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 45]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4444444444444444\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6153846153846153\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 57\t Learning rate: 0.0000\tLoss: 18.024286\t Accuracy: 143/213 (67%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 45]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4444444444444444\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6153846153846153\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 58\t Learning rate: 0.0000\tLoss: 17.972931\t Accuracy: 140/213 (66%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 45]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4444444444444444\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6153846153846153\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 59\t Learning rate: 0.0000\tLoss: 17.991795\t Accuracy: 140/213 (66%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 45]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4444444444444444\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6153846153846153\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 60\t Learning rate: 0.0000\tLoss: 17.964159\t Accuracy: 141/213 (66%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 44]\n",
            " [ 0  1]]\n",
            "Accuracy: 0.4567901234567901\n",
            "Precision: 0.45\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6206896551724138\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 61\t Learning rate: 0.0000\tLoss: 17.943704\t Accuracy: 142/213 (67%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 44]\n",
            " [ 0  1]]\n",
            "Accuracy: 0.4567901234567901\n",
            "Precision: 0.45\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6206896551724138\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 62\t Learning rate: 0.0000\tLoss: 17.906571\t Accuracy: 140/213 (66%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 44]\n",
            " [ 0  1]]\n",
            "Accuracy: 0.4567901234567901\n",
            "Precision: 0.45\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6206896551724138\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 63\t Learning rate: 0.0000\tLoss: 17.826646\t Accuracy: 145/213 (68%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 44]\n",
            " [ 0  1]]\n",
            "Accuracy: 0.4567901234567901\n",
            "Precision: 0.45\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6206896551724138\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 64\t Learning rate: 0.0000\tLoss: 17.806141\t Accuracy: 137/213 (64%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 44]\n",
            " [ 0  1]]\n",
            "Accuracy: 0.4567901234567901\n",
            "Precision: 0.45\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6206896551724138\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 65\t Learning rate: 0.0000\tLoss: 17.852912\t Accuracy: 136/213 (64%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 44]\n",
            " [ 0  1]]\n",
            "Accuracy: 0.4567901234567901\n",
            "Precision: 0.45\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6206896551724138\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 66\t Learning rate: 0.0000\tLoss: 17.864905\t Accuracy: 138/213 (65%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 44]\n",
            " [ 0  1]]\n",
            "Accuracy: 0.4567901234567901\n",
            "Precision: 0.45\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6206896551724138\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 67\t Learning rate: 0.0000\tLoss: 17.721156\t Accuracy: 145/213 (68%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[36 44]\n",
            " [ 0  1]]\n",
            "Accuracy: 0.4567901234567901\n",
            "Precision: 0.45\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6206896551724138\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 68\t Learning rate: 0.0000\tLoss: 17.782992\t Accuracy: 138/213 (65%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[35 44]\n",
            " [ 1  1]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4430379746835443\n",
            "Recall: 0.9722222222222222\n",
            "F1-Score: 0.608695652173913\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 69\t Learning rate: 0.0000\tLoss: 17.733780\t Accuracy: 132/213 (62%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[35 44]\n",
            " [ 1  1]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4430379746835443\n",
            "Recall: 0.9722222222222222\n",
            "F1-Score: 0.608695652173913\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 70\t Learning rate: 0.0000\tLoss: 17.701912\t Accuracy: 137/213 (64%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[35 44]\n",
            " [ 1  1]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4430379746835443\n",
            "Recall: 0.9722222222222222\n",
            "F1-Score: 0.608695652173913\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 71\t Learning rate: 0.0000\tLoss: 17.632353\t Accuracy: 144/213 (68%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[35 44]\n",
            " [ 1  1]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4430379746835443\n",
            "Recall: 0.9722222222222222\n",
            "F1-Score: 0.608695652173913\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 72\t Learning rate: 0.0000\tLoss: 17.624515\t Accuracy: 140/213 (66%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[35 44]\n",
            " [ 1  1]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4430379746835443\n",
            "Recall: 0.9722222222222222\n",
            "F1-Score: 0.608695652173913\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 73\t Learning rate: 0.0000\tLoss: 17.582355\t Accuracy: 143/213 (67%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[35 44]\n",
            " [ 1  1]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4430379746835443\n",
            "Recall: 0.9722222222222222\n",
            "F1-Score: 0.608695652173913\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 74\t Learning rate: 0.0000\tLoss: 17.472111\t Accuracy: 143/213 (67%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[35 44]\n",
            " [ 1  1]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4430379746835443\n",
            "Recall: 0.9722222222222222\n",
            "F1-Score: 0.608695652173913\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 75\t Learning rate: 0.0000\tLoss: 17.546250\t Accuracy: 147/213 (69%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[35 44]\n",
            " [ 1  1]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4430379746835443\n",
            "Recall: 0.9722222222222222\n",
            "F1-Score: 0.608695652173913\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 76\t Learning rate: 0.0000\tLoss: 17.558077\t Accuracy: 143/213 (67%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[35 44]\n",
            " [ 1  1]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4430379746835443\n",
            "Recall: 0.9722222222222222\n",
            "F1-Score: 0.608695652173913\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 77\t Learning rate: 0.0000\tLoss: 17.424679\t Accuracy: 143/213 (67%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[35 44]\n",
            " [ 1  1]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4430379746835443\n",
            "Recall: 0.9722222222222222\n",
            "F1-Score: 0.608695652173913\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 78\t Learning rate: 0.0000\tLoss: 17.419988\t Accuracy: 139/213 (65%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[35 44]\n",
            " [ 1  1]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4430379746835443\n",
            "Recall: 0.9722222222222222\n",
            "F1-Score: 0.608695652173913\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 79\t Learning rate: 0.0000\tLoss: 17.347193\t Accuracy: 136/213 (64%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[35 44]\n",
            " [ 1  1]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4430379746835443\n",
            "Recall: 0.9722222222222222\n",
            "F1-Score: 0.608695652173913\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 80\t Learning rate: 0.0000\tLoss: 17.414478\t Accuracy: 135/213 (63%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[35 44]\n",
            " [ 1  1]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4430379746835443\n",
            "Recall: 0.9722222222222222\n",
            "F1-Score: 0.608695652173913\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 81\t Learning rate: 0.0000\tLoss: 17.314604\t Accuracy: 143/213 (67%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[35 44]\n",
            " [ 1  1]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4430379746835443\n",
            "Recall: 0.9722222222222222\n",
            "F1-Score: 0.608695652173913\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 82\t Learning rate: 0.0000\tLoss: 17.223892\t Accuracy: 140/213 (66%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[35 42]\n",
            " [ 1  3]]\n",
            "Accuracy: 0.4691358024691358\n",
            "Precision: 0.45454545454545453\n",
            "Recall: 0.9722222222222222\n",
            "F1-Score: 0.6194690265486725\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 83\t Learning rate: 0.0000\tLoss: 17.308670\t Accuracy: 140/213 (66%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[35 42]\n",
            " [ 1  3]]\n",
            "Accuracy: 0.4691358024691358\n",
            "Precision: 0.45454545454545453\n",
            "Recall: 0.9722222222222222\n",
            "F1-Score: 0.6194690265486725\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 84\t Learning rate: 0.0000\tLoss: 17.086748\t Accuracy: 147/213 (69%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[34 42]\n",
            " [ 2  3]]\n",
            "Accuracy: 0.4567901234567901\n",
            "Precision: 0.4473684210526316\n",
            "Recall: 0.9444444444444444\n",
            "F1-Score: 0.6071428571428572\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 85\t Learning rate: 0.0000\tLoss: 17.033188\t Accuracy: 147/213 (69%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[34 42]\n",
            " [ 2  3]]\n",
            "Accuracy: 0.4567901234567901\n",
            "Precision: 0.4473684210526316\n",
            "Recall: 0.9444444444444444\n",
            "F1-Score: 0.6071428571428572\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 86\t Learning rate: 0.0000\tLoss: 16.945115\t Accuracy: 147/213 (69%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[34 42]\n",
            " [ 2  3]]\n",
            "Accuracy: 0.4567901234567901\n",
            "Precision: 0.4473684210526316\n",
            "Recall: 0.9444444444444444\n",
            "F1-Score: 0.6071428571428572\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 87\t Learning rate: 0.0000\tLoss: 16.971341\t Accuracy: 141/213 (66%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[33 42]\n",
            " [ 3  3]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.44\n",
            "Recall: 0.9166666666666666\n",
            "F1-Score: 0.5945945945945945\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 88\t Learning rate: 0.0000\tLoss: 16.981824\t Accuracy: 150/213 (70%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[33 42]\n",
            " [ 3  3]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.44\n",
            "Recall: 0.9166666666666666\n",
            "F1-Score: 0.5945945945945945\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 89\t Learning rate: 0.0000\tLoss: 16.745236\t Accuracy: 148/213 (69%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[33 42]\n",
            " [ 3  3]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.44\n",
            "Recall: 0.9166666666666666\n",
            "F1-Score: 0.5945945945945945\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 90\t Learning rate: 0.0000\tLoss: 16.852514\t Accuracy: 146/213 (69%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[33 42]\n",
            " [ 3  3]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.44\n",
            "Recall: 0.9166666666666666\n",
            "F1-Score: 0.5945945945945945\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 91\t Learning rate: 0.0000\tLoss: 16.745112\t Accuracy: 143/213 (67%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[33 42]\n",
            " [ 3  3]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.44\n",
            "Recall: 0.9166666666666666\n",
            "F1-Score: 0.5945945945945945\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 92\t Learning rate: 0.0000\tLoss: 16.635797\t Accuracy: 149/213 (70%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[32 42]\n",
            " [ 4  3]]\n",
            "Accuracy: 0.43209876543209874\n",
            "Precision: 0.43243243243243246\n",
            "Recall: 0.8888888888888888\n",
            "F1-Score: 0.5818181818181818\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 93\t Learning rate: 0.0000\tLoss: 16.651572\t Accuracy: 151/213 (71%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[32 42]\n",
            " [ 4  3]]\n",
            "Accuracy: 0.43209876543209874\n",
            "Precision: 0.43243243243243246\n",
            "Recall: 0.8888888888888888\n",
            "F1-Score: 0.5818181818181818\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 94\t Learning rate: 0.0000\tLoss: 16.682684\t Accuracy: 148/213 (69%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[32 42]\n",
            " [ 4  3]]\n",
            "Accuracy: 0.43209876543209874\n",
            "Precision: 0.43243243243243246\n",
            "Recall: 0.8888888888888888\n",
            "F1-Score: 0.5818181818181818\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 95\t Learning rate: 0.0000\tLoss: 16.517368\t Accuracy: 151/213 (71%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[32 42]\n",
            " [ 4  3]]\n",
            "Accuracy: 0.43209876543209874\n",
            "Precision: 0.43243243243243246\n",
            "Recall: 0.8888888888888888\n",
            "F1-Score: 0.5818181818181818\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 96\t Learning rate: 0.0000\tLoss: 16.509553\t Accuracy: 148/213 (69%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[32 41]\n",
            " [ 4  4]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4383561643835616\n",
            "Recall: 0.8888888888888888\n",
            "F1-Score: 0.5871559633027523\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 97\t Learning rate: 0.0000\tLoss: 16.429816\t Accuracy: 148/213 (69%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[32 41]\n",
            " [ 4  4]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4383561643835616\n",
            "Recall: 0.8888888888888888\n",
            "F1-Score: 0.5871559633027523\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 98\t Learning rate: 0.0000\tLoss: 16.409814\t Accuracy: 151/213 (71%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[32 41]\n",
            " [ 4  4]]\n",
            "Accuracy: 0.4444444444444444\n",
            "Precision: 0.4383561643835616\n",
            "Recall: 0.8888888888888888\n",
            "F1-Score: 0.5871559633027523\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 99\t Learning rate: 0.0000\tLoss: 16.263719\t Accuracy: 152/213 (71%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[32 40]\n",
            " [ 4  5]]\n",
            "Accuracy: 0.4567901234567901\n",
            "Precision: 0.4444444444444444\n",
            "Recall: 0.8888888888888888\n",
            "F1-Score: 0.5925925925925926\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 100\t Learning rate: 0.0000\tLoss: 16.119067\t Accuracy: 150/213 (70%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[32 40]\n",
            " [ 4  5]]\n",
            "Accuracy: 0.4567901234567901\n",
            "Precision: 0.4444444444444444\n",
            "Recall: 0.8888888888888888\n",
            "F1-Score: 0.5925925925925926\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 101\t Learning rate: 0.0000\tLoss: 16.104563\t Accuracy: 149/213 (70%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[32 40]\n",
            " [ 4  5]]\n",
            "Accuracy: 0.4567901234567901\n",
            "Precision: 0.4444444444444444\n",
            "Recall: 0.8888888888888888\n",
            "F1-Score: 0.5925925925925926\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 102\t Learning rate: 0.0000\tLoss: 16.050660\t Accuracy: 156/213 (73%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[32 40]\n",
            " [ 4  5]]\n",
            "Accuracy: 0.4567901234567901\n",
            "Precision: 0.4444444444444444\n",
            "Recall: 0.8888888888888888\n",
            "F1-Score: 0.5925925925925926\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 103\t Learning rate: 0.0000\tLoss: 15.989877\t Accuracy: 150/213 (70%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[32 40]\n",
            " [ 4  5]]\n",
            "Accuracy: 0.4567901234567901\n",
            "Precision: 0.4444444444444444\n",
            "Recall: 0.8888888888888888\n",
            "F1-Score: 0.5925925925925926\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 104\t Learning rate: 0.0000\tLoss: 15.914094\t Accuracy: 154/213 (72%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[32 40]\n",
            " [ 4  5]]\n",
            "Accuracy: 0.4567901234567901\n",
            "Precision: 0.4444444444444444\n",
            "Recall: 0.8888888888888888\n",
            "F1-Score: 0.5925925925925926\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 105\t Learning rate: 0.0000\tLoss: 15.875974\t Accuracy: 150/213 (70%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[32 40]\n",
            " [ 4  5]]\n",
            "Accuracy: 0.4567901234567901\n",
            "Precision: 0.4444444444444444\n",
            "Recall: 0.8888888888888888\n",
            "F1-Score: 0.5925925925925926\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 106\t Learning rate: 0.0000\tLoss: 15.712190\t Accuracy: 160/213 (75%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[32 40]\n",
            " [ 4  5]]\n",
            "Accuracy: 0.4567901234567901\n",
            "Precision: 0.4444444444444444\n",
            "Recall: 0.8888888888888888\n",
            "F1-Score: 0.5925925925925926\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 107\t Learning rate: 0.0000\tLoss: 15.592569\t Accuracy: 157/213 (74%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[32 40]\n",
            " [ 4  5]]\n",
            "Accuracy: 0.4567901234567901\n",
            "Precision: 0.4444444444444444\n",
            "Recall: 0.8888888888888888\n",
            "F1-Score: 0.5925925925925926\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 108\t Learning rate: 0.0000\tLoss: 15.612472\t Accuracy: 159/213 (75%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[32 39]\n",
            " [ 4  6]]\n",
            "Accuracy: 0.4691358024691358\n",
            "Precision: 0.4507042253521127\n",
            "Recall: 0.8888888888888888\n",
            "F1-Score: 0.5981308411214953\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 109\t Learning rate: 0.0000\tLoss: 15.525412\t Accuracy: 160/213 (75%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[32 39]\n",
            " [ 4  6]]\n",
            "Accuracy: 0.4691358024691358\n",
            "Precision: 0.4507042253521127\n",
            "Recall: 0.8888888888888888\n",
            "F1-Score: 0.5981308411214953\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 110\t Learning rate: 0.0000\tLoss: 15.511766\t Accuracy: 158/213 (74%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[32 39]\n",
            " [ 4  6]]\n",
            "Accuracy: 0.4691358024691358\n",
            "Precision: 0.4507042253521127\n",
            "Recall: 0.8888888888888888\n",
            "F1-Score: 0.5981308411214953\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 111\t Learning rate: 0.0000\tLoss: 15.370569\t Accuracy: 165/213 (77%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[32 39]\n",
            " [ 4  6]]\n",
            "Accuracy: 0.4691358024691358\n",
            "Precision: 0.4507042253521127\n",
            "Recall: 0.8888888888888888\n",
            "F1-Score: 0.5981308411214953\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 112\t Learning rate: 0.0000\tLoss: 15.254149\t Accuracy: 163/213 (77%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[32 39]\n",
            " [ 4  6]]\n",
            "Accuracy: 0.4691358024691358\n",
            "Precision: 0.4507042253521127\n",
            "Recall: 0.8888888888888888\n",
            "F1-Score: 0.5981308411214953\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 113\t Learning rate: 0.0000\tLoss: 15.131741\t Accuracy: 158/213 (74%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[32 39]\n",
            " [ 4  6]]\n",
            "Accuracy: 0.4691358024691358\n",
            "Precision: 0.4507042253521127\n",
            "Recall: 0.8888888888888888\n",
            "F1-Score: 0.5981308411214953\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 114\t Learning rate: 0.0000\tLoss: 15.154840\t Accuracy: 167/213 (78%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[32 37]\n",
            " [ 4  8]]\n",
            "Accuracy: 0.49382716049382713\n",
            "Precision: 0.463768115942029\n",
            "Recall: 0.8888888888888888\n",
            "F1-Score: 0.6095238095238095\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 115\t Learning rate: 0.0000\tLoss: 14.979482\t Accuracy: 165/213 (77%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[32 37]\n",
            " [ 4  8]]\n",
            "Accuracy: 0.49382716049382713\n",
            "Precision: 0.463768115942029\n",
            "Recall: 0.8888888888888888\n",
            "F1-Score: 0.6095238095238095\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 116\t Learning rate: 0.0000\tLoss: 14.994007\t Accuracy: 171/213 (80%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[32 37]\n",
            " [ 4  8]]\n",
            "Accuracy: 0.49382716049382713\n",
            "Precision: 0.463768115942029\n",
            "Recall: 0.8888888888888888\n",
            "F1-Score: 0.6095238095238095\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 117\t Learning rate: 0.0000\tLoss: 14.921793\t Accuracy: 160/213 (75%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[32 35]\n",
            " [ 4 10]]\n",
            "Accuracy: 0.5185185185185185\n",
            "Precision: 0.47761194029850745\n",
            "Recall: 0.8888888888888888\n",
            "F1-Score: 0.6213592233009708\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 118\t Learning rate: 0.0000\tLoss: 14.785725\t Accuracy: 170/213 (80%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[30 35]\n",
            " [ 6 10]]\n",
            "Accuracy: 0.49382716049382713\n",
            "Precision: 0.46153846153846156\n",
            "Recall: 0.8333333333333334\n",
            "F1-Score: 0.594059405940594\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 119\t Learning rate: 0.0000\tLoss: 14.685384\t Accuracy: 167/213 (78%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[30 35]\n",
            " [ 6 10]]\n",
            "Accuracy: 0.49382716049382713\n",
            "Precision: 0.46153846153846156\n",
            "Recall: 0.8333333333333334\n",
            "F1-Score: 0.594059405940594\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 120\t Learning rate: 0.0000\tLoss: 14.693375\t Accuracy: 170/213 (80%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[30 35]\n",
            " [ 6 10]]\n",
            "Accuracy: 0.49382716049382713\n",
            "Precision: 0.46153846153846156\n",
            "Recall: 0.8333333333333334\n",
            "F1-Score: 0.594059405940594\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 121\t Learning rate: 0.0000\tLoss: 14.523258\t Accuracy: 169/213 (79%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[30 34]\n",
            " [ 6 11]]\n",
            "Accuracy: 0.5061728395061729\n",
            "Precision: 0.46875\n",
            "Recall: 0.8333333333333334\n",
            "F1-Score: 0.6\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 122\t Learning rate: 0.0000\tLoss: 14.533598\t Accuracy: 174/213 (82%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[30 34]\n",
            " [ 6 11]]\n",
            "Accuracy: 0.5061728395061729\n",
            "Precision: 0.46875\n",
            "Recall: 0.8333333333333334\n",
            "F1-Score: 0.6\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 123\t Learning rate: 0.0000\tLoss: 14.487702\t Accuracy: 171/213 (80%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[29 33]\n",
            " [ 7 12]]\n",
            "Accuracy: 0.5061728395061729\n",
            "Precision: 0.46774193548387094\n",
            "Recall: 0.8055555555555556\n",
            "F1-Score: 0.5918367346938775\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 124\t Learning rate: 0.0000\tLoss: 14.318314\t Accuracy: 174/213 (82%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[29 33]\n",
            " [ 7 12]]\n",
            "Accuracy: 0.5061728395061729\n",
            "Precision: 0.46774193548387094\n",
            "Recall: 0.8055555555555556\n",
            "F1-Score: 0.5918367346938775\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 125\t Learning rate: 0.0000\tLoss: 14.307141\t Accuracy: 172/213 (81%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[28 33]\n",
            " [ 8 12]]\n",
            "Accuracy: 0.49382716049382713\n",
            "Precision: 0.45901639344262296\n",
            "Recall: 0.7777777777777778\n",
            "F1-Score: 0.5773195876288659\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 126\t Learning rate: 0.0000\tLoss: 14.123907\t Accuracy: 179/213 (84%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[27 33]\n",
            " [ 9 12]]\n",
            "Accuracy: 0.48148148148148145\n",
            "Precision: 0.45\n",
            "Recall: 0.75\n",
            "F1-Score: 0.5625000000000001\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 127\t Learning rate: 0.0000\tLoss: 14.135530\t Accuracy: 172/213 (81%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[27 33]\n",
            " [ 9 12]]\n",
            "Accuracy: 0.48148148148148145\n",
            "Precision: 0.45\n",
            "Recall: 0.75\n",
            "F1-Score: 0.5625000000000001\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 128\t Learning rate: 0.0000\tLoss: 13.973367\t Accuracy: 177/213 (83%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[27 33]\n",
            " [ 9 12]]\n",
            "Accuracy: 0.48148148148148145\n",
            "Precision: 0.45\n",
            "Recall: 0.75\n",
            "F1-Score: 0.5625000000000001\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 129\t Learning rate: 0.0000\tLoss: 13.943909\t Accuracy: 181/213 (85%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[26 33]\n",
            " [10 12]]\n",
            "Accuracy: 0.4691358024691358\n",
            "Precision: 0.4406779661016949\n",
            "Recall: 0.7222222222222222\n",
            "F1-Score: 0.5473684210526315\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 130\t Learning rate: 0.0000\tLoss: 13.874446\t Accuracy: 183/213 (86%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[25 31]\n",
            " [11 14]]\n",
            "Accuracy: 0.48148148148148145\n",
            "Precision: 0.44642857142857145\n",
            "Recall: 0.6944444444444444\n",
            "F1-Score: 0.5434782608695653\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 131\t Learning rate: 0.0000\tLoss: 13.872011\t Accuracy: 179/213 (84%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[25 31]\n",
            " [11 14]]\n",
            "Accuracy: 0.48148148148148145\n",
            "Precision: 0.44642857142857145\n",
            "Recall: 0.6944444444444444\n",
            "F1-Score: 0.5434782608695653\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 132\t Learning rate: 0.0000\tLoss: 13.812753\t Accuracy: 181/213 (85%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[24 30]\n",
            " [12 15]]\n",
            "Accuracy: 0.48148148148148145\n",
            "Precision: 0.4444444444444444\n",
            "Recall: 0.6666666666666666\n",
            "F1-Score: 0.5333333333333333\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 133\t Learning rate: 0.0000\tLoss: 13.749751\t Accuracy: 184/213 (86%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[24 29]\n",
            " [12 16]]\n",
            "Accuracy: 0.49382716049382713\n",
            "Precision: 0.4528301886792453\n",
            "Recall: 0.6666666666666666\n",
            "F1-Score: 0.5393258426966292\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 134\t Learning rate: 0.0000\tLoss: 13.633705\t Accuracy: 185/213 (87%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[24 28]\n",
            " [12 17]]\n",
            "Accuracy: 0.5061728395061729\n",
            "Precision: 0.46153846153846156\n",
            "Recall: 0.6666666666666666\n",
            "F1-Score: 0.5454545454545455\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 135\t Learning rate: 0.0000\tLoss: 13.667341\t Accuracy: 177/213 (83%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[24 28]\n",
            " [12 17]]\n",
            "Accuracy: 0.5061728395061729\n",
            "Precision: 0.46153846153846156\n",
            "Recall: 0.6666666666666666\n",
            "F1-Score: 0.5454545454545455\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 136\t Learning rate: 0.0000\tLoss: 13.490537\t Accuracy: 183/213 (86%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[24 28]\n",
            " [12 17]]\n",
            "Accuracy: 0.5061728395061729\n",
            "Precision: 0.46153846153846156\n",
            "Recall: 0.6666666666666666\n",
            "F1-Score: 0.5454545454545455\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 137\t Learning rate: 0.0000\tLoss: 13.405654\t Accuracy: 187/213 (88%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[24 28]\n",
            " [12 17]]\n",
            "Accuracy: 0.5061728395061729\n",
            "Precision: 0.46153846153846156\n",
            "Recall: 0.6666666666666666\n",
            "F1-Score: 0.5454545454545455\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 138\t Learning rate: 0.0000\tLoss: 13.267635\t Accuracy: 189/213 (89%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[24 27]\n",
            " [12 18]]\n",
            "Accuracy: 0.5185185185185185\n",
            "Precision: 0.47058823529411764\n",
            "Recall: 0.6666666666666666\n",
            "F1-Score: 0.5517241379310345\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 139\t Learning rate: 0.0000\tLoss: 13.311701\t Accuracy: 188/213 (88%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[23 27]\n",
            " [13 18]]\n",
            "Accuracy: 0.5061728395061729\n",
            "Precision: 0.46\n",
            "Recall: 0.6388888888888888\n",
            "F1-Score: 0.5348837209302325\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 140\t Learning rate: 0.0000\tLoss: 13.210752\t Accuracy: 188/213 (88%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[23 26]\n",
            " [13 19]]\n",
            "Accuracy: 0.5185185185185185\n",
            "Precision: 0.46938775510204084\n",
            "Recall: 0.6388888888888888\n",
            "F1-Score: 0.5411764705882353\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 141\t Learning rate: 0.0000\tLoss: 13.202925\t Accuracy: 194/213 (91%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[23 26]\n",
            " [13 19]]\n",
            "Accuracy: 0.5185185185185185\n",
            "Precision: 0.46938775510204084\n",
            "Recall: 0.6388888888888888\n",
            "F1-Score: 0.5411764705882353\n",
            "\n",
            "=========================================================================================\n",
            "Saved as /content/drive/MyDrive/Data/DepressionDetection/Baseline/Model/ClassificationWhole/Audio/BiLSTM_gru_vlad256_256_0.54_1.pt\n",
            "****************************************************************\n",
            "model saved: f1: 0.5411764705882353\tacc: 0.5185185185185185\n",
            "****************************************************************\n",
            "Train Epoch: 142\t Learning rate: 0.0000\tLoss: 13.058326\t Accuracy: 194/213 (91%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[23 26]\n",
            " [13 19]]\n",
            "Accuracy: 0.5185185185185185\n",
            "Precision: 0.46938775510204084\n",
            "Recall: 0.6388888888888888\n",
            "F1-Score: 0.5411764705882353\n",
            "\n",
            "=========================================================================================\n",
            "Saved as /content/drive/MyDrive/Data/DepressionDetection/Baseline/Model/ClassificationWhole/Audio/BiLSTM_gru_vlad256_256_0.54_1.pt\n",
            "****************************************************************\n",
            "model saved: f1: 0.5411764705882353\tacc: 0.5185185185185185\n",
            "****************************************************************\n",
            "Train Epoch: 143\t Learning rate: 0.0000\tLoss: 13.035576\t Accuracy: 192/213 (90%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[22 24]\n",
            " [14 21]]\n",
            "Accuracy: 0.5308641975308642\n",
            "Precision: 0.4782608695652174\n",
            "Recall: 0.6111111111111112\n",
            "F1-Score: 0.5365853658536586\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 144\t Learning rate: 0.0000\tLoss: 12.952230\t Accuracy: 193/213 (91%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[22 24]\n",
            " [14 21]]\n",
            "Accuracy: 0.5308641975308642\n",
            "Precision: 0.4782608695652174\n",
            "Recall: 0.6111111111111112\n",
            "F1-Score: 0.5365853658536586\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 145\t Learning rate: 0.0000\tLoss: 12.988504\t Accuracy: 191/213 (90%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[22 24]\n",
            " [14 21]]\n",
            "Accuracy: 0.5308641975308642\n",
            "Precision: 0.4782608695652174\n",
            "Recall: 0.6111111111111112\n",
            "F1-Score: 0.5365853658536586\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 146\t Learning rate: 0.0000\tLoss: 12.774486\t Accuracy: 196/213 (92%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[22 24]\n",
            " [14 21]]\n",
            "Accuracy: 0.5308641975308642\n",
            "Precision: 0.4782608695652174\n",
            "Recall: 0.6111111111111112\n",
            "F1-Score: 0.5365853658536586\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 147\t Learning rate: 0.0000\tLoss: 12.842778\t Accuracy: 190/213 (89%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[22 23]\n",
            " [14 22]]\n",
            "Accuracy: 0.5432098765432098\n",
            "Precision: 0.4888888888888889\n",
            "Recall: 0.6111111111111112\n",
            "F1-Score: 0.5432098765432098\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 148\t Learning rate: 0.0000\tLoss: 12.724226\t Accuracy: 197/213 (92%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[21 23]\n",
            " [15 22]]\n",
            "Accuracy: 0.5308641975308642\n",
            "Precision: 0.4772727272727273\n",
            "Recall: 0.5833333333333334\n",
            "F1-Score: 0.5250000000000001\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 149\t Learning rate: 0.0000\tLoss: 12.787555\t Accuracy: 196/213 (92%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[21 23]\n",
            " [15 22]]\n",
            "Accuracy: 0.5308641975308642\n",
            "Precision: 0.4772727272727273\n",
            "Recall: 0.5833333333333334\n",
            "F1-Score: 0.5250000000000001\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 150\t Learning rate: 0.0000\tLoss: 12.660067\t Accuracy: 198/213 (93%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[21 23]\n",
            " [15 22]]\n",
            "Accuracy: 0.5308641975308642\n",
            "Precision: 0.4772727272727273\n",
            "Recall: 0.5833333333333334\n",
            "F1-Score: 0.5250000000000001\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 151\t Learning rate: 0.0000\tLoss: 12.411524\t Accuracy: 201/213 (94%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[21 23]\n",
            " [15 22]]\n",
            "Accuracy: 0.5308641975308642\n",
            "Precision: 0.4772727272727273\n",
            "Recall: 0.5833333333333334\n",
            "F1-Score: 0.5250000000000001\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 152\t Learning rate: 0.0000\tLoss: 12.425895\t Accuracy: 200/213 (94%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[21 23]\n",
            " [15 22]]\n",
            "Accuracy: 0.5308641975308642\n",
            "Precision: 0.4772727272727273\n",
            "Recall: 0.5833333333333334\n",
            "F1-Score: 0.5250000000000001\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 153\t Learning rate: 0.0000\tLoss: 12.379340\t Accuracy: 202/213 (95%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[21 23]\n",
            " [15 22]]\n",
            "Accuracy: 0.5308641975308642\n",
            "Precision: 0.4772727272727273\n",
            "Recall: 0.5833333333333334\n",
            "F1-Score: 0.5250000000000001\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 154\t Learning rate: 0.0000\tLoss: 12.263663\t Accuracy: 201/213 (94%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[21 23]\n",
            " [15 22]]\n",
            "Accuracy: 0.5308641975308642\n",
            "Precision: 0.4772727272727273\n",
            "Recall: 0.5833333333333334\n",
            "F1-Score: 0.5250000000000001\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 155\t Learning rate: 0.0000\tLoss: 12.304967\t Accuracy: 198/213 (93%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[21 23]\n",
            " [15 22]]\n",
            "Accuracy: 0.5308641975308642\n",
            "Precision: 0.4772727272727273\n",
            "Recall: 0.5833333333333334\n",
            "F1-Score: 0.5250000000000001\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 156\t Learning rate: 0.0000\tLoss: 12.146847\t Accuracy: 202/213 (95%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[21 23]\n",
            " [15 22]]\n",
            "Accuracy: 0.5308641975308642\n",
            "Precision: 0.4772727272727273\n",
            "Recall: 0.5833333333333334\n",
            "F1-Score: 0.5250000000000001\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 157\t Learning rate: 0.0000\tLoss: 12.090506\t Accuracy: 203/213 (95%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[21 23]\n",
            " [15 22]]\n",
            "Accuracy: 0.5308641975308642\n",
            "Precision: 0.4772727272727273\n",
            "Recall: 0.5833333333333334\n",
            "F1-Score: 0.5250000000000001\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 158\t Learning rate: 0.0000\tLoss: 12.067674\t Accuracy: 202/213 (95%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[21 23]\n",
            " [15 22]]\n",
            "Accuracy: 0.5308641975308642\n",
            "Precision: 0.4772727272727273\n",
            "Recall: 0.5833333333333334\n",
            "F1-Score: 0.5250000000000001\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 159\t Learning rate: 0.0000\tLoss: 11.977332\t Accuracy: 202/213 (95%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[21 22]\n",
            " [15 23]]\n",
            "Accuracy: 0.5432098765432098\n",
            "Precision: 0.4883720930232558\n",
            "Recall: 0.5833333333333334\n",
            "F1-Score: 0.5316455696202531\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 160\t Learning rate: 0.0000\tLoss: 11.838269\t Accuracy: 205/213 (96%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[21 22]\n",
            " [15 23]]\n",
            "Accuracy: 0.5432098765432098\n",
            "Precision: 0.4883720930232558\n",
            "Recall: 0.5833333333333334\n",
            "F1-Score: 0.5316455696202531\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 161\t Learning rate: 0.0000\tLoss: 11.951368\t Accuracy: 202/213 (95%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[21 22]\n",
            " [15 23]]\n",
            "Accuracy: 0.5432098765432098\n",
            "Precision: 0.4883720930232558\n",
            "Recall: 0.5833333333333334\n",
            "F1-Score: 0.5316455696202531\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 162\t Learning rate: 0.0000\tLoss: 11.886281\t Accuracy: 202/213 (95%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[21 22]\n",
            " [15 23]]\n",
            "Accuracy: 0.5432098765432098\n",
            "Precision: 0.4883720930232558\n",
            "Recall: 0.5833333333333334\n",
            "F1-Score: 0.5316455696202531\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 163\t Learning rate: 0.0000\tLoss: 11.724976\t Accuracy: 203/213 (95%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[21 22]\n",
            " [15 23]]\n",
            "Accuracy: 0.5432098765432098\n",
            "Precision: 0.4883720930232558\n",
            "Recall: 0.5833333333333334\n",
            "F1-Score: 0.5316455696202531\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 164\t Learning rate: 0.0000\tLoss: 11.722644\t Accuracy: 206/213 (97%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[21 22]\n",
            " [15 23]]\n",
            "Accuracy: 0.5432098765432098\n",
            "Precision: 0.4883720930232558\n",
            "Recall: 0.5833333333333334\n",
            "F1-Score: 0.5316455696202531\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 165\t Learning rate: 0.0000\tLoss: 11.690658\t Accuracy: 202/213 (95%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[20 22]\n",
            " [16 23]]\n",
            "Accuracy: 0.5308641975308642\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 0.5555555555555556\n",
            "F1-Score: 0.5128205128205129\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 166\t Learning rate: 0.0000\tLoss: 11.628781\t Accuracy: 204/213 (96%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[20 22]\n",
            " [16 23]]\n",
            "Accuracy: 0.5308641975308642\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 0.5555555555555556\n",
            "F1-Score: 0.5128205128205129\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 167\t Learning rate: 0.0000\tLoss: 11.590420\t Accuracy: 206/213 (97%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[20 22]\n",
            " [16 23]]\n",
            "Accuracy: 0.5308641975308642\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 0.5555555555555556\n",
            "F1-Score: 0.5128205128205129\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 168\t Learning rate: 0.0000\tLoss: 11.397572\t Accuracy: 206/213 (97%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[20 21]\n",
            " [16 24]]\n",
            "Accuracy: 0.5432098765432098\n",
            "Precision: 0.4878048780487805\n",
            "Recall: 0.5555555555555556\n",
            "F1-Score: 0.5194805194805195\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 169\t Learning rate: 0.0000\tLoss: 11.286005\t Accuracy: 207/213 (97%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[20 21]\n",
            " [16 24]]\n",
            "Accuracy: 0.5432098765432098\n",
            "Precision: 0.4878048780487805\n",
            "Recall: 0.5555555555555556\n",
            "F1-Score: 0.5194805194805195\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 170\t Learning rate: 0.0000\tLoss: 11.349808\t Accuracy: 207/213 (97%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[20 21]\n",
            " [16 24]]\n",
            "Accuracy: 0.5432098765432098\n",
            "Precision: 0.4878048780487805\n",
            "Recall: 0.5555555555555556\n",
            "F1-Score: 0.5194805194805195\n",
            "\n",
            "=========================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/169 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a1d2b6104af041efaa985fc874b70441"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch:  2\t Learning rate: 0.0000\tLoss: 17.950467\t Accuracy: 120/208 (58%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  3\t Learning rate: 0.0000\tLoss: 17.960948\t Accuracy: 113/208 (54%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  4\t Learning rate: 0.0000\tLoss: 18.010393\t Accuracy: 107/208 (51%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  5\t Learning rate: 0.0000\tLoss: 17.965260\t Accuracy: 115/208 (55%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  6\t Learning rate: 0.0000\tLoss: 17.911283\t Accuracy: 123/208 (59%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  7\t Learning rate: 0.0000\tLoss: 17.929493\t Accuracy: 119/208 (57%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  8\t Learning rate: 0.0000\tLoss: 17.957794\t Accuracy: 116/208 (56%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch:  9\t Learning rate: 0.0000\tLoss: 17.919447\t Accuracy: 125/208 (60%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 10\t Learning rate: 0.0000\tLoss: 17.882823\t Accuracy: 123/208 (59%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 11\t Learning rate: 0.0000\tLoss: 17.909759\t Accuracy: 130/208 (62%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 12\t Learning rate: 0.0000\tLoss: 17.920776\t Accuracy: 125/208 (60%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 13\t Learning rate: 0.0000\tLoss: 17.872610\t Accuracy: 118/208 (57%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 14\t Learning rate: 0.0000\tLoss: 17.922978\t Accuracy: 119/208 (57%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 15\t Learning rate: 0.0000\tLoss: 17.909079\t Accuracy: 124/208 (60%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 16\t Learning rate: 0.0000\tLoss: 17.910042\t Accuracy: 124/208 (60%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 17\t Learning rate: 0.0000\tLoss: 17.825426\t Accuracy: 126/208 (61%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 18\t Learning rate: 0.0000\tLoss: 17.835885\t Accuracy: 130/208 (62%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 19\t Learning rate: 0.0000\tLoss: 17.817766\t Accuracy: 128/208 (62%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 20\t Learning rate: 0.0000\tLoss: 17.837210\t Accuracy: 123/208 (59%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 21\t Learning rate: 0.0000\tLoss: 17.859244\t Accuracy: 123/208 (59%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 22\t Learning rate: 0.0000\tLoss: 17.812271\t Accuracy: 127/208 (61%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 23\t Learning rate: 0.0000\tLoss: 17.814552\t Accuracy: 126/208 (61%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 24\t Learning rate: 0.0000\tLoss: 17.810791\t Accuracy: 127/208 (61%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 25\t Learning rate: 0.0000\tLoss: 17.838727\t Accuracy: 126/208 (61%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 26\t Learning rate: 0.0000\tLoss: 17.856072\t Accuracy: 119/208 (57%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 27\t Learning rate: 0.0000\tLoss: 17.832745\t Accuracy: 126/208 (61%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 28\t Learning rate: 0.0000\tLoss: 17.834979\t Accuracy: 126/208 (61%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 29\t Learning rate: 0.0000\tLoss: 17.778017\t Accuracy: 132/208 (63%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 30\t Learning rate: 0.0000\tLoss: 17.757608\t Accuracy: 120/208 (58%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 31\t Learning rate: 0.0000\tLoss: 17.799768\t Accuracy: 128/208 (62%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 32\t Learning rate: 0.0000\tLoss: 17.765624\t Accuracy: 131/208 (63%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 33\t Learning rate: 0.0000\tLoss: 17.763720\t Accuracy: 132/208 (63%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 34\t Learning rate: 0.0000\tLoss: 17.731426\t Accuracy: 128/208 (62%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 35\t Learning rate: 0.0000\tLoss: 17.707154\t Accuracy: 133/208 (64%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 36\t Learning rate: 0.0000\tLoss: 17.697240\t Accuracy: 133/208 (64%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 37\t Learning rate: 0.0000\tLoss: 17.677215\t Accuracy: 130/208 (62%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 38\t Learning rate: 0.0000\tLoss: 17.716217\t Accuracy: 133/208 (64%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 39\t Learning rate: 0.0000\tLoss: 17.667899\t Accuracy: 127/208 (61%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 40\t Learning rate: 0.0000\tLoss: 17.684930\t Accuracy: 131/208 (63%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 41\t Learning rate: 0.0000\tLoss: 17.613597\t Accuracy: 136/208 (65%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 42\t Learning rate: 0.0000\tLoss: 17.628641\t Accuracy: 131/208 (63%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 43\t Learning rate: 0.0000\tLoss: 17.575202\t Accuracy: 128/208 (62%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 44\t Learning rate: 0.0000\tLoss: 17.655268\t Accuracy: 132/208 (63%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 45\t Learning rate: 0.0000\tLoss: 17.569451\t Accuracy: 134/208 (64%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 46\t Learning rate: 0.0000\tLoss: 17.609894\t Accuracy: 125/208 (60%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 47\t Learning rate: 0.0000\tLoss: 17.589840\t Accuracy: 131/208 (63%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 48\t Learning rate: 0.0000\tLoss: 17.572281\t Accuracy: 133/208 (64%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 44]\n",
            " [ 0  0]]\n",
            "Accuracy: 0.47619047619047616\n",
            "Precision: 0.47619047619047616\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6451612903225806\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 49\t Learning rate: 0.0000\tLoss: 17.527485\t Accuracy: 128/208 (62%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 43]\n",
            " [ 0  1]]\n",
            "Accuracy: 0.4880952380952381\n",
            "Precision: 0.4819277108433735\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6504065040650406\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 50\t Learning rate: 0.0000\tLoss: 17.520912\t Accuracy: 129/208 (62%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 43]\n",
            " [ 0  1]]\n",
            "Accuracy: 0.4880952380952381\n",
            "Precision: 0.4819277108433735\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6504065040650406\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 51\t Learning rate: 0.0000\tLoss: 17.532726\t Accuracy: 139/208 (67%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 43]\n",
            " [ 0  1]]\n",
            "Accuracy: 0.4880952380952381\n",
            "Precision: 0.4819277108433735\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6504065040650406\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 52\t Learning rate: 0.0000\tLoss: 17.482035\t Accuracy: 134/208 (64%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 43]\n",
            " [ 0  1]]\n",
            "Accuracy: 0.4880952380952381\n",
            "Precision: 0.4819277108433735\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6504065040650406\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 53\t Learning rate: 0.0000\tLoss: 17.512758\t Accuracy: 133/208 (64%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 43]\n",
            " [ 0  1]]\n",
            "Accuracy: 0.4880952380952381\n",
            "Precision: 0.4819277108433735\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6504065040650406\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 54\t Learning rate: 0.0000\tLoss: 17.472728\t Accuracy: 126/208 (61%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 43]\n",
            " [ 0  1]]\n",
            "Accuracy: 0.4880952380952381\n",
            "Precision: 0.4819277108433735\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6504065040650406\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 55\t Learning rate: 0.0000\tLoss: 17.448071\t Accuracy: 131/208 (63%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 43]\n",
            " [ 0  1]]\n",
            "Accuracy: 0.4880952380952381\n",
            "Precision: 0.4819277108433735\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6504065040650406\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 56\t Learning rate: 0.0000\tLoss: 17.420676\t Accuracy: 135/208 (65%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 43]\n",
            " [ 0  1]]\n",
            "Accuracy: 0.4880952380952381\n",
            "Precision: 0.4819277108433735\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6504065040650406\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 57\t Learning rate: 0.0000\tLoss: 17.425775\t Accuracy: 133/208 (64%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 43]\n",
            " [ 0  1]]\n",
            "Accuracy: 0.4880952380952381\n",
            "Precision: 0.4819277108433735\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6504065040650406\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 58\t Learning rate: 0.0000\tLoss: 17.377784\t Accuracy: 134/208 (64%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 42]\n",
            " [ 0  2]]\n",
            "Accuracy: 0.5\n",
            "Precision: 0.4878048780487805\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6557377049180327\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 59\t Learning rate: 0.0000\tLoss: 17.389686\t Accuracy: 131/208 (63%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 42]\n",
            " [ 0  2]]\n",
            "Accuracy: 0.5\n",
            "Precision: 0.4878048780487805\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6557377049180327\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 60\t Learning rate: 0.0000\tLoss: 17.430879\t Accuracy: 135/208 (65%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 42]\n",
            " [ 0  2]]\n",
            "Accuracy: 0.5\n",
            "Precision: 0.4878048780487805\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6557377049180327\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 61\t Learning rate: 0.0000\tLoss: 17.463662\t Accuracy: 132/208 (63%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 42]\n",
            " [ 0  2]]\n",
            "Accuracy: 0.5\n",
            "Precision: 0.4878048780487805\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6557377049180327\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 62\t Learning rate: 0.0000\tLoss: 17.310906\t Accuracy: 137/208 (66%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 42]\n",
            " [ 0  2]]\n",
            "Accuracy: 0.5\n",
            "Precision: 0.4878048780487805\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6557377049180327\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 63\t Learning rate: 0.0000\tLoss: 17.281916\t Accuracy: 137/208 (66%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 42]\n",
            " [ 0  2]]\n",
            "Accuracy: 0.5\n",
            "Precision: 0.4878048780487805\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6557377049180327\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 64\t Learning rate: 0.0000\tLoss: 17.279162\t Accuracy: 142/208 (68%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 42]\n",
            " [ 0  2]]\n",
            "Accuracy: 0.5\n",
            "Precision: 0.4878048780487805\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6557377049180327\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 65\t Learning rate: 0.0000\tLoss: 17.291279\t Accuracy: 127/208 (61%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 42]\n",
            " [ 0  2]]\n",
            "Accuracy: 0.5\n",
            "Precision: 0.4878048780487805\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6557377049180327\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 66\t Learning rate: 0.0000\tLoss: 17.217690\t Accuracy: 135/208 (65%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 42]\n",
            " [ 0  2]]\n",
            "Accuracy: 0.5\n",
            "Precision: 0.4878048780487805\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6557377049180327\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 67\t Learning rate: 0.0000\tLoss: 17.223094\t Accuracy: 134/208 (64%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 42]\n",
            " [ 0  2]]\n",
            "Accuracy: 0.5\n",
            "Precision: 0.4878048780487805\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6557377049180327\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 68\t Learning rate: 0.0000\tLoss: 17.174658\t Accuracy: 134/208 (64%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 42]\n",
            " [ 0  2]]\n",
            "Accuracy: 0.5\n",
            "Precision: 0.4878048780487805\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6557377049180327\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 69\t Learning rate: 0.0000\tLoss: 17.145726\t Accuracy: 135/208 (65%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 42]\n",
            " [ 0  2]]\n",
            "Accuracy: 0.5\n",
            "Precision: 0.4878048780487805\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6557377049180327\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 70\t Learning rate: 0.0000\tLoss: 17.140891\t Accuracy: 139/208 (67%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 42]\n",
            " [ 0  2]]\n",
            "Accuracy: 0.5\n",
            "Precision: 0.4878048780487805\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6557377049180327\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 71\t Learning rate: 0.0000\tLoss: 17.109499\t Accuracy: 136/208 (65%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 42]\n",
            " [ 0  2]]\n",
            "Accuracy: 0.5\n",
            "Precision: 0.4878048780487805\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6557377049180327\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 72\t Learning rate: 0.0000\tLoss: 17.112504\t Accuracy: 135/208 (65%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 42]\n",
            " [ 0  2]]\n",
            "Accuracy: 0.5\n",
            "Precision: 0.4878048780487805\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6557377049180327\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 73\t Learning rate: 0.0000\tLoss: 17.070584\t Accuracy: 136/208 (65%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 42]\n",
            " [ 0  2]]\n",
            "Accuracy: 0.5\n",
            "Precision: 0.4878048780487805\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6557377049180327\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 74\t Learning rate: 0.0000\tLoss: 17.078329\t Accuracy: 131/208 (63%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 42]\n",
            " [ 0  2]]\n",
            "Accuracy: 0.5\n",
            "Precision: 0.4878048780487805\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6557377049180327\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 75\t Learning rate: 0.0000\tLoss: 17.017916\t Accuracy: 137/208 (66%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 42]\n",
            " [ 0  2]]\n",
            "Accuracy: 0.5\n",
            "Precision: 0.4878048780487805\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6557377049180327\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 76\t Learning rate: 0.0000\tLoss: 17.014264\t Accuracy: 135/208 (65%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 42]\n",
            " [ 0  2]]\n",
            "Accuracy: 0.5\n",
            "Precision: 0.4878048780487805\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6557377049180327\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 77\t Learning rate: 0.0000\tLoss: 16.999378\t Accuracy: 133/208 (64%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 42]\n",
            " [ 0  2]]\n",
            "Accuracy: 0.5\n",
            "Precision: 0.4878048780487805\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6557377049180327\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 78\t Learning rate: 0.0000\tLoss: 16.921094\t Accuracy: 136/208 (65%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 42]\n",
            " [ 0  2]]\n",
            "Accuracy: 0.5\n",
            "Precision: 0.4878048780487805\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6557377049180327\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 79\t Learning rate: 0.0000\tLoss: 16.900753\t Accuracy: 134/208 (64%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[40 42]\n",
            " [ 0  2]]\n",
            "Accuracy: 0.5\n",
            "Precision: 0.4878048780487805\n",
            "Recall: 1.0\n",
            "F1-Score: 0.6557377049180327\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 80\t Learning rate: 0.0000\tLoss: 16.849619\t Accuracy: 140/208 (67%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[39 42]\n",
            " [ 1  2]]\n",
            "Accuracy: 0.4880952380952381\n",
            "Precision: 0.48148148148148145\n",
            "Recall: 0.975\n",
            "F1-Score: 0.6446280991735537\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 81\t Learning rate: 0.0000\tLoss: 16.819909\t Accuracy: 138/208 (66%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[39 42]\n",
            " [ 1  2]]\n",
            "Accuracy: 0.4880952380952381\n",
            "Precision: 0.48148148148148145\n",
            "Recall: 0.975\n",
            "F1-Score: 0.6446280991735537\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 82\t Learning rate: 0.0000\tLoss: 16.815095\t Accuracy: 139/208 (67%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[39 42]\n",
            " [ 1  2]]\n",
            "Accuracy: 0.4880952380952381\n",
            "Precision: 0.48148148148148145\n",
            "Recall: 0.975\n",
            "F1-Score: 0.6446280991735537\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 83\t Learning rate: 0.0000\tLoss: 16.787792\t Accuracy: 134/208 (64%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[39 41]\n",
            " [ 1  3]]\n",
            "Accuracy: 0.5\n",
            "Precision: 0.4875\n",
            "Recall: 0.975\n",
            "F1-Score: 0.65\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 84\t Learning rate: 0.0000\tLoss: 16.764729\t Accuracy: 139/208 (67%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[39 41]\n",
            " [ 1  3]]\n",
            "Accuracy: 0.5\n",
            "Precision: 0.4875\n",
            "Recall: 0.975\n",
            "F1-Score: 0.65\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 85\t Learning rate: 0.0000\tLoss: 16.663226\t Accuracy: 140/208 (67%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[39 41]\n",
            " [ 1  3]]\n",
            "Accuracy: 0.5\n",
            "Precision: 0.4875\n",
            "Recall: 0.975\n",
            "F1-Score: 0.65\n",
            "\n",
            "=========================================================================================\n",
            "Train Epoch: 86\t Learning rate: 0.0000\tLoss: 16.581352\t Accuracy: 144/208 (69%)\n",
            " \n",
            "Confusion Matrix:\n",
            "[[39 41]\n",
            " [ 1  3]]\n",
            "Accuracy: 0.5\n",
            "Precision: 0.4875\n",
            "Recall: 0.975\n",
            "F1-Score: 0.65\n",
            "\n",
            "=========================================================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-d4da76fe759c>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_idxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mtloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_idxs_tmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_idxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mfold\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-8ec0a511f2e5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, train_idxs)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# 根据梯度更新网络参数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mbatch_idx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# loss.item()能够得到张量中的元素值\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m                             )\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    185\u001b[0m             )\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             adamw(\n\u001b[0m\u001b[1;32m    188\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adamw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlerp_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcapturable\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdifferentiable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `AudioModelChecking.py`\n",
        "Only loads the previously learnt \"BiLSTM_gru_vlad256_256_0\" models and reports the performances"
      ],
      "metadata": {
        "id": "X8ba6rgbfB6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import wave\n",
        "import re\n",
        "import os\n",
        "import tensorflow.compat.v1 as tf\n",
        "import random\n",
        "import itertools\n",
        "# from audio_gru_whole import AudioBiLSTM\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pickle"
      ],
      "metadata": {
        "id": "RnvAO8bsfS-0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self, rnn_layers, dropout, num_classes, audio_hidden_dims, audio_embed_size):\n",
        "        super(BiLSTM, self).__init__()\n",
        "\n",
        "        self.lstm_net_audio = nn.GRU(audio_embed_size, audio_hidden_dims,\n",
        "                                num_layers=rnn_layers, dropout=dropout, batch_first=True)\n",
        "\n",
        "        self.fc_audio = nn.Sequential(\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(audio_hidden_dims, audio_hidden_dims),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(audio_hidden_dims, num_classes),\n",
        "            # nn.ReLU(),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, _ = self.lstm_net_audio(x)\n",
        "        # x = self.bn(x)\n",
        "        x = x.sum(dim=1)\n",
        "        out = self.fc_audio(x)\n",
        "        return out"
      ],
      "metadata": {
        "id": "A6YPZJsdfF7C"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prefix = os.path.abspath(os.path.join(os.getcwd(), \".\"))\n",
        "# audio_features = np.squeeze(np.load(os.path.join(prefix, 'Features/Audio/whole_samples_clf_avid256.npz'))['arr_0'], axis=2)\n",
        "# audio_targets = np.load(os.path.join(prefix, 'Features/Audio/whole_labels_clf_avid256.npz'))['arr_0']\n",
        "\n",
        "audio_features = np.squeeze(np.load(f'{BASELINE_DIR}/Features/AudioWhole/whole_samples_clf_256.npz')['arr_0'], axis=2)\n",
        "audio_targets = np.load(f'{BASELINE_DIR}/Features/AudioWhole/whole_labels_clf_256.npz')['arr_0']\n",
        "\n",
        "audio_dep_idxs = np.where(audio_targets == 1)[0]\n",
        "audio_non_idxs = np.where(audio_targets == 0)[0]"
      ],
      "metadata": {
        "id": "PvgpZHsogHXx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def standard_confusion_matrix(y_test, y_test_pred):\n",
        "    \"\"\"\n",
        "    Make confusion matrix with format:\n",
        "                  -----------\n",
        "                  | TP | FP |\n",
        "                  -----------\n",
        "                  | FN | TN |\n",
        "                  -----------\n",
        "    Parameters\n",
        "    ----------\n",
        "    y_true : ndarray - 1D\n",
        "    y_pred : ndarray - 1D\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    ndarray - 2D\n",
        "    \"\"\"\n",
        "    [[tn, fp], [fn, tp]] = confusion_matrix(y_test, y_test_pred)\n",
        "    return np.array([[tp, fp], [fn, tn]])\n",
        "\n",
        "def model_performance(y_test, y_test_pred_proba):\n",
        "    \"\"\"\n",
        "    Evaluation metrics for network performance.\n",
        "    \"\"\"\n",
        "    # y_test_pred = y_test_pred_proba.data.max(1, keepdim=True)[1]\n",
        "    y_test_pred = y_test_pred_proba\n",
        "\n",
        "    # Computing confusion matrix for test dataset\n",
        "    conf_matrix = standard_confusion_matrix(y_test, y_test_pred)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "    return y_test_pred, conf_matrix"
      ],
      "metadata": {
        "id": "d0N2R13egD3a"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'num_classes': 2,\n",
        "    'dropout': 0.5,\n",
        "    'rnn_layers': 2,\n",
        "    'embedding_size': 256,\n",
        "    'batch_size': 4,\n",
        "    'epochs': 100,\n",
        "    'learning_rate': 1e-5,\n",
        "    'hidden_dims': 256,\n",
        "    'bidirectional': False,\n",
        "    'cuda': False\n",
        "}"
      ],
      "metadata": {
        "id": "I-KBYLpJf-41"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# audio_lstm_model = torch.load(os.path.join(prefix, 'Model/Classification/Audio/BiLSTM_gru_vlad256_256_0.80.pt'))\n",
        "# audio_lstm_model = torch.load(os.path.join(prefix, 'Model/Classification/Audio3/BiLSTM_gru_vlad256_256_0.89.pt'))\n",
        "# audio_lstm_model = torch.load(os.path.join(prefix, 'Model/Classification/Audio2/BiLSTM_gru_vlad256_256_0.65.pt'))\n",
        "\n",
        "# model = BiLSTM(config['rnn_layers'], config['dropout'], config['num_classes'], \\\n",
        "#          config['hidden_dims'], config['embedding_size'])\n",
        "\n",
        "# model_state_dict = {}\n",
        "# model_state_dict['lstm_net_audio.weight_ih_l0'] = audio_lstm_model.state_dict()['lstm_net_audio.weight_ih_l0']\n",
        "# model_state_dict['lstm_net_audio.weight_hh_l0'] = audio_lstm_model.state_dict()['lstm_net_audio.weight_hh_l0']\n",
        "# model_state_dict['lstm_net_audio.bias_ih_l0'] = audio_lstm_model.state_dict()['lstm_net_audio.bias_ih_l0']\n",
        "# model_state_dict['lstm_net_audio.bias_hh_l0'] = audio_lstm_model.state_dict()['lstm_net_audio.bias_hh_l0']\n",
        "\n",
        "# model_state_dict['lstm_net_audio.weight_ih_l1'] = audio_lstm_model.state_dict()['lstm_net_audio.weight_ih_l1']\n",
        "# model_state_dict['lstm_net_audio.weight_hh_l1'] = audio_lstm_model.state_dict()['lstm_net_audio.weight_hh_l1']\n",
        "# model_state_dict['lstm_net_audio.bias_ih_l1'] = audio_lstm_model.state_dict()['lstm_net_audio.bias_ih_l1']\n",
        "# model_state_dict['lstm_net_audio.bias_hh_l1'] = audio_lstm_model.state_dict()['lstm_net_audio.bias_hh_l1']\n",
        "\n",
        "# model_state_dict['fc_audio.1.weight'] = audio_lstm_model.state_dict()['fc_audio.1.weight']\n",
        "# model_state_dict['fc_audio.1.bias'] = audio_lstm_model.state_dict()['fc_audio.1.bias']\n",
        "# model_state_dict['fc_audio.4.weight'] = audio_lstm_model.state_dict()['fc_audio.4.weight']\n",
        "# model_state_dict['fc_audio.4.bias'] = audio_lstm_model.state_dict()['fc_audio.4.bias']\n",
        "# model_state_dict = audio_lstm_model.state_dict()\n",
        "# model.load_state_dict(model_state_dict, strict=False)"
      ],
      "metadata": {
        "id": "B15wRLmygA73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_idxs):\n",
        "    model.eval()\n",
        "    batch_idx = 1\n",
        "    total_loss = 0\n",
        "    pred = torch.empty(config['batch_size'], 1).type(torch.LongTensor)\n",
        "    # X_test = audio_features[test_dep_idxs+test_non_idxs]\n",
        "    # Y_test = audio_targets[test_dep_idxs+test_non_idxs]\n",
        "    X_test = audio_features[test_idxs]\n",
        "    Y_test = audio_targets[test_idxs]\n",
        "    global max_train_acc, max_acc,max_f1\n",
        "    for i in range(0, X_test.shape[0], config['batch_size']):\n",
        "        if i + config['batch_size'] > X_test.shape[0]:\n",
        "            x, y = X_test[i:], Y_test[i:]\n",
        "        else:\n",
        "            x, y = X_test[i:(i+config['batch_size'])], Y_test[i:(i+config['batch_size'])]\n",
        "        if config['cuda']:\n",
        "            x, y = Variable(torch.from_numpy(x).type(torch.FloatTensor), requires_grad=True).cuda(), Variable(torch.from_numpy(y)).cuda()\n",
        "        else:\n",
        "            x, y = Variable(torch.from_numpy(x).type(torch.FloatTensor), requires_grad=True), Variable(torch.from_numpy(y))\n",
        "        with torch.no_grad():\n",
        "            output = model(x.squeeze(2))\n",
        "        pred = torch.cat((pred, output.data.max(1, keepdim=True)[1]))\n",
        "\n",
        "    y_test_pred, conf_matrix = model_performance(Y_test, pred[config['batch_size']:])\n",
        "    print('Calculating additional test metrics...')\n",
        "    accuracy = float(conf_matrix[0][0] + conf_matrix[1][1]) / np.sum(conf_matrix)\n",
        "    precision = float(conf_matrix[0][0]) / (conf_matrix[0][0] + conf_matrix[0][1])\n",
        "    recall = float(conf_matrix[0][0]) / (conf_matrix[0][0] + conf_matrix[1][0])\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "    print(\"Accuracy: {}\".format(accuracy))\n",
        "    print(\"Precision: {}\".format(precision))\n",
        "    print(\"Recall: {}\".format(recall))\n",
        "    print(\"F1-Score: {}\\n\".format(f1_score))\n",
        "    print('='*89)\n",
        "    return precision, recall, f1_score"
      ],
      "metadata": {
        "id": "iBF12dBcf6LJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate(audio_features_test, fuse_targets_test, audio_lstm_model)\n",
        "# evaluate(model)\n",
        "\n",
        "idxs_paths = ['train_idxs_0.63_1.npy', 'train_idxs_0.65_2.npy', 'train_idxs_0.60_3.npy']\n",
        "audio_model_paths = ['BiLSTM_gru_vlad256_256_0.67_1.pt', 'BiLSTM_gru_vlad256_256_0.67_2.pt', 'BiLSTM_gru_vlad256_256_0.63_3.pt']\n",
        "ps, rs, fs = [], [], []\n",
        "for fold in range(3):\n",
        "    train_idxs_tmp = np.load(f'{BASELINE_DIR}/Features/TextWhole/{idxs_paths[fold]}', allow_pickle=True)\n",
        "    test_idxs_tmp = list(set(list(audio_dep_idxs)+list(audio_non_idxs)) - set(train_idxs_tmp))\n",
        "    audio_lstm_model = torch.load(f'{BASELINE_DIR}/Model/ClassificationWhole/Audio/{audio_model_paths[fold]}')\n",
        "\n",
        "    train_idxs, test_idxs = [], []\n",
        "    for idx in train_idxs_tmp:\n",
        "        if idx in audio_dep_idxs:\n",
        "            feat = audio_features[idx]\n",
        "            count = 0\n",
        "            resample_idxs = [0,1,2,3,4,5]\n",
        "            for i in itertools.permutations(feat, feat.shape[0]):\n",
        "                if count in resample_idxs:\n",
        "                    audio_features = np.vstack((audio_features, np.expand_dims(list(i), 0)))\n",
        "                    audio_targets = np.hstack((audio_targets, 1))\n",
        "                    train_idxs.append(len(audio_features)-1)\n",
        "                count += 1\n",
        "        else:\n",
        "            train_idxs.append(idx)\n",
        "\n",
        "    for idx in test_idxs_tmp:\n",
        "        if idx in audio_dep_idxs:\n",
        "            feat = audio_features[idx]\n",
        "            count = 0\n",
        "            # resample_idxs = random.sample(range(6), 4)\n",
        "            resample_idxs = [0,1,4,5]\n",
        "            for i in itertools.permutations(feat, feat.shape[0]):\n",
        "                if count in resample_idxs:\n",
        "                    audio_features = np.vstack((audio_features, np.expand_dims(list(i), 0)))\n",
        "                    audio_targets = np.hstack((audio_targets, 1))\n",
        "                    test_idxs.append(len(audio_features)-1)\n",
        "                count += 1\n",
        "        else:\n",
        "            test_idxs.append(idx)\n",
        "    p, r, f = evaluate(audio_lstm_model, test_idxs)\n",
        "    ps.append(p)\n",
        "    rs.append(r)\n",
        "    fs.append(f)\n",
        "print('precison: {} \\n recall: {} \\n f1 score: {}'.format(np.mean(ps), np.mean(rs), np.mean(fs)))"
      ],
      "metadata": {
        "id": "eIAaXF2hf3fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `AudioTraditionalClassifiers.py`\n",
        "Tries \"DecisionTreeClassifier\", \"LogisticRegression\", \"SVC\", and \"RandomForestClassifier\" on the same folds to compare against the proposed GRU"
      ],
      "metadata": {
        "id": "9bS_G1fWiUKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "u7fEDu6gjbFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_features = np.squeeze(np.load(f'{BASELINE_DIR}/Features/AudioWhole/whole_samples_clf_256.npz')['arr_0'], axis=2)\n",
        "audio_targets = np.load(f'{BASELINE_DIR}/Features/AudioWhole/whole_labels_clf_256.npz')['arr_0']\n",
        "\n",
        "audio_dep_idxs_tmp = np.where(audio_targets == 1)[0]\n",
        "audio_non_idxs = np.where(audio_targets == 0)[0]"
      ],
      "metadata": {
        "id": "5zcUzjFJjc4a"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_performance(y_test, y_test_pred_proba):\n",
        "    \"\"\"\n",
        "    Evaluation metrics for network performance.\n",
        "    \"\"\"\n",
        "#     y_test_pred = y_test_pred_proba.data.max(1, keepdim=True)[1]\n",
        "    y_test_pred = y_test_pred_proba\n",
        "\n",
        "    # Computing confusion matrix for test dataset\n",
        "    conf_matrix = standard_confusion_matrix(y_test, y_test_pred)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "    return y_test_pred, conf_matrix\n",
        "\n",
        "def standard_confusion_matrix(y_test, y_test_pred):\n",
        "    [[tn, fp], [fn, tp]] = confusion_matrix(y_test, y_test_pred)\n",
        "    return np.array([[tp, fp], [fn, tn]])"
      ],
      "metadata": {
        "id": "4eSr9t0Cjfns"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_idxs_tmps = [\n",
        "    np.load(f'{BASELINE_DIR}/Features/TextWhole/train_idxs_0.63_1.npy', allow_pickle=True),\n",
        "    np.load(f'{BASELINE_DIR}/Features/TextWhole/train_idxs_0.65_2.npy', allow_pickle=True),\n",
        "    np.load(f'{BASELINE_DIR}/Features/TextWhole/train_idxs_0.60_3.npy', allow_pickle=True)\n",
        "]\n",
        "precs, recs, f1s = [], [], []\n",
        "for idx_idx, train_idxs_tmp in enumerate(train_idxs_tmps):\n",
        "    test_idxs_tmp = list(set(list(audio_dep_idxs_tmp)+list(audio_non_idxs)) - set(train_idxs_tmp))\n",
        "    train_idxs, test_idxs = [], []\n",
        "    # depression data augmentation\n",
        "    for idx in train_idxs_tmp:\n",
        "        if idx in audio_dep_idxs_tmp:\n",
        "            feat = audio_features[idx]\n",
        "            count = 0\n",
        "            resample_idxs = [0,1,2,3,4,5]\n",
        "            for i in itertools.permutations(feat, feat.shape[0]):\n",
        "                if count in resample_idxs:\n",
        "                    audio_features = np.vstack((audio_features, np.expand_dims(list(i), 0)))\n",
        "                    audio_targets = np.hstack((audio_targets, 1))\n",
        "                    train_idxs.append(len(audio_features)-1)\n",
        "                count += 1\n",
        "        else:\n",
        "            train_idxs.append(idx)\n",
        "\n",
        "    for idx in test_idxs_tmp:\n",
        "        if idx in audio_dep_idxs_tmp:\n",
        "            feat = audio_features[idx]\n",
        "            count = 0\n",
        "            # resample_idxs = random.sample(range(6), 4)\n",
        "            resample_idxs = [0,1,4,5]\n",
        "            for i in itertools.permutations(feat, feat.shape[0]):\n",
        "                if count in resample_idxs:\n",
        "                    audio_features = np.vstack((audio_features, np.expand_dims(list(i), 0)))\n",
        "                    audio_targets = np.hstack((audio_targets, 1))\n",
        "                    test_idxs.append(len(audio_features)-1)\n",
        "                count += 1\n",
        "        else:\n",
        "            test_idxs.append(idx)\n",
        "\n",
        "    X_train = audio_features[train_idxs]\n",
        "    Y_train = audio_targets[train_idxs]\n",
        "    X_test = audio_features[test_idxs]\n",
        "    Y_test = audio_targets[test_idxs]\n",
        "\n",
        "    # Decision Tree\n",
        "    # from sklearn import tree\n",
        "    # clf = tree.DecisionTreeClassifier(max_depth=20)\n",
        "\n",
        "    # svm\n",
        "    # from sklearn.svm import SVC\n",
        "    # clf = SVC(kernel='sigmoid')\n",
        "\n",
        "    # rf\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    clf = RandomForestClassifier(n_estimators=50)\n",
        "\n",
        "    # lr\n",
        "    # from sklearn.linear_model import LogisticRegression\n",
        "    # clf = LogisticRegression(solver='newton-cg')\n",
        "\n",
        "    clf.fit([f.flatten() for f in X_train], Y_train)\n",
        "    pred = clf.predict([f.flatten() for f in X_test])\n",
        "    # clf.fit([f.sum(axis=0) for f in X_train], Y_train)\n",
        "    # pred = clf.predict([f.sum(axis=0) for f in X_test])\n",
        "\n",
        "    y_test_pred, conf_matrix = model_performance(Y_test, pred)\n",
        "\n",
        "    # custom evaluation metrics\n",
        "    print('Calculating additional test metrics...')\n",
        "    accuracy = float(conf_matrix[0][0] + conf_matrix[1][1]) / np.sum(conf_matrix)\n",
        "    precision = float(conf_matrix[0][0]) / (conf_matrix[0][0] + conf_matrix[0][1])\n",
        "    recall = float(conf_matrix[0][0]) / (conf_matrix[0][0] + conf_matrix[1][0])\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "    print(\"Accuracy: {}\".format(accuracy))\n",
        "    print(\"Precision: {}\".format(precision))\n",
        "    print(\"Recall: {}\".format(recall))\n",
        "    print(\"F1-Score: {}\\n\".format(f1_score))\n",
        "    print('='*89)\n",
        "    precs.append(0 if np.isnan(precision) else precision)\n",
        "    recs.append(0 if np.isnan(recall) else recall)\n",
        "    f1s.append(0 if np.isnan(f1_score) else f1_score)\n",
        "    # precs.append(precision)\n",
        "    # recs.append(recall)\n",
        "    # f1s.append(f1_score)\n",
        "print(np.mean(precs), np.mean(recs), np.mean(f1s))"
      ],
      "metadata": {
        "id": "pj2W9P-3iQgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text"
      ],
      "metadata": {
        "id": "O6QGWMhjmBPe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `text_features_whole.py`\n",
        "Tries to extract textual features using \"ELMoForManyLangs\""
      ],
      "metadata": {
        "id": "mNgR526yOhXn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- From the [GitHub repository](https://github.com/HIT-SCIR/ELMoForManyLangs?tab=readme-ov-file) download the model and place in the Google Drive.\n",
        "- If using the latest version of `overrides`, delete the decorator from `/content/ELMoForManyLangs/elmoformanylangs/modules/highway.py`.\n",
        "- Inside `ELMoForManyLangs/zhs.model`, set `\"config_path\"` to `\"/content/ELMoForManyLangs/elmoformanylangs/configs/cnn_50_100_512_4096_sample.json\"`"
      ],
      "metadata": {
        "id": "8FJVQ0HyDoai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install overrides\n",
        "!git clone https://github.com/HIT-SCIR/ELMoForManyLangs.git\n",
        "!python ELMoForManyLangs/setup.py install\n",
        "!pip install overrides==4.1.2"
      ],
      "metadata": {
        "id": "A5WlpvVCoBPp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import wave\n",
        "import librosa\n",
        "import re\n",
        "from tqdm.notebook import trange, tqdm\n",
        "# from allennlp.commands.elmo import ElmoEmbedder\n",
        "import os\n",
        "from ELMoForManyLangs.elmoformanylangs import Embedder\n",
        "# import pkuseg\n",
        "# import thulac\n",
        "# from pyhanlp import HanLP\n",
        "import jieba\n",
        "# seg = pkuseg.pkuseg()\n",
        "# thu1 = thulac.thulac(seg_only=True)"
      ],
      "metadata": {
        "id": "FW2SbfnRCqKt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elmo = Embedder(f'{BASELINE_DIR}/Model/ELMoForManyLangs/zhs.model')\n",
        "topics = ['positive', 'neutral', 'negative']\n",
        "answers = {}\n",
        "text_features = []\n",
        "text_targets = []"
      ],
      "metadata": {
        "id": "QTHnewvSDSbr",
        "outputId": "ecfb9b6d-07ac-41a6-f8f6-eaca231e1835",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:elmoformanylangs:char embedding size: 6169\n",
            "INFO:elmoformanylangs:word embedding size: 71222\n",
            "INFO:elmoformanylangs:Model(\n",
            "  (token_embedder): ConvTokenEmbedder(\n",
            "    (word_emb_layer): EmbeddingLayer(\n",
            "      (embedding): Embedding(71222, 100, padding_idx=3)\n",
            "    )\n",
            "    (char_emb_layer): EmbeddingLayer(\n",
            "      (embedding): Embedding(6169, 50, padding_idx=6166)\n",
            "    )\n",
            "    (convolutions): ModuleList(\n",
            "      (0): Conv1d(50, 32, kernel_size=(1,), stride=(1,))\n",
            "      (1): Conv1d(50, 32, kernel_size=(2,), stride=(1,))\n",
            "      (2): Conv1d(50, 64, kernel_size=(3,), stride=(1,))\n",
            "      (3): Conv1d(50, 128, kernel_size=(4,), stride=(1,))\n",
            "      (4): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
            "      (5): Conv1d(50, 512, kernel_size=(6,), stride=(1,))\n",
            "      (6): Conv1d(50, 1024, kernel_size=(7,), stride=(1,))\n",
            "    )\n",
            "    (highways): Highway(\n",
            "      (_layers): ModuleList(\n",
            "        (0-1): 2 x Linear(in_features=2048, out_features=4096, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (projection): Linear(in_features=2148, out_features=512, bias=True)\n",
            "  )\n",
            "  (encoder): ElmobiLm(\n",
            "    (forward_layer_0): LstmCellWithProjection(\n",
            "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
            "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
            "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
            "    )\n",
            "    (backward_layer_0): LstmCellWithProjection(\n",
            "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
            "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
            "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
            "    )\n",
            "    (forward_layer_1): LstmCellWithProjection(\n",
            "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
            "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
            "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
            "    )\n",
            "    (backward_layer_1): LstmCellWithProjection(\n",
            "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
            "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
            "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(text_features, text_targets, folder):\n",
        "    for index in trange(114):\n",
        "        if os.path.isdir(f'{DATASET_DIR}/{folder}{index+1}'):\n",
        "            answers[index+1] = []\n",
        "            for topic in topics:\n",
        "                with open(f'{DATASET_DIR}/{folder}{index+1}/{topic}.txt' ,'r') as f:\n",
        "                    lines = f.readlines()[0]\n",
        "                    # seg_text = seg.cut(lines)\n",
        "                    # seg_text = thu1.cut(lines)\n",
        "                    # seg_text_iter = HanLP.segment(lines)\n",
        "                    seg_text_iter = jieba.cut(lines, cut_all=False)\n",
        "                    answers[index+1].append([item for item in seg_text_iter])\n",
        "                    # answers[dir].append(seg_text)\n",
        "\n",
        "            with open(f'{DATASET_DIR}/{folder}{index+1}/new_label.txt') as fli:\n",
        "                target = float(fli.readline())\n",
        "            text_targets.append(1 if target >= 53 else 0)\n",
        "            # text_targets.append(target)\n",
        "            text_features.append([np.array(item).mean(axis=0) for item in elmo.sents2elmo(answers[index+1])])"
      ],
      "metadata": {
        "id": "ADuOnO8ImFEn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_features(text_features, text_targets, 't_')\n",
        "extract_features(text_features, text_targets, 'v_')\n",
        "\n",
        "print(\"Saving npz file locally...\")\n",
        "np.savez(f'{BASELINE_DIR}/Features/TextWhole/whole_samples_clf_avg.npz', text_features)\n",
        "np.savez(f'{BASELINE_DIR}/Features/TextWhole/whole_labels_clf_avg.npz', text_targets)"
      ],
      "metadata": {
        "id": "jZVpznh6GGRB",
        "outputId": "be4d9c18-f63b-46c2-93c5-ad6e0bb94c72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "444ac9c047d348a7a743e719d34d5357",
            "69bacb88b3854f6e97ab039a3325b641",
            "23355b514bb5445ea7cc98db021cd983",
            "e8820441c56940cea37d2576066351e1",
            "8b4fea35e89243b4b3ce74e16375bb74",
            "7114c0e18b35411b9996742fa0507283",
            "a8cb1ce9b0ee4960a6a8df991c6e7a03",
            "efc451e52ea54afda02d3a43a454afe6",
            "46e0c7ae81164d808276f1c012bf9b72",
            "969a402499fa445ba4ee86e1b77beab5",
            "1957c7190f824f6b99b6ecd06678335c",
            "9166a6768d6646659927f127514db35f",
            "b5d19865740540edb94a1f0aa2565161",
            "803cf4f39e02434a9c47fb9b3dc88e94",
            "3f5c0ecc39854b1a9e59b9819a1a004f",
            "dfcb3c129bb4474795b5ff39854676d2",
            "4ec9a908a012446ab8b152bba9ccb7ce",
            "a1d540f250754fb2b68a7a583ddc5ac9",
            "88966dffcdb746dd9f9e60a6d547b9f9",
            "408fcd226c45469a944cb52b3ef73b70",
            "9d87ba61bdd146f2b8ef8f63e6a09101",
            "19b039bc15ed4981be05c2663d4a6afb"
          ]
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/114 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "444ac9c047d348a7a743e719d34d5357"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "DEBUG:jieba:Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "DEBUG:jieba:Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.700 seconds.\n",
            "DEBUG:jieba:Loading model cost 0.700 seconds.\n",
            "Prefix dict has been built successfully.\n",
            "DEBUG:jieba:Prefix dict has been built successfully.\n",
            "INFO:elmoformanylangs:1 batches, avg len: 70.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 19.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 33.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 12.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 32.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 109.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 62.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 45.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 150.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 37.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 87.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 21.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 61.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 25.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 39.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 13.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 60.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 28.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 15.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 42.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 25.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 53.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 18.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 26.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 23.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 42.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 14.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 60.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 38.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 28.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 75.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 80.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 60.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 229.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 27.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 69.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 19.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 13.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 113.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 44.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 19.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 86.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 13.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 75.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 15.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 24.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 21.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 81.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 21.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 78.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 11.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 31.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 25.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 20.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 46.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 15.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 24.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 59.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 97.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 23.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 61.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 57.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 11.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 33.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 34.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 20.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 19.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 51.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 38.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 15.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 23.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 31.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 32.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 33.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 40.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 22.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 24.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 69.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 74.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 11.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 10.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 31.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 197.7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/114 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9166a6768d6646659927f127514db35f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:elmoformanylangs:1 batches, avg len: 28.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 17.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 27.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 13.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 84.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 171.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 68.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 25.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 26.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 35.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 58.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 20.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 39.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 28.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 48.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 22.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 14.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 128.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 9.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 55.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 25.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 34.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 12.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 48.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 34.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 22.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 32.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 40.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 9.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 9.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 18.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 48.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 25.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 46.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 51.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 22.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 22.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 7.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 36.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 9.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 81.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 40.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 31.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 71.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 86.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 21.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 12.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 14.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 108.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 22.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 62.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 11.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 77.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 113.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 21.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 7.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 53.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 14.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 80.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 9.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 15.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 24.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 26.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 26.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 38.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 36.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 11.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 17.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 18.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 24.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 27.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 49.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 52.7\n",
            "INFO:elmoformanylangs:1 batches, avg len: 18.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 17.3\n",
            "INFO:elmoformanylangs:1 batches, avg len: 16.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 10.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 16.0\n",
            "INFO:elmoformanylangs:1 batches, avg len: 21.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving npz file locally...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `text_bilstm_whole.py`\n",
        "Trains a BiLSTM on the textual features extracted from each of the 3 folds (using indices)"
      ],
      "metadata": {
        "id": "sREWigzzPHF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import itertools"
      ],
      "metadata": {
        "id": "o6EOF7ofQKn7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_features = np.load(f'{BASELINE_DIR}/Features/TextWhole/whole_samples_clf_avg.npz')['arr_0']\n",
        "text_targets = np.load(f'{BASELINE_DIR}/Features/TextWhole/whole_labels_clf_avg.npz')['arr_0']\n",
        "text_dep_idxs_tmp = np.where(text_targets == 1)[0]\n",
        "text_non_idxs = np.where(text_targets == 0)[0]"
      ],
      "metadata": {
        "id": "hLP5F4gXQW23"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextBiLSTM(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(TextBiLSTM, self).__init__()\n",
        "        self.num_classes = config['num_classes']\n",
        "        self.learning_rate = config['learning_rate']\n",
        "        self.dropout = config['dropout']\n",
        "        self.hidden_dims = config['hidden_dims']\n",
        "        self.rnn_layers = config['rnn_layers']\n",
        "        self.embedding_size = config['embedding_size']\n",
        "        self.bidirectional = config['bidirectional']\n",
        "\n",
        "        self.build_model()\n",
        "        self.init_weight()\n",
        "\n",
        "    def init_weight(net):\n",
        "        for name, param in net.named_parameters():\n",
        "            if 'ln' not in name:\n",
        "                if 'bias' in name:\n",
        "                    nn.init.constant_(param, 0.0)\n",
        "                elif 'weight' in name:\n",
        "                    nn.init.xavier_uniform_(param)\n",
        "\n",
        "    def build_model(self):\n",
        "        # attention layer\n",
        "        self.attention_layer = nn.Sequential(\n",
        "            nn.Linear(self.hidden_dims, self.hidden_dims),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        # self.attention_weights = self.attention_weights.view(self.hidden_dims, 1)\n",
        "\n",
        "        # 双层lstm\n",
        "        self.lstm_net = nn.LSTM(self.embedding_size, self.hidden_dims,\n",
        "                                num_layers=self.rnn_layers, dropout=self.dropout,\n",
        "                                bidirectional=self.bidirectional)\n",
        "\n",
        "        # FC层\n",
        "        # self.fc_out = nn.Linear(self.hidden_dims, self.num_classes)\n",
        "        self.fc_out = nn.Sequential(\n",
        "            # nn.Dropout(self.dropout),\n",
        "            nn.Linear(self.hidden_dims, self.hidden_dims),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(self.dropout),\n",
        "            nn.Linear(self.hidden_dims, self.num_classes),\n",
        "            # nn.ReLU(),\n",
        "            nn.Softmax(dim=1),\n",
        "        )\n",
        "\n",
        "        self.ln1 = nn.LayerNorm(self.embedding_size)\n",
        "        self.ln2 = nn.LayerNorm(self.hidden_dims)\n",
        "\n",
        "\n",
        "    def attention_net_with_w(self, lstm_out, lstm_hidden):\n",
        "        '''\n",
        "        :param lstm_out:    [batch_size, len_seq, n_hidden * 2]\n",
        "        :param lstm_hidden: [batch_size, num_layers * num_directions, n_hidden]\n",
        "        :return: [batch_size, n_hidden]\n",
        "        '''\n",
        "        lstm_tmp_out = torch.chunk(lstm_out, 2, -1)\n",
        "        # h [batch_size, time_step, hidden_dims]\n",
        "        h = lstm_tmp_out[0] + lstm_tmp_out[1]\n",
        "        # h = lstm_out\n",
        "        # [batch_size, num_layers * num_directions, n_hidden]\n",
        "        lstm_hidden = torch.sum(lstm_hidden, dim=1)\n",
        "        # [batch_size, 1, n_hidden]\n",
        "        lstm_hidden = lstm_hidden.unsqueeze(1)\n",
        "        # atten_w [batch_size, 1, hidden_dims]\n",
        "        atten_w = self.attention_layer(lstm_hidden)\n",
        "        # m [batch_size, time_step, hidden_dims]\n",
        "        m = nn.Tanh()(h)\n",
        "        # atten_context [batch_size, 1, time_step]\n",
        "        atten_context = torch.bmm(atten_w, m.transpose(1, 2))\n",
        "        # softmax_w [batch_size, 1, time_step]\n",
        "        softmax_w = F.softmax(atten_context, dim=-1)\n",
        "        # context [batch_size, 1, hidden_dims]\n",
        "        context = torch.bmm(softmax_w, h)\n",
        "        result = context.squeeze(1)\n",
        "        return result\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x : [len_seq, batch_size, embedding_dim]\n",
        "        x = x.permute(1, 0, 2)\n",
        "        # x = self.ln1(x)\n",
        "        output, (final_hidden_state, _) = self.lstm_net(x)\n",
        "        # output : [batch_size, len_seq, n_hidden * 2]\n",
        "        output = output.permute(1, 0, 2)\n",
        "        # final_hidden_state : [batch_size, num_layers * num_directions, n_hidden]\n",
        "        final_hidden_state = final_hidden_state.permute(1, 0, 2)\n",
        "        # final_hidden_state = torch.mean(final_hidden_state, dim=0, keepdim=True)\n",
        "        # atten_out = self.attention_net(output, final_hidden_state)\n",
        "        atten_out = self.attention_net_with_w(output, final_hidden_state)\n",
        "        # atten_out = self.ln2(atten_out)\n",
        "        return self.fc_out(atten_out)"
      ],
      "metadata": {
        "id": "HSFSZuBEP2_h"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save(model, filename):\n",
        "    save_filename = '{}.pt'.format(filename)\n",
        "    torch.save(model, save_filename)\n",
        "    print('Saved as %s' % save_filename)\n",
        "\n",
        "def standard_confusion_matrix(y_test, y_test_pred):\n",
        "    \"\"\"\n",
        "    Make confusion matrix with format:\n",
        "                  -----------\n",
        "                  | TP | FP |\n",
        "                  -----------\n",
        "                  | FN | TN |\n",
        "                  -----------\n",
        "    Parameters\n",
        "    ----------\n",
        "    y_true : ndarray - 1D\n",
        "    y_pred : ndarray - 1D\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    ndarray - 2D\n",
        "    \"\"\"\n",
        "    [[tn, fp], [fn, tp]] = confusion_matrix(y_test, y_test_pred)\n",
        "    return np.array([[tp, fp], [fn, tn]])\n",
        "\n",
        "def model_performance(y_test, y_test_pred_proba):\n",
        "    \"\"\"\n",
        "    Evaluation metrics for network performance.\n",
        "    \"\"\"\n",
        "    y_test_pred = y_test_pred_proba.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    # Computing confusion matrix for test dataset\n",
        "    conf_matrix = standard_confusion_matrix(y_test, y_test_pred)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "    return y_test_pred, conf_matrix\n",
        "\n",
        "def train(epoch, train_idxs):\n",
        "    global lr, train_acc\n",
        "    model.train()\n",
        "    batch_idx = 1\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    X_train = text_features[train_idxs]\n",
        "    Y_train = text_targets[train_idxs]\n",
        "    for i in range(0, X_train.shape[0], config['batch_size']):\n",
        "        if i + config['batch_size'] > X_train.shape[0]:\n",
        "            x, y = X_train[i:], Y_train[i:]\n",
        "        else:\n",
        "            x, y = X_train[i:(i + config['batch_size'])], Y_train[i:(\n",
        "                i + config['batch_size'])]\n",
        "        if config['cuda']:\n",
        "            x, y = Variable(torch.from_numpy(x).type(torch.FloatTensor), requires_grad=True).cuda(), Variable(torch.from_numpy(y)).cuda()\n",
        "        else:\n",
        "            x, y = Variable(torch.from_numpy(x).type(torch.FloatTensor), requires_grad=True), \\\n",
        "                Variable(torch.from_numpy(y))\n",
        "\n",
        "        # 将模型的参数梯度设置为0\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x)\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        #print(pred.shape, y.shape)\n",
        "        correct += pred.eq(y.data.view_as(pred)).cpu().sum()\n",
        "        loss = criterion(output, y)\n",
        "        # 后向传播调整参数\n",
        "        loss.backward()\n",
        "        # 根据梯度更新网络参数\n",
        "        optimizer.step()\n",
        "        batch_idx += 1\n",
        "        # loss.item()能够得到张量中的元素值\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    train_acc = correct\n",
        "    print(\n",
        "        'Train Epoch: {:2d}\\t Learning rate: {:.4f}\\tLoss: {:.6f}\\t Accuracy: {}/{} ({:.0f}%)\\n '\n",
        "        .format(epoch + 1, config['learning_rate'], total_loss, correct,\n",
        "                X_train.shape[0], 100. * correct / X_train.shape[0]))\n",
        "\n",
        "\n",
        "def evaluate(model, test_idxs, fold, train_idxs):\n",
        "    model.eval()\n",
        "    batch_idx = 1\n",
        "    total_loss = 0\n",
        "    global max_f1, max_acc, min_mae, X_test_lens, max_prec, max_rec\n",
        "    pred = np.array([])\n",
        "    with torch.no_grad():\n",
        "        if config['cuda']:\n",
        "            x, y = Variable(torch.from_numpy(text_features[test_idxs]).type(torch.FloatTensor), requires_grad=True).cuda(),\\\n",
        "                Variable(torch.from_numpy(text_targets[test_idxs])).cuda()\n",
        "        else:\n",
        "            x, y = Variable(torch.from_numpy(text_features[test_idxs]).type(torch.FloatTensor), requires_grad=True), \\\n",
        "                Variable(torch.from_numpy(text_targets[test_idxs])).type(torch.LongTensor)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x)\n",
        "        loss = criterion(output, y)\n",
        "        total_loss += loss.item()\n",
        "        y_test_pred, conf_matrix = model_performance(y, output.cpu())\n",
        "        accuracy = float(conf_matrix[0][0] + conf_matrix[1][1]) / np.sum(conf_matrix)\n",
        "        precision = float(conf_matrix[0][0]) / (conf_matrix[0][0] + conf_matrix[0][1])\n",
        "        recall = float(conf_matrix[0][0]) / (conf_matrix[0][0] + conf_matrix[1][0])\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "        print(\"Accuracy: {}\".format(accuracy))\n",
        "        print(\"Precision: {}\".format(precision))\n",
        "        print(\"Recall: {}\".format(recall))\n",
        "        print(\"F1-Score: {}\\n\".format(f1_score))\n",
        "        print('=' * 89)\n",
        "\n",
        "        if max_f1 <= f1_score and train_acc > len(train_idxs)*0.9 and f1_score > 0.5:\n",
        "            max_f1 = f1_score\n",
        "            max_acc = accuracy\n",
        "            max_rec = recall\n",
        "            max_prec = precision\n",
        "            save(model, f\"{BASELINE_DIR}/Model/ClassificationWhole/Text/BiLSTM_{config['hidden_dims']}_{max_f1:.2f}_{fold}\")\n",
        "            print('*' * 64)\n",
        "            print('model saved: f1: {}\\tacc: {}'.format(max_f1, max_acc))\n",
        "            print('*' * 64)\n",
        "\n",
        "    return total_loss\n",
        "\n",
        "def get_param_group(model):\n",
        "    nd_list = []\n",
        "    param_list = []\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'ln' in name:\n",
        "            nd_list.append(param)\n",
        "        else:\n",
        "            param_list.append(param)\n",
        "    return [{'params': param_list, 'weight_decay': 1e-5}, {'params': nd_list, 'weight_decay': 0}]"
      ],
      "metadata": {
        "id": "7X9vago7QdvL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'num_classes': 2,\n",
        "    'dropout': 0.5,\n",
        "    'rnn_layers': 2,\n",
        "    'embedding_size': 1024,\n",
        "    'batch_size': 4,\n",
        "    'epochs': 150,\n",
        "    'learning_rate': 1e-5,\n",
        "    'hidden_dims': 128,\n",
        "    'bidirectional': True,\n",
        "    'cuda': False,\n",
        "}"
      ],
      "metadata": {
        "id": "9MFXfTnbQpln"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_idxs_tmps = [\n",
        "    np.load(f'{BASELINE_DIR}/Features/TextWhole/train_idxs_0.63_1.npy', allow_pickle=True),\n",
        "    np.load(f'{BASELINE_DIR}/Features/TextWhole/train_idxs_0.60_2.npy', allow_pickle=True),\n",
        "    np.load(f'{BASELINE_DIR}/Features/TextWhole/train_idxs_0.60_3.npy', allow_pickle=True)\n",
        "]\n",
        "fold = 1\n",
        "\n",
        "for idx_idx, train_idxs_tmp in enumerate(train_idxs_tmps):\n",
        "    # if idx_idx != 2:\n",
        "    #     continue\n",
        "    test_idxs_tmp = list(set(list(text_dep_idxs_tmp)+list(text_non_idxs)) - set(train_idxs_tmp))\n",
        "    train_idxs, test_idxs = [], []\n",
        "    # depression data augmentation\n",
        "    for idx in train_idxs_tmp:\n",
        "        if idx in text_dep_idxs_tmp:\n",
        "            feat = text_features[idx]\n",
        "            count = 0\n",
        "            resample_idxs = [0,1,2,3,4,5]\n",
        "            for i in itertools.permutations(feat, feat.shape[0]):\n",
        "                if count in resample_idxs:\n",
        "                    text_features = np.vstack((text_features, np.expand_dims(list(i), 0)))\n",
        "                    text_targets = np.hstack((text_targets, 1))\n",
        "                    train_idxs.append(len(text_features)-1)\n",
        "                count += 1\n",
        "        else:\n",
        "            train_idxs.append(idx)\n",
        "\n",
        "    for idx in test_idxs_tmp:\n",
        "        if idx in text_dep_idxs_tmp:\n",
        "            feat = text_features[idx]\n",
        "            count = 0\n",
        "            # resample_idxs = random.sample(range(6), 4)\n",
        "            resample_idxs = [0,1,4,5]\n",
        "            for i in itertools.permutations(feat, feat.shape[0]):\n",
        "                if count in resample_idxs:\n",
        "                    text_features = np.vstack((text_features, np.expand_dims(list(i), 0)))\n",
        "                    text_targets = np.hstack((text_targets, 1))\n",
        "                    test_idxs.append(len(text_features)-1)\n",
        "                count += 1\n",
        "        else:\n",
        "            test_idxs.append(idx)\n",
        "\n",
        "    model = TextBiLSTM(config)\n",
        "\n",
        "    param_group = get_param_group(model)\n",
        "    optimizer = optim.AdamW(param_group, lr=config['learning_rate'])\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    max_f1 = -1\n",
        "    max_acc = -1\n",
        "    max_rec = -1\n",
        "    max_prec = -1\n",
        "    train_acc = -1\n",
        "\n",
        "    for ep in range(1, config['epochs']):\n",
        "        train(ep, train_idxs)\n",
        "        tloss = evaluate(model, test_idxs, fold, train_idxs)\n",
        "    fold += 1"
      ],
      "metadata": {
        "id": "_UQEXMgOQbX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `TextModelChecking.py`\n",
        "Just evaluates some \"BiLSTM_128_0\" models on each of the 3 folds"
      ],
      "metadata": {
        "id": "inM0bpczYYLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import wave\n",
        "import re\n",
        "import os\n",
        "import tensorflow.compat.v1 as tf\n",
        "import random\n",
        "import itertools\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pickle"
      ],
      "metadata": {
        "id": "C4-2I54rYoi_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prefix = os.path.abspath(os.path.join(os.getcwd(), \".\"))\n",
        "# text_features = np.load(os.path.join(prefix, 'Features/Text/whole_samples_clf_avg.npz'))['arr_0']\n",
        "# text_targets = np.load(os.path.join(prefix, 'Features/Text/whole_labels_clf_avg.npz'))['arr_0']\n",
        "\n",
        "# audio_dep_idxs = np.where(text_targets == 1)[0]\n",
        "# audio_non_idxs = np.where(text_targets == 0)[0]\n",
        "# # train_dep_idxs_tmp = np.load(os.path.join(prefix, 'Features/Text/train_dep_idxs_0.80.npy'), allow_pickle=True)\n",
        "# # train_non_idxs = list(np.load(os.path.join(prefix, 'Features/Text/train_non_idxs_0.80.npy'), allow_pickle=True))\n",
        "# # train_dep_idxs_tmp = np.load(os.path.join(prefix, 'Features/Text/train_dep_idxs_0.65_2.npy'), allow_pickle=True)\n",
        "# # train_non_idxs = list(np.load(os.path.join(prefix, 'Features/Text/train_non_idxs_0.65_2.npy'), allow_pickle=True))\n",
        "# train_dep_idxs_tmp = np.load(os.path.join(prefix, 'Features/Text/train_dep_idxs_0.89_3.npy'), allow_pickle=True)\n",
        "# train_non_idxs = list(np.load(os.path.join(prefix, 'Features/Text/train_non_idxs_0.89_3.npy'), allow_pickle=True))\n",
        "\n",
        "# test_dep_idxs_tmp = list(set(audio_dep_idxs) - set(train_dep_idxs_tmp))\n",
        "# test_non_idxs = list(set(audio_non_idxs) - set(train_non_idxs))\n",
        "\n",
        "text_features = np.load(f'{BASELINE_DIR}/Features/TextWhole/whole_samples_clf_avg.npz')['arr_0']\n",
        "text_targets = np.load(f'{BASELINE_DIR}/Features/TextWhole/whole_labels_clf_avg.npz')['arr_0']\n",
        "text_dep_idxs_tmp = np.where(text_targets == 1)[0]\n",
        "text_non_idxs = np.where(text_targets == 0)[0]"
      ],
      "metadata": {
        "id": "dxva-cz4a3ZV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # training data augmentation\n",
        "# train_dep_idxs = []\n",
        "# for idx in train_dep_idxs_tmp:\n",
        "#     feat = text_features[idx]\n",
        "#     for i in itertools.permutations(feat, feat.shape[0]):\n",
        "#         text_features = np.vstack((text_features, np.expand_dims(list(i), 0)))\n",
        "#         text_targets = np.hstack((text_targets, 1))\n",
        "#         train_dep_idxs.append(len(text_features)-1)\n",
        "\n",
        "#         text_features = np.vstack((text_features, np.expand_dims(list(i), 0)))\n",
        "#         text_targets = np.hstack((text_targets, 1))\n",
        "#         train_dep_idxs.append(len(text_features)-1)\n",
        "\n",
        "# # test data augmentation\n",
        "# test_dep_idxs = []\n",
        "# for idx in test_dep_idxs_tmp:\n",
        "#     feat = text_features[idx]\n",
        "#     for i in itertools.permutations(feat, feat.shape[0]):\n",
        "#         text_features = np.vstack((text_features, np.expand_dims(list(i), 0)))\n",
        "#         text_targets = np.hstack((text_targets, 1))\n",
        "#         test_dep_idxs.append(len(text_features)-1)"
      ],
      "metadata": {
        "id": "jFm-YROQbAnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def standard_confusion_matrix(y_test, y_test_pred):\n",
        "    \"\"\"\n",
        "    Make confusion matrix with format:\n",
        "                  -----------\n",
        "                  | TP | FP |\n",
        "                  -----------\n",
        "                  | FN | TN |\n",
        "                  -----------\n",
        "    Parameters\n",
        "    ----------\n",
        "    y_true : ndarray - 1D\n",
        "    y_pred : ndarray - 1D\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    ndarray - 2D\n",
        "    \"\"\"\n",
        "    [[tn, fp], [fn, tp]] = confusion_matrix(y_test, y_test_pred)\n",
        "    return np.array([[tp, fp], [fn, tn]])\n",
        "\n",
        "\n",
        "def model_performance(y_test, y_test_pred_proba):\n",
        "    \"\"\"\n",
        "    Evaluation metrics for network performance.\n",
        "    \"\"\"\n",
        "    # y_test_pred = y_test_pred_proba.data.max(1, keepdim=True)[1]\n",
        "    y_test_pred = y_test_pred_proba\n",
        "\n",
        "    # Computing confusion matrix for test dataset\n",
        "    conf_matrix = standard_confusion_matrix(y_test, y_test_pred)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "    return y_test_pred, conf_matrix"
      ],
      "metadata": {
        "id": "AjNe23o_bERs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextBiLSTM(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(TextBiLSTM, self).__init__()\n",
        "        self.num_classes = config['num_classes']\n",
        "        self.learning_rate = config['learning_rate']\n",
        "        self.dropout = config['dropout']\n",
        "        self.hidden_dims = config['hidden_dims']\n",
        "        self.rnn_layers = config['rnn_layers']\n",
        "        self.embedding_size = config['embedding_size']\n",
        "        self.bidirectional = config['bidirectional']\n",
        "\n",
        "        self.build_model()\n",
        "        self.init_weight()\n",
        "\n",
        "    def init_weight(net):\n",
        "        for name, param in net.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                nn.init.constant_(param, 0.0)\n",
        "            elif 'weight' in name:\n",
        "                nn.init.xavier_uniform_(param)\n",
        "\n",
        "    def build_model(self):\n",
        "        # attention layer\n",
        "        self.attention_layer = nn.Sequential(\n",
        "            nn.Linear(self.hidden_dims, self.hidden_dims),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        # self.attention_weights = self.attention_weights.view(self.hidden_dims, 1)\n",
        "\n",
        "        # 双层lstm\n",
        "        self.lstm_net = nn.LSTM(self.embedding_size, self.hidden_dims,\n",
        "                                num_layers=self.rnn_layers, dropout=self.dropout,\n",
        "                                bidirectional=self.bidirectional)\n",
        "\n",
        "        # self.init_weight()\n",
        "\n",
        "        # FC层\n",
        "        # self.fc_out = nn.Linear(self.hidden_dims, self.num_classes)\n",
        "        self.fc_out = nn.Sequential(\n",
        "            nn.Dropout(self.dropout),\n",
        "            nn.Linear(self.hidden_dims, self.hidden_dims),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(self.dropout),\n",
        "            nn.Linear(self.hidden_dims, self.num_classes),\n",
        "            # nn.ReLU(),\n",
        "            nn.Softmax(dim=1),\n",
        "        )\n",
        "\n",
        "    def attention_net_with_w(self, lstm_out, lstm_hidden):\n",
        "        '''\n",
        "        :param lstm_out:    [batch_size, len_seq, n_hidden * 2]\n",
        "        :param lstm_hidden: [batch_size, num_layers * num_directions, n_hidden]\n",
        "        :return: [batch_size, n_hidden]\n",
        "        '''\n",
        "        lstm_tmp_out = torch.chunk(lstm_out, 2, -1)\n",
        "        # h [batch_size, time_step, hidden_dims]\n",
        "        h = lstm_tmp_out[0] + lstm_tmp_out[1]\n",
        "        # h = lstm_out\n",
        "        # [batch_size, num_layers * num_directions, n_hidden]\n",
        "        lstm_hidden = torch.sum(lstm_hidden, dim=1)\n",
        "        # [batch_size, 1, n_hidden]\n",
        "        lstm_hidden = lstm_hidden.unsqueeze(1)\n",
        "        # atten_w [batch_size, 1, hidden_dims]\n",
        "        atten_w = self.attention_layer(lstm_hidden)\n",
        "        # m [batch_size, time_step, hidden_dims]\n",
        "        m = nn.Tanh()(h)\n",
        "        # atten_context [batch_size, 1, time_step]\n",
        "        atten_context = torch.bmm(atten_w, m.transpose(1, 2))\n",
        "        # softmax_w [batch_size, 1, time_step]\n",
        "        softmax_w = F.softmax(atten_context, dim=-1)\n",
        "        # context [batch_size, 1, hidden_dims]\n",
        "        context = torch.bmm(softmax_w, h)\n",
        "        result = context.squeeze(1)\n",
        "        return result\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # x : [len_seq, batch_size, embedding_dim]\n",
        "        x = x.permute(1, 0, 2)\n",
        "        output, (final_hidden_state, final_cell_state) = self.lstm_net(x)\n",
        "        # output : [batch_size, len_seq, n_hidden * 2]\n",
        "        output = output.permute(1, 0, 2)\n",
        "        # final_hidden_state : [batch_size, num_layers * num_directions, n_hidden]\n",
        "        final_hidden_state = final_hidden_state.permute(1, 0, 2)\n",
        "        # final_hidden_state = torch.mean(final_hidden_state, dim=0, keepdim=True)\n",
        "        # atten_out = self.attention_net(output, final_hidden_state)\n",
        "        atten_out = self.attention_net_with_w(output, final_hidden_state)\n",
        "        return self.fc_out(atten_out)\n",
        "\n",
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self, rnn_layers, dropout, num_classes, text_hidden_dims, text_embed_size):\n",
        "        super(BiLSTM, self).__init__()\n",
        "\n",
        "        self.text_embed_size = text_embed_size\n",
        "        self.text_hidden_dims = text_hidden_dims\n",
        "        self.rnn_layers = rnn_layers\n",
        "        self.dropout = dropout\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # attention layer\n",
        "        self.attention_layer = nn.Sequential(\n",
        "            nn.Linear(self.text_hidden_dims, self.text_hidden_dims),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # 双层lstm\n",
        "        self.lstm_net = nn.LSTM(self.text_embed_size, self.text_hidden_dims,\n",
        "                                num_layers=self.rnn_layers, dropout=self.dropout,\n",
        "                                bidirectional=True)\n",
        "        # FC层\n",
        "        self.fc_out = nn.Sequential(\n",
        "            nn.Dropout(self.dropout),\n",
        "            nn.Linear(self.text_hidden_dims, self.text_hidden_dims),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(self.dropout),\n",
        "            nn.Linear(self.text_hidden_dims, self.num_classes),\n",
        "            # nn.ReLU(),\n",
        "            nn.Softmax(dim=1),\n",
        "        )\n",
        "\n",
        "    def attention_net_with_w(self, lstm_out, lstm_hidden):\n",
        "        '''\n",
        "        :param lstm_out:    [batch_size, len_seq, n_hidden * 2]\n",
        "        :param lstm_hidden: [batch_size, num_layers * num_directions, n_hidden]\n",
        "        :return: [batch_size, n_hidden]\n",
        "        '''\n",
        "        lstm_tmp_out = torch.chunk(lstm_out, 2, -1)\n",
        "        # h [batch_size, time_step, hidden_dims]\n",
        "        h = lstm_tmp_out[0] + lstm_tmp_out[1]\n",
        "        # [batch_size, num_layers * num_directions, n_hidden]\n",
        "        lstm_hidden = torch.sum(lstm_hidden, dim=1)\n",
        "        # [batch_size, 1, n_hidden]\n",
        "        lstm_hidden = lstm_hidden.unsqueeze(1)\n",
        "        # atten_w [batch_size, 1, hidden_dims]\n",
        "        atten_w = self.attention_layer(lstm_hidden)\n",
        "        # m [batch_size, time_step, hidden_dims]\n",
        "        m = nn.Tanh()(h)\n",
        "        # atten_context [batch_size, 1, time_step]\n",
        "        atten_context = torch.bmm(atten_w, m.transpose(1, 2))\n",
        "        # softmax_w [batch_size, 1, time_step]\n",
        "        softmax_w = F.softmax(atten_context, dim=-1)\n",
        "        # context [batch_size, 1, hidden_dims]\n",
        "        context = torch.bmm(softmax_w, h)\n",
        "        result = context.squeeze(1)\n",
        "        return result\n",
        "\n",
        "    def forward(self, x_text):\n",
        "        # x : [len_seq, batch_size, embedding_dim]\n",
        "        x_text = x_text.permute(1, 0, 2)\n",
        "        output, (final_hidden_state, _) = self.lstm_net(x_text)\n",
        "        # output : [batch_size, len_seq, n_hidden * 2]\n",
        "        output = output.permute(1, 0, 2)\n",
        "        # final_hidden_state : [batch_size, num_layers * num_directions, n_hidden]\n",
        "        final_hidden_state = final_hidden_state.permute(1, 0, 2)\n",
        "        # final_hidden_state = torch.mean(final_hidden_state, dim=0, keepdim=True)\n",
        "        # atten_out = self.attention_net(output, final_hidden_state)\n",
        "        atten_out = self.attention_net_with_w(output, final_hidden_state)\n",
        "        text_feature = self.fc_out(atten_out)\n",
        "\n",
        "        return text_feature"
      ],
      "metadata": {
        "id": "2uxKQ5hJbKrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_idxs):\n",
        "    model.eval()\n",
        "    batch_idx = 1\n",
        "    total_loss = 0\n",
        "    pred = torch.empty(config['batch_size'], 1).type(torch.LongTensor)\n",
        "    # X_test = text_features[test_dep_idxs+test_non_idxs]\n",
        "    # Y_test = text_targets[test_dep_idxs+test_non_idxs]\n",
        "    X_test = text_features[test_idxs]\n",
        "    Y_test = text_targets[test_idxs]\n",
        "    global max_train_acc, max_acc, max_f1\n",
        "    for i in range(0, X_test.shape[0], config['batch_size']):\n",
        "        if i + config['batch_size'] > X_test.shape[0]:\n",
        "            x, y = X_test[i:], Y_test[i:]\n",
        "        else:\n",
        "            x, y = X_test[i:(i+config['batch_size'])\n",
        "                          ], Y_test[i:(i+config['batch_size'])]\n",
        "        if config['cuda']:\n",
        "            x, y = Variable(torch.from_numpy(x).type(torch.FloatTensor), requires_grad=True).cuda(\n",
        "            ),             Variable(torch.from_numpy(y)).cuda()\n",
        "        else:\n",
        "            x, y = Variable(torch.from_numpy(x).type(\n",
        "                torch.FloatTensor), requires_grad=True), Variable(torch.from_numpy(y))\n",
        "        with torch.no_grad():\n",
        "            output = model(x.squeeze(2))\n",
        "        pred = torch.cat((pred, output.data.max(1, keepdim=True)[1]))\n",
        "\n",
        "    y_test_pred, conf_matrix = model_performance(\n",
        "        Y_test, pred[config['batch_size']:])\n",
        "    print('Calculating additional test metrics...')\n",
        "    accuracy = float(conf_matrix[0][0] +\n",
        "                     conf_matrix[1][1]) / np.sum(conf_matrix)\n",
        "    precision = float(conf_matrix[0][0]) / \\\n",
        "        (conf_matrix[0][0] + conf_matrix[0][1])\n",
        "    recall = float(conf_matrix[0][0]) / (conf_matrix[0][0] + conf_matrix[1][0])\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "    print(\"Accuracy: {}\".format(accuracy))\n",
        "    print(\"Precision: {}\".format(precision))\n",
        "    print(\"Recall: {}\".format(recall))\n",
        "    print(\"F1-Score: {}\\n\".format(f1_score))\n",
        "    print('='*89)\n",
        "    return precision, recall, f1_score"
      ],
      "metadata": {
        "id": "msHHPK22bolF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_model_paths = ['BiLSTM_128_0.64_1.pt', 'BiLSTM_128_0.66_2.pt', 'BiLSTM_128_0.66_3.pt']\n",
        "train_idxs_tmps = [\n",
        "    np.load(f'{BASELINE_DIR}/Features/TextWhole/train_idxs_0.63_1.npy', allow_pickle=True),\n",
        "    np.load(f'{BASELINE_DIR}/Features/TextWhole/train_idxs_0.60_2.npy', allow_pickle=True),\n",
        "    np.load(f'{BASELINE_DIR}/Features/TextWhole/train_idxs_0.60_3.npy', allow_pickle=True)\n",
        "]\n",
        "resample_idxs = [0, 1, 2, 3, 4, 5]\n",
        "fold = 1\n",
        "ps, rs, fs = [], [], []\n",
        "for idx_i, train_idxs_tmp in enumerate(train_idxs_tmps):\n",
        "    test_idxs_tmp = list(\n",
        "        set(list(text_dep_idxs_tmp)+list(text_non_idxs)) - set(train_idxs_tmp))\n",
        "    train_idxs, test_idxs = [], []\n",
        "    # depression data augmentation\n",
        "    for idx in train_idxs_tmp:\n",
        "        if idx in text_dep_idxs_tmp:\n",
        "            feat = text_features[idx]\n",
        "            count = 0\n",
        "            for i in itertools.permutations(feat, feat.shape[0]):\n",
        "                if count in resample_idxs:\n",
        "                    text_features = np.vstack(\n",
        "                        (text_features, np.expand_dims(list(i), 0)))\n",
        "                    text_targets = np.hstack((text_targets, 1))\n",
        "                    train_idxs.append(len(text_features)-1)\n",
        "                count += 1\n",
        "        else:\n",
        "            train_idxs.append(idx)\n",
        "\n",
        "    for idx in test_idxs_tmp:\n",
        "        if idx in text_dep_idxs_tmp:\n",
        "            feat = text_features[idx]\n",
        "            count = 0\n",
        "            # resample_idxs = random.sample(range(6), 4)\n",
        "            resample_idxs = [0,1,4,5]\n",
        "            for i in itertools.permutations(feat, feat.shape[0]):\n",
        "                if count in resample_idxs:\n",
        "                    text_features = np.vstack(\n",
        "                        (text_features, np.expand_dims(list(i), 0)))\n",
        "                    text_targets = np.hstack((text_targets, 1))\n",
        "                    test_idxs.append(len(text_features)-1)\n",
        "                count += 1\n",
        "        else:\n",
        "            test_idxs.append(idx)\n",
        "\n",
        "    config = {\n",
        "        'num_classes': 2,\n",
        "        'dropout': 0.5,\n",
        "        'rnn_layers': 2,\n",
        "        'embedding_size': 1024,\n",
        "        'batch_size': 4,\n",
        "        'epochs': 100,\n",
        "        'learning_rate': 2e-5,\n",
        "        'hidden_dims': 128,\n",
        "        'bidirectional': True,\n",
        "        'cuda': False,\n",
        "    }\n",
        "\n",
        "    text_lstm_model = torch.load(os.path.join(\n",
        "        prefix, 'Model/ClassificationWhole/Text/{}'.format(text_model_paths[idx_i])))\n",
        "\n",
        "    model = BiLSTM(config['rnn_layers'], config['dropout'], config['num_classes'],\n",
        "                   config['hidden_dims'], config['embedding_size'])\n",
        "\n",
        "    # model_state_dict = {}\n",
        "    # model_state_dict['lstm_net_audio.weight_ih_l0'] = audio_lstm_model.state_dict()['lstm_net_audio.weight_ih_l0']\n",
        "    # model_state_dict['lstm_net_audio.weight_hh_l0'] = audio_lstm_model.state_dict()['lstm_net_audio.weight_hh_l0']\n",
        "    # model_state_dict['lstm_net_audio.bias_ih_l0'] = audio_lstm_model.state_dict()['lstm_net_audio.bias_ih_l0']\n",
        "    # model_state_dict['lstm_net_audio.bias_hh_l0'] = audio_lstm_model.state_dict()['lstm_net_audio.bias_hh_l0']\n",
        "\n",
        "    # model_state_dict['lstm_net_audio.weight_ih_l1'] = audio_lstm_model.state_dict()['lstm_net_audio.weight_ih_l1']\n",
        "    # model_state_dict['lstm_net_audio.weight_hh_l1'] = audio_lstm_model.state_dict()['lstm_net_audio.weight_hh_l1']\n",
        "    # model_state_dict['lstm_net_audio.bias_ih_l1'] = audio_lstm_model.state_dict()['lstm_net_audio.bias_ih_l1']\n",
        "    # model_state_dict['lstm_net_audio.bias_hh_l1'] = audio_lstm_model.state_dict()['lstm_net_audio.bias_hh_l1']\n",
        "\n",
        "    # model_state_dict['fc_audio.1.weight'] = audio_lstm_model.state_dict()['fc_audio.1.weight']\n",
        "    # model_state_dict['fc_audio.1.bias'] = audio_lstm_model.state_dict()['fc_audio.1.bias']\n",
        "    # model_state_dict['fc_audio.4.weight'] = audio_lstm_model.state_dict()['fc_audio.4.weight']\n",
        "    # model_state_dict['fc_audio.4.bias'] = audio_lstm_model.state_dict()['fc_audio.4.bias']\n",
        "    # model_state_dict = text_lstm_model.state_dict()\n",
        "    # model.load_state_dict(model_state_dict)\n",
        "\n",
        "    # evaluate(text_features_test, fuse_targets_test, audio_lstm_model)\n",
        "    # evaluate(model, test_idxs)\n",
        "\n",
        "    p, r, f = evaluate(text_lstm_model, test_idxs)\n",
        "    ps.append(p)\n",
        "    rs.append(r)\n",
        "    fs.append(f)\n",
        "print('precison: {} \\n recall: {} \\n f1 score: {}'.format(np.mean(ps), np.mean(rs), np.mean(fs)))"
      ],
      "metadata": {
        "id": "7IZUvRj6YcLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `TextTraditionalClassifiers.py`\n",
        "Tries \"DecisionTreeClassifier\", \"LogisticRegression\", \"SVC\", and \"RandomForestClassifier\" on the same folds to compare against the proposed BiLSTM"
      ],
      "metadata": {
        "id": "zDvmTNjRcHVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "W4GT7UE5dIs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_features = np.load(f'{BASELINE_DIR}/Features/TextWhole/whole_samples_clf_avg.npz')['arr_0']\n",
        "text_targets = np.load(f'{BASELINE_DIR}/Features/TextWhole/whole_labels_clf_avg.npz')['arr_0']\n",
        "\n",
        "text_dep_idxs_tmp = np.where(text_targets == 1)[0]\n",
        "text_non_idxs = np.where(text_targets == 0)[0]"
      ],
      "metadata": {
        "id": "HsgIqPRMdXUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_performance(y_test, y_test_pred_proba):\n",
        "    \"\"\"\n",
        "    Evaluation metrics for network performance.\n",
        "    \"\"\"\n",
        "#     y_test_pred = y_test_pred_proba.data.max(1, keepdim=True)[1]\n",
        "    y_test_pred = y_test_pred_proba\n",
        "\n",
        "    # Computing confusion matrix for test dataset\n",
        "    conf_matrix = standard_confusion_matrix(y_test, y_test_pred)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "    return y_test_pred, conf_matrix\n",
        "\n",
        "def standard_confusion_matrix(y_test, y_test_pred):\n",
        "    [[tn, fp], [fn, tp]] = confusion_matrix(y_test, y_test_pred)\n",
        "    return np.array([[tp, fp], [fn, tn]])"
      ],
      "metadata": {
        "id": "3EscJ7XndkzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_idxs_tmps = [\n",
        "    np.load(f'{BASELINE_DIR}/Features/TextWhole/train_idxs_0.63_1.npy', allow_pickle=True),\n",
        "    np.load(f'{BASELINE_DIR}/Features/TextWhole/train_idxs_0.65_2.npy', allow_pickle=True),\n",
        "    np.load(f'{BASELINE_DIR}/Features/TextWhole/train_idxs_0.60_3.npy', allow_pickle=True)\n",
        "]\n",
        "precs, recs, f1s = [], [], []\n",
        "\n",
        "for idx_idx, train_idxs_tmp in enumerate(train_idxs_tmps):\n",
        "    test_idxs_tmp = list(set(list(text_dep_idxs_tmp)+list(text_non_idxs)) - set(train_idxs_tmp))\n",
        "    train_idxs, test_idxs = [], []\n",
        "\n",
        "    # depression data augmentation\n",
        "    for idx in train_idxs_tmp:\n",
        "        if idx in text_dep_idxs_tmp:\n",
        "            feat = text_features[idx]\n",
        "            count = 0\n",
        "            resample_idxs = [0,1,2,3,4,5]\n",
        "            for i in itertools.permutations(feat, feat.shape[0]):\n",
        "                if count in resample_idxs:\n",
        "                    text_features = np.vstack((text_features, np.expand_dims(list(i), 0)))\n",
        "                    text_targets = np.hstack((text_targets, 1))\n",
        "                    train_idxs.append(len(text_features)-1)\n",
        "                count += 1\n",
        "        else:\n",
        "            train_idxs.append(idx)\n",
        "\n",
        "    for idx in test_idxs_tmp:\n",
        "        if idx in text_dep_idxs_tmp:\n",
        "            feat = text_features[idx]\n",
        "            count = 0\n",
        "            # resample_idxs = random.sample(range(6), 4)\n",
        "            resample_idxs = [0,1,4,5]\n",
        "            for i in itertools.permutations(feat, feat.shape[0]):\n",
        "                if count in resample_idxs:\n",
        "                    text_features = np.vstack((text_features, np.expand_dims(list(i), 0)))\n",
        "                    text_targets = np.hstack((text_targets, 1))\n",
        "                    test_idxs.append(len(text_features)-1)\n",
        "                count += 1\n",
        "        else:\n",
        "            test_idxs.append(idx)\n",
        "    # train_idxs = train_idxs_tmp\n",
        "    # test_idxs = test_idxs_tmp\n",
        "\n",
        "    X_train = text_features[train_idxs]\n",
        "    Y_train = text_targets[train_idxs]\n",
        "    X_test = text_features[test_idxs]\n",
        "    Y_test = text_targets[test_idxs]\n",
        "\n",
        "    # Decision Tree\n",
        "    from sklearn import tree\n",
        "    clf = tree.DecisionTreeClassifier(max_depth=20)\n",
        "\n",
        "    # svm\n",
        "    # from sklearn.svm import SVC\n",
        "    # clf = SVC(kernel='rbf', gamma='auto')\n",
        "\n",
        "    # rf\n",
        "    # from sklearn.ensemble import RandomForestClassifier\n",
        "    # clf = RandomForestClassifier(n_estimators=10, max_depth=20)\n",
        "\n",
        "    # lr\n",
        "    # from sklearn.linear_model import LogisticRegression\n",
        "    # clf = LogisticRegression()\n",
        "\n",
        "    clf.fit([f.flatten() for f in X_train], Y_train)\n",
        "    pred = clf.predict([f.flatten() for f in X_test])\n",
        "    # clf.fit([f.sum(axis=0) for f in X_train], Y_train)\n",
        "    # pred = clf.predict([f.sum(axis=0) for f in X_test])\n",
        "\n",
        "    y_test_pred, conf_matrix = model_performance(Y_test, pred)\n",
        "\n",
        "    # custom evaluation metrics\n",
        "    print('Calculating additional test metrics...')\n",
        "    accuracy = float(conf_matrix[0][0] + conf_matrix[1][1]) / np.sum(conf_matrix)\n",
        "    precision = float(conf_matrix[0][0]) / (conf_matrix[0][0] + conf_matrix[0][1])\n",
        "    recall = float(conf_matrix[0][0]) / (conf_matrix[0][0] + conf_matrix[1][0])\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "    print(\"Accuracy: {}\".format(accuracy))\n",
        "    print(\"Precision: {}\".format(precision))\n",
        "    print(\"Recall: {}\".format(recall))\n",
        "    print(\"F1-Score: {}\\n\".format(f1_score))\n",
        "    print('='*89)\n",
        "    # precs.append(0 if np.isnan(precision) else precision)\n",
        "    # recs.append(0 if np.isnan(recall) else recall)\n",
        "    # f1s.append(0 if np.isnan(f1_score) else f1_score)\n",
        "    precs.append(precision)\n",
        "    recs.append(recall)\n",
        "    f1s.append(f1_score)\n",
        "print(np.mean(precs), np.mean(recs), np.mean(f1s))"
      ],
      "metadata": {
        "id": "zA1YvKxMcbV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fusion"
      ],
      "metadata": {
        "id": "_JIA-CrKfK6C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `fuse_net_whole.py`\n",
        "Connects altogether using 3-fold indices and textual \"BiLSTM\" features along with \"BiLSTM-GRU-VLAD\" features and their according saved models"
      ],
      "metadata": {
        "id": "7aKb6nCbfQ2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install python_speech_features"
      ],
      "metadata": {
        "id": "nO18pM6fhXo0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import wave\n",
        "import librosa\n",
        "from python_speech_features import *\n",
        "import re\n",
        "# from allennlp.commands.elmo import ElmoEmbedder\n",
        "import os\n",
        "import tensorflow.compat.v1 as tf\n",
        "import itertools"
      ],
      "metadata": {
        "id": "Pfe_2-AXhE-I"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text_features = np.load(f'{BASELINE_DIR}/Features/TextWhole/whole_samples_clf_avg.npz')['arr_0']\n",
        "text_targets = np.load(f'{BASELINE_DIR}/Features/TextWhole/whole_labels_clf_avg.npz')['arr_0']\n",
        "\n",
        "audio_features = np.squeeze(np.load(f'{BASELINE_DIR}/Features/AudioWhole/whole_samples_clf_256.npz')['arr_0'], axis=2)\n",
        "audio_targets = np.load(f'{BASELINE_DIR}/Features/AudioWhole/whole_labels_clf_256.npz')['arr_0']\n",
        "\n",
        "fuse_features = [[audio_features[i], text_features[i]] for i in range(text_features.shape[0])]\n",
        "fuse_targets = text_targets\n",
        "\n",
        "fuse_dep_idxs = np.where(text_targets == 1)[0]\n",
        "fuse_non_idxs = np.where(text_targets == 0)[0]"
      ],
      "metadata": {
        "id": "tM-kE8nWhdI2"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save(model, filename):\n",
        "    save_filename = '{}.pt'.format(filename)\n",
        "    torch.save(model, save_filename)\n",
        "    print('Saved as %s' % save_filename)\n",
        "\n",
        "def standard_confusion_matrix(y_test, y_test_pred):\n",
        "    \"\"\"\n",
        "    Make confusion matrix with format:\n",
        "                  -----------\n",
        "                  | TP | FP |\n",
        "                  -----------\n",
        "                  | FN | TN |\n",
        "                  -----------\n",
        "    Parameters\n",
        "    ----------\n",
        "    y_true : ndarray - 1D\n",
        "    y_pred : ndarray - 1D\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    ndarray - 2D\n",
        "    \"\"\"\n",
        "    [[tn, fp], [fn, tp]] = confusion_matrix(y_test, y_test_pred)\n",
        "    return np.array([[tp, fp], [fn, tn]])\n",
        "\n",
        "def model_performance(y_test, y_test_pred_proba):\n",
        "    \"\"\"\n",
        "    Evaluation metrics for network performance.\n",
        "    \"\"\"\n",
        "    # y_test_pred = y_test_pred_proba.data.max(1, keepdim=True)[1]\n",
        "    y_test_pred = y_test_pred_proba\n",
        "\n",
        "    # Computing confusion matrix for test dataset\n",
        "    conf_matrix = standard_confusion_matrix(y_test, y_test_pred)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "    return y_test_pred, conf_matrix"
      ],
      "metadata": {
        "id": "IlAX1CUGiDs6"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextBiLSTM(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(TextBiLSTM, self).__init__()\n",
        "        self.num_classes = config['num_classes']\n",
        "        self.learning_rate = config['learning_rate']\n",
        "        self.dropout = config['dropout']\n",
        "        self.hidden_dims = config['hidden_dims']\n",
        "        self.rnn_layers = config['rnn_layers']\n",
        "        self.embedding_size = config['embedding_size']\n",
        "        self.bidirectional = config['bidirectional']\n",
        "\n",
        "        self.build_model()\n",
        "        self.init_weight()\n",
        "\n",
        "    def init_weight(net):\n",
        "        for name, param in net.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                nn.init.constant_(param, 0.0)\n",
        "            elif 'weight' in name:\n",
        "                nn.init.xavier_uniform_(param)\n",
        "\n",
        "    def build_model(self):\n",
        "        # attention layer\n",
        "        self.attention_layer = nn.Sequential(\n",
        "            nn.Linear(self.hidden_dims, self.hidden_dims),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        # self.attention_weights = self.attention_weights.view(self.hidden_dims, 1)\n",
        "\n",
        "        # 双层lstm\n",
        "        self.lstm_net = nn.LSTM(self.embedding_size, self.hidden_dims,\n",
        "                                num_layers=self.rnn_layers, dropout=self.dropout,\n",
        "                                bidirectional=self.bidirectional)\n",
        "\n",
        "        # self.init_weight()\n",
        "\n",
        "        # FC层\n",
        "        # self.fc_out = nn.Linear(self.hidden_dims, self.num_classes)\n",
        "        self.fc_out = nn.Sequential(\n",
        "            nn.Dropout(self.dropout),\n",
        "            nn.Linear(self.hidden_dims, self.hidden_dims),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(self.dropout),\n",
        "            nn.Linear(self.hidden_dims, self.num_classes),\n",
        "            # nn.ReLU(),\n",
        "            nn.Softmax(dim=1),\n",
        "        )\n",
        "\n",
        "    def attention_net_with_w(self, lstm_out, lstm_hidden):\n",
        "        '''\n",
        "        :param lstm_out:    [batch_size, len_seq, n_hidden * 2]\n",
        "        :param lstm_hidden: [batch_size, num_layers * num_directions, n_hidden]\n",
        "        :return: [batch_size, n_hidden]\n",
        "        '''\n",
        "        lstm_tmp_out = torch.chunk(lstm_out, 2, -1)\n",
        "        # h [batch_size, time_step, hidden_dims]\n",
        "        h = lstm_tmp_out[0] + lstm_tmp_out[1]\n",
        "        # h = lstm_out\n",
        "        # [batch_size, num_layers * num_directions, n_hidden]\n",
        "        lstm_hidden = torch.sum(lstm_hidden, dim=1)\n",
        "        # [batch_size, 1, n_hidden]\n",
        "        lstm_hidden = lstm_hidden.unsqueeze(1)\n",
        "        # atten_w [batch_size, 1, hidden_dims]\n",
        "        atten_w = self.attention_layer(lstm_hidden)\n",
        "        # m [batch_size, time_step, hidden_dims]\n",
        "        m = nn.Tanh()(h)\n",
        "        # atten_context [batch_size, 1, time_step]\n",
        "        atten_context = torch.bmm(atten_w, m.transpose(1, 2))\n",
        "        # softmax_w [batch_size, 1, time_step]\n",
        "        softmax_w = F.softmax(atten_context, dim=-1)\n",
        "        # context [batch_size, 1, hidden_dims]\n",
        "        context = torch.bmm(softmax_w, h)\n",
        "        result = context.squeeze(1)\n",
        "        return result\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # x : [len_seq, batch_size, embedding_dim]\n",
        "        x = x.permute(1, 0, 2)\n",
        "        output, (final_hidden_state, final_cell_state) = self.lstm_net(x)\n",
        "        # output : [batch_size, len_seq, n_hidden * 2]\n",
        "        output = output.permute(1, 0, 2)\n",
        "        # final_hidden_state : [batch_size, num_layers * num_directions, n_hidden]\n",
        "        final_hidden_state = final_hidden_state.permute(1, 0, 2)\n",
        "        # final_hidden_state = torch.mean(final_hidden_state, dim=0, keepdim=True)\n",
        "        # atten_out = self.attention_net(output, final_hidden_state)\n",
        "        atten_out = self.attention_net_with_w(output, final_hidden_state)\n",
        "        return self.fc_out(atten_out)\n",
        "\n",
        "class AudioBiLSTM(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(AudioBiLSTM, self).__init__()\n",
        "        self.num_classes = config['num_classes']\n",
        "        self.learning_rate = config['learning_rate']\n",
        "        self.dropout = config['dropout']\n",
        "        self.hidden_dims = config['hidden_dims']\n",
        "        self.rnn_layers = config['rnn_layers']\n",
        "        self.embedding_size = config['embedding_size']\n",
        "        self.bidirectional = config['bidirectional']\n",
        "\n",
        "        self.build_model()\n",
        "        # self.init_weight()\n",
        "\n",
        "    def init_weight(net):\n",
        "        for name, param in net.named_parameters():\n",
        "            if not 'ln' in name:\n",
        "                if 'bias' in name:\n",
        "                    nn.init.constant_(param, 0.0)\n",
        "                elif 'weight' in name:\n",
        "                    nn.init.xavier_uniform_(param)\n",
        "\n",
        "    def build_model(self):\n",
        "        # attention layer\n",
        "        self.attention_layer = nn.Sequential(\n",
        "            nn.Linear(self.hidden_dims, self.hidden_dims),\n",
        "            nn.ReLU(inplace=True))\n",
        "        # self.attention_weights = self.attention_weights.view(self.hidden_dims, 1)\n",
        "\n",
        "        # self.lstm_net_audio = nn.LSTM(self.embedding_size,\n",
        "        #                         self.hidden_dims,\n",
        "        #                         num_layers=self.rnn_layers,\n",
        "        #                         dropout=self.dropout,\n",
        "        #                         bidirectional=self.bidirectional,\n",
        "        #                         batch_first=True)\n",
        "        self.lstm_net_audio = nn.GRU(self.embedding_size, self.hidden_dims,\n",
        "                                num_layers=self.rnn_layers, dropout=self.dropout, batch_first=True)\n",
        "\n",
        "        self.ln = nn.LayerNorm(self.embedding_size)\n",
        "\n",
        "        # FC层\n",
        "        self.fc_audio = nn.Sequential(\n",
        "            nn.Dropout(self.dropout),\n",
        "            nn.Linear(self.hidden_dims, self.hidden_dims),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(self.dropout),\n",
        "            nn.Linear(self.hidden_dims, self.num_classes),\n",
        "            # nn.ReLU(),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def attention_net_with_w(self, lstm_out, lstm_hidden):\n",
        "        '''\n",
        "        :param lstm_out:    [batch_size, len_seq, n_hidden * 2]\n",
        "        :param lstm_hidden: [batch_size, num_layers * num_directions, n_hidden]\n",
        "        :return: [batch_size, n_hidden]\n",
        "        '''\n",
        "        lstm_tmp_out = torch.chunk(lstm_out, 2, -1)\n",
        "        # h [batch_size, time_step, hidden_dims]\n",
        "        h = lstm_tmp_out[0] + lstm_tmp_out[1]\n",
        "        #         h = lstm_out\n",
        "        # [batch_size, num_layers * num_directions, n_hidden]\n",
        "        lstm_hidden = torch.sum(lstm_hidden, dim=1)\n",
        "        # [batch_size, 1, n_hidden]\n",
        "        lstm_hidden = lstm_hidden.unsqueeze(1)\n",
        "        # atten_w [batch_size, 1, hidden_dims]\n",
        "        atten_w = self.attention_layer(lstm_hidden)\n",
        "        # m [batch_size, time_step, hidden_dims]\n",
        "        m = nn.Tanh()(h)\n",
        "        # atten_context [batch_size, 1, time_step]\n",
        "       # print(atten_w.shape, m.transpose(1, 2).shape)\n",
        "        atten_context = torch.bmm(atten_w, m.transpose(1, 2))\n",
        "        # softmax_w [batch_size, 1, time_step]\n",
        "        softmax_w = F.softmax(atten_context, dim=-1)\n",
        "        # context [batch_size, 1, hidden_dims]\n",
        "        context = torch.bmm(softmax_w, h)\n",
        "        result = context.squeeze(1)\n",
        "        return result\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln(x)\n",
        "        x, _ = self.lstm_net_audio(x)\n",
        "        x = x.mean(dim=1)\n",
        "        out = self.fc_audio(x)\n",
        "        return out\n",
        "\n",
        "class fusion_net(nn.Module):\n",
        "    def __init__(self, text_embed_size, text_hidden_dims, rnn_layers, dropout, num_classes, \\\n",
        "         audio_hidden_dims, audio_embed_size):\n",
        "        super(fusion_net, self).__init__()\n",
        "        self.text_embed_size = text_embed_size\n",
        "        self.audio_embed_size = audio_embed_size\n",
        "        self.text_hidden_dims = text_hidden_dims\n",
        "        self.audio_hidden_dims = audio_hidden_dims\n",
        "        self.rnn_layers = rnn_layers\n",
        "        self.dropout = dropout\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # ============================= TextBiLSTM =================================\n",
        "\n",
        "        # attention layer\n",
        "        self.attention_layer = nn.Sequential(\n",
        "            nn.Linear(self.text_hidden_dims, self.text_hidden_dims),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # 双层lstm\n",
        "        self.lstm_net = nn.LSTM(self.text_embed_size, self.text_hidden_dims,\n",
        "                                num_layers=self.rnn_layers, dropout=self.dropout,\n",
        "                                bidirectional=True)\n",
        "        # FC层\n",
        "        self.fc_out = nn.Sequential(\n",
        "            nn.Dropout(self.dropout),\n",
        "            nn.Linear(self.text_hidden_dims, self.text_hidden_dims),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(self.dropout)\n",
        "        )\n",
        "\n",
        "        # ============================= TextBiLSTM =================================\n",
        "\n",
        "        # ============================= AudioBiLSTM =============================\n",
        "\n",
        "        self.lstm_net_audio = nn.GRU(self.audio_embed_size,\n",
        "                                self.audio_hidden_dims,\n",
        "                                num_layers=self.rnn_layers,\n",
        "                                dropout=self.dropout,\n",
        "                                bidirectional=False,\n",
        "                                batch_first=True)\n",
        "\n",
        "        self.fc_audio = nn.Sequential(\n",
        "            nn.Dropout(self.dropout),\n",
        "            nn.Linear(self.audio_hidden_dims, self.audio_hidden_dims),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(self.dropout)\n",
        "        )\n",
        "\n",
        "        self.ln = nn.LayerNorm(self.audio_embed_size)\n",
        "\n",
        "        # ============================= AudioBiLSTM =============================\n",
        "\n",
        "        # ============================= last fc layer =============================\n",
        "        # self.bn = nn.BatchNorm1d(self.text_hidden_dims + self.audio_hidden_dims)\n",
        "        # modal attention\n",
        "        self.modal_attn = nn.Linear(self.text_hidden_dims + self.audio_hidden_dims, self.text_hidden_dims + self.audio_hidden_dims, bias=False)\n",
        "        self.fc_final = nn.Sequential(\n",
        "            nn.Linear(self.text_hidden_dims + self.audio_hidden_dims, self.num_classes, bias=False),\n",
        "            # nn.ReLU(),\n",
        "            nn.Softmax(dim=1),\n",
        "            # nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def attention_net_with_w(self, lstm_out, lstm_hidden):\n",
        "        '''\n",
        "        :param lstm_out:    [batch_size, len_seq, n_hidden * 2]\n",
        "        :param lstm_hidden: [batch_size, num_layers * num_directions, n_hidden]\n",
        "        :return: [batch_size, n_hidden]\n",
        "        '''\n",
        "        lstm_tmp_out = torch.chunk(lstm_out, 2, -1)\n",
        "        # h [batch_size, time_step, hidden_dims]\n",
        "        h = lstm_tmp_out[0] + lstm_tmp_out[1]\n",
        "        # [batch_size, num_layers * num_directions, n_hidden]\n",
        "        lstm_hidden = torch.sum(lstm_hidden, dim=1)\n",
        "        # [batch_size, 1, n_hidden]\n",
        "        lstm_hidden = lstm_hidden.unsqueeze(1)\n",
        "        # atten_w [batch_size, 1, hidden_dims]\n",
        "        atten_w = self.attention_layer(lstm_hidden)\n",
        "        # m [batch_size, time_step, hidden_dims]\n",
        "        m = nn.Tanh()(h)\n",
        "        # atten_context [batch_size, 1, time_step]\n",
        "        atten_context = torch.bmm(atten_w, m.transpose(1, 2))\n",
        "        # softmax_w [batch_size, 1, time_step]\n",
        "        softmax_w = F.softmax(atten_context, dim=-1)\n",
        "        # context [batch_size, 1, hidden_dims]\n",
        "        context = torch.bmm(softmax_w, h)\n",
        "        result = context.squeeze(1)\n",
        "        return result\n",
        "\n",
        "    def pretrained_feature(self, x):\n",
        "        with torch.no_grad():\n",
        "            x_text = []\n",
        "            x_audio = []\n",
        "            for ele in x:\n",
        "                x_text.append(ele[1])\n",
        "                x_audio.append(ele[0])\n",
        "            x_text, x_audio = Variable(torch.tensor(x_text).type(torch.FloatTensor), requires_grad=False), Variable(torch.tensor(x_audio).type(torch.FloatTensor), requires_grad=False)\n",
        "            # ============================= TextBiLSTM =================================\n",
        "            # x : [len_seq, batch_size, embedding_dim]\n",
        "            x_text = x_text.permute(1, 0, 2)\n",
        "            output, (final_hidden_state, _) = self.lstm_net(x_text)\n",
        "            # output : [batch_size, len_seq, n_hidden * 2]\n",
        "            output = output.permute(1, 0, 2)\n",
        "            # final_hidden_state : [batch_size, num_layers * num_directions, n_hidden]\n",
        "            final_hidden_state = final_hidden_state.permute(1, 0, 2)\n",
        "            # final_hidden_state = torch.mean(final_hidden_state, dim=0, keepdim=True)\n",
        "            # atten_out = self.attention_net(output, final_hidden_state)\n",
        "            atten_out = self.attention_net_with_w(output, final_hidden_state)\n",
        "            text_feature = self.fc_out(atten_out)\n",
        "\n",
        "            # ============================= TextBiLSTM =================================\n",
        "\n",
        "            # ============================= AudioBiLSTM =============================\n",
        "            x_audio = self.ln(x_audio)\n",
        "            x_audio, _ = self.lstm_net_audio(x_audio)\n",
        "            x_audio = x_audio.sum(dim=1)\n",
        "            audio_feature = self.fc_audio(x_audio)\n",
        "\n",
        "        # ============================= AudioBiLSTM =============================\n",
        "        return (text_feature, audio_feature)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = self.bn(x)\n",
        "        # modal_weights = torch.softmax(self.modal_attn(x), dim=1)\n",
        "        # modal_weights = self.modal_attn(x)\n",
        "        # x = (modal_weights * x)\n",
        "        output = self.fc_final(x)\n",
        "        return output\n",
        "\n",
        "class MyLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyLoss, self).__init__()\n",
        "\n",
        "    def forward(self, text_feature, audio_feature, target, model):\n",
        "        weight = model.fc_final[0].weight\n",
        "        # bias = model.fc_final[0].bias\n",
        "        # print(weight, bias)\n",
        "        pred_text = F.linear(text_feature, weight[:, :config['text_hidden_dims']])\n",
        "        pred_audio = F.linear(audio_feature, weight[:, config['text_hidden_dims']:])\n",
        "        l = nn.CrossEntropyLoss()\n",
        "        target = torch.tensor(target)\n",
        "        # l = nn.BCEWithLogitsLoss()\n",
        "        # target = F.one_hot(target, num_classes=2).type(torch.FloatTensor)\n",
        "        # print('y: {}\\npred_audio: {}\\npred_text: {}\\n'.format(target, pred_audio.data.max(1, keepdim=True)[1], pred_text.data.max(1, keepdim=True)[1]))\n",
        "        # return l(pred_text, target) + l(pred_audio, target) + \\\n",
        "        #         config['lambda']*torch.norm(weight[:, :config['text_hidden_dims']]) + \\\n",
        "        #         config['lambda']*torch.norm(weight[:, config['text_hidden_dims']:])\n",
        "        # a = F.softmax(pred_text, dim=1) + F.softmax(pred_audio, dim=1)\n",
        "        return l(pred_text, target) + l(pred_audio, target)"
      ],
      "metadata": {
        "id": "qnhjSKV2iXeP"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'num_classes': 2,\n",
        "    'dropout': 0.3,\n",
        "    'rnn_layers': 2,\n",
        "    'audio_embed_size': 256,\n",
        "    'text_embed_size': 1024,\n",
        "    'batch_size': 2,\n",
        "    'epochs': 100,\n",
        "    'learning_rate': 8e-6,\n",
        "    'audio_hidden_dims': 256,\n",
        "    'text_hidden_dims': 128,\n",
        "    'cuda': False,\n",
        "    'lambda': 1e-5,\n",
        "}"
      ],
      "metadata": {
        "id": "TeH8buZ8iZNb"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = fusion_net(config['text_embed_size'], config['text_hidden_dims'], config['rnn_layers'], \\\n",
        "    config['dropout'], config['num_classes'], config['audio_hidden_dims'], config['audio_embed_size'])\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
        "# optimizer = optim.Adam(model.parameters())\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "criterion = MyLoss()"
      ],
      "metadata": {
        "id": "E9k8MT9UiiEw"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch, train_idxs):\n",
        "    global max_train_acc, train_acc\n",
        "    model.train()\n",
        "    batch_idx = 1\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    X_train = []\n",
        "    Y_train = []\n",
        "    for idx in train_idxs:\n",
        "        X_train.append(fuse_features[idx])\n",
        "        Y_train.append(fuse_targets[idx])\n",
        "    for i in range(0, len(X_train), config['batch_size']):\n",
        "        if i + config['batch_size'] > len(X_train):\n",
        "            x, y = X_train[i:], Y_train[i:]\n",
        "        else:\n",
        "            x, y = X_train[i:(i+config['batch_size'])], Y_train[i:(i+config['batch_size'])]\n",
        "        if config['cuda']:\n",
        "            x, y = Variable(torch.from_numpy(x).type(torch.FloatTensor), requires_grad=True).cuda(), Variable(torch.from_numpy(y)).cuda()\n",
        "        # 将模型的参数梯度设置为0\n",
        "        optimizer.zero_grad()\n",
        "        text_feature, audio_feature = model.pretrained_feature(x)\n",
        "        # text_feature = torch.from_numpy(ss.fit_transform(text_feature.numpy()))\n",
        "        # audio_feature = torch.from_numpy(ss.fit_transform(audio_feature.numpy()))\n",
        "        # concat_x = torch.cat((audio_feature, text_feature), dim=1)\n",
        "        concat_x = torch.cat((text_feature, audio_feature), dim=1)\n",
        "        # dot_x = text_feature.mul(audio_feature)\n",
        "        # add_x = text_feature.add(audio_feature)\n",
        "        output = model(concat_x)\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(torch.tensor(y).data.view_as(pred)).cpu().sum()\n",
        "        # loss = criterion(output, torch.tensor(y))\n",
        "        loss = criterion(text_feature, audio_feature, y, model)\n",
        "        # 后向传播调整参数\n",
        "        loss.backward()\n",
        "        # 根据梯度更新网络参数\n",
        "        optimizer.step()\n",
        "        batch_idx += 1\n",
        "        # loss.item()能够得到张量中的元素值\n",
        "        total_loss += loss.item()\n",
        "    cur_loss = total_loss\n",
        "    max_train_acc = correct\n",
        "    train_acc = correct\n",
        "    print('Train Epoch: {:2d}\\t Learning rate: {:.4f}\\tLoss: {:.6f}\\t Accuracy: {}/{} ({:.0f}%)\\n '.format(\n",
        "                epoch, config['learning_rate'], cur_loss/len(X_train), correct, len(X_train),\n",
        "        100. * correct / len(X_train)))\n",
        "\n",
        "\n",
        "def evaluate(model, test_idxs, fold, train_idxs):\n",
        "    model.eval()\n",
        "    batch_idx = 1\n",
        "    total_loss = 0\n",
        "    pred = torch.empty(config['batch_size'], 1).type(torch.LongTensor)\n",
        "    X_test = []\n",
        "    Y_test = []\n",
        "    for idx in test_idxs:\n",
        "        X_test.append(fuse_features[idx])\n",
        "        Y_test.append(fuse_targets[idx])\n",
        "    global max_train_acc, max_acc,max_f1\n",
        "    for i in range(0, len(X_test), config['batch_size']):\n",
        "        if i + config['batch_size'] > len(X_test):\n",
        "            x, y = X_test[i:], Y_test[i:]\n",
        "        else:\n",
        "            x, y = X_test[i:(i+config['batch_size'])], Y_test[i:(i+config['batch_size'])]\n",
        "        if config['cuda']:\n",
        "            x, y = Variable(torch.from_numpy(x).type(torch.FloatTensor), requires_grad=True).cuda(), Variable(torch.from_numpy(y)).cuda()\n",
        "        text_feature, audio_feature = model.pretrained_feature(x)\n",
        "        with torch.no_grad():\n",
        "            # concat_x = torch.cat((audio_feature, text_feature), dim=1)\n",
        "            audio_feature_norm = (audio_feature - audio_feature.mean())/audio_feature.std()\n",
        "            text_feature_norm = (text_feature - text_feature.mean())/text_feature.std()\n",
        "            concat_x = torch.cat((text_feature, audio_feature), dim=1)\n",
        "            output = model(concat_x)\n",
        "        # loss = criterion(output, torch.tensor(y))\n",
        "        loss = criterion(text_feature, audio_feature, y, model)\n",
        "        pred = torch.cat((pred, output.data.max(1, keepdim=True)[1]))\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    y_test_pred, conf_matrix = model_performance(Y_test, pred[config['batch_size']:])\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}'.format(total_loss/len(X_test)))\n",
        "    # custom evaluation metrics\n",
        "    print('Calculating additional test metrics...')\n",
        "    accuracy = float(conf_matrix[0][0] + conf_matrix[1][1]) / np.sum(conf_matrix)\n",
        "    precision = float(conf_matrix[0][0]) / (conf_matrix[0][0] + conf_matrix[0][1])\n",
        "    recall = float(conf_matrix[0][0]) / (conf_matrix[0][0] + conf_matrix[1][0])\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "    print(\"Accuracy: {}\".format(accuracy))\n",
        "    print(\"Precision: {}\".format(precision))\n",
        "    print(\"Recall: {}\".format(recall))\n",
        "    print(\"F1-Score: {}\\n\".format(f1_score))\n",
        "    print('='*89)\n",
        "\n",
        "    if max_f1 < f1_score and max_train_acc >= len(train_idxs)*0.9 and f1_score > 0.61:\n",
        "        max_f1 = f1_score\n",
        "        max_acc = accuracy\n",
        "        save(model, f'{BASELINE_DIR}/Model/ClassificationWhole/Fuse/fuse_{max_f1:.2f}_{fold}')\n",
        "        print('*'*64)\n",
        "        print('model saved: f1: {}\\tacc: {}'.format(max_f1, max_acc))\n",
        "        print('*'*64)\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "_8836Yr_lWDo"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idxs_paths = ['train_idxs_0.63_1.npy', 'train_idxs_0.65_2.npy', 'train_idxs_0.60_3.npy']\n",
        "text_model_paths = ['BiLSTM_128_0.64_1.pt', 'BiLSTM_128_0.66_2.pt', 'BiLSTM_128_0.62_3.pt']\n",
        "audio_model_paths = ['BiLSTM_gru_vlad256_256_0.67_1.pt', 'BiLSTM_gru_vlad256_256_0.67_2.pt', 'BiLSTM_gru_vlad256_256_0.63_3.pt']\n",
        "for fold in range(1, 4):\n",
        "    # if fold != 2:\n",
        "    #     continue\n",
        "    train_idxs_tmp = np.load(f'{BASELINE_DIR}/Features/TextWhole/{idxs_paths[fold-1]}', allow_pickle=True)\n",
        "    test_idxs_tmp = list(set(list(fuse_dep_idxs)+list(fuse_non_idxs)) - set(train_idxs_tmp))\n",
        "    resample_idxs = list(range(6))\n",
        "\n",
        "    train_idxs, test_idxs = [], []\n",
        "    # depression data augmentation\n",
        "    for idx in train_idxs_tmp:\n",
        "        if idx in fuse_dep_idxs:\n",
        "            feat = fuse_features[idx]\n",
        "            audio_perm = itertools.permutations(feat[0], 3)\n",
        "            text_perm = itertools.permutations(feat[1], 3)\n",
        "            count = 0\n",
        "            for fuse_perm in zip(audio_perm, text_perm):\n",
        "                if count in resample_idxs:\n",
        "                    fuse_features.append(fuse_perm)\n",
        "                    fuse_targets = np.hstack((fuse_targets, 1))\n",
        "                    train_idxs.append(len(fuse_features)-1)\n",
        "                count += 1\n",
        "        else:\n",
        "            train_idxs.append(idx)\n",
        "\n",
        "    for idx in test_idxs_tmp:\n",
        "        if idx in fuse_dep_idxs:\n",
        "            feat = fuse_features[idx]\n",
        "            audio_perm = itertools.permutations(feat[0], 3)\n",
        "            text_perm = itertools.permutations(feat[1], 3)\n",
        "            count = 0\n",
        "            resample_idxs = [0,1,4,5]\n",
        "            for fuse_perm in zip(audio_perm, text_perm):\n",
        "                if count in resample_idxs:\n",
        "                    fuse_features.append(fuse_perm)\n",
        "                    fuse_targets = np.hstack((fuse_targets, 1))\n",
        "                    test_idxs.append(len(fuse_features)-1)\n",
        "                count += 1\n",
        "        else:\n",
        "            test_idxs.append(idx)\n",
        "\n",
        "    text_lstm_model = torch.load(f'{BASELINE_DIR}/Model/ClassificationWhole/Text/{text_model_paths[fold-1]}')\n",
        "    audio_lstm_model = torch.load(f'{BASELINE_DIR}/Model/ClassificationWhole/Audio/{audio_model_paths[fold-1]}')\n",
        "    model_state_dict = {}\n",
        "    model_state_dict['lstm_net_audio.weight_ih_l0'] = audio_lstm_model.state_dict()['lstm_net_audio.weight_ih_l0']\n",
        "    model_state_dict['lstm_net_audio.weight_hh_l0'] = audio_lstm_model.state_dict()['lstm_net_audio.weight_hh_l0']\n",
        "    model_state_dict['lstm_net_audio.bias_ih_l0'] = audio_lstm_model.state_dict()['lstm_net_audio.bias_ih_l0']\n",
        "    model_state_dict['lstm_net_audio.bias_hh_l0'] = audio_lstm_model.state_dict()['lstm_net_audio.bias_hh_l0']\n",
        "\n",
        "    model_state_dict['lstm_net_audio.weight_ih_l1'] = audio_lstm_model.state_dict()['lstm_net_audio.weight_ih_l1']\n",
        "    model_state_dict['lstm_net_audio.weight_hh_l1'] = audio_lstm_model.state_dict()['lstm_net_audio.weight_hh_l1']\n",
        "    model_state_dict['lstm_net_audio.bias_ih_l1'] = audio_lstm_model.state_dict()['lstm_net_audio.bias_ih_l1']\n",
        "    model_state_dict['lstm_net_audio.bias_hh_l1'] = audio_lstm_model.state_dict()['lstm_net_audio.bias_hh_l1']\n",
        "\n",
        "    model_state_dict['fc_audio.1.weight'] = audio_lstm_model.state_dict()['fc_audio.1.weight']\n",
        "    model_state_dict['fc_audio.1.bias'] = audio_lstm_model.state_dict()['fc_audio.1.bias']\n",
        "    model_state_dict['fc_audio.4.weight'] = audio_lstm_model.state_dict()['fc_audio.4.weight']\n",
        "    model_state_dict['fc_audio.4.bias'] = audio_lstm_model.state_dict()['fc_audio.4.bias']\n",
        "\n",
        "    model_state_dict['ln.weight'] = audio_lstm_model.state_dict()['ln.weight']\n",
        "    model_state_dict['ln.bias'] = audio_lstm_model.state_dict()['ln.bias']\n",
        "    model.load_state_dict(text_lstm_model.state_dict(), strict=False)\n",
        "    # model.load_state_dict(audio_lstm_model.state_dict(), strict=False)\n",
        "    model.load_state_dict(model_state_dict, strict=False)\n",
        "\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    model.fc_final[0].weight.requires_grad = True\n",
        "    # model.fc_final[0].bias.requires_grad = True\n",
        "    # model.modal_attn.weight.requires_grad = True\n",
        "\n",
        "    max_f1 = -1\n",
        "    max_acc = -1\n",
        "    max_train_acc = -1\n",
        "\n",
        "    for ep in range(1, config['epochs']):\n",
        "        train(ep, train_idxs)\n",
        "        tloss = evaluate(model, test_idxs, fold, train_idxs)"
      ],
      "metadata": {
        "id": "mD62cvjwfYsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `FuseModelChecking.py`\n",
        "testing module for all the stored models and features altogether"
      ],
      "metadata": {
        "id": "vxFQb7s8fWvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from fuse_net_whole import fusion_net, config, model_performance\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import itertools"
      ],
      "metadata": {
        "id": "9ysjDFRtne8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idxs_paths = ['train_idxs_0.63_1.npy', 'train_idxs_0.65_2.npy', 'train_idxs_0.60_3.npy']\n",
        "text_model_paths = ['BiLSTM_128_0.67_1.pt', 'BiLSTM_128_0.66_2.pt', 'BiLSTM_128_0.66_3.pt']\n",
        "audio_model_paths = ['BiLSTM_gru_vlad256_256_0.63_1.pt', 'BiLSTM_gru_vlad256_256_0.65_2.pt', 'BiLSTM_gru_vlad256_256_0.60_3.pt']\n",
        "fuse_model_paths = ['fuse_0.69_1.pt', 'fuse_0.68_2.pt', 'fuse_0.62_3.pt']\n",
        "\n",
        "text_features = np.load(f'{BASELINE_DIR}/Features/TextWhole/whole_samples_clf_avg.npz')['arr_0']\n",
        "text_targets = np.load(f'{BASELINE_DIR}/Features/TextWhole/whole_labels_clf_avg.npz')['arr_0']\n",
        "audio_features = np.squeeze(np.load(f'{BASELINE_DIR}/Features/AudioWhole/whole_samples_clf_256.npz')['arr_0'], axis=2)\n",
        "audio_targets = np.load(f'{BASELINE_DIR}/Features/AudioWhole/whole_labels_clf_256.npz')['arr_0']\n",
        "\n",
        "fuse_features = [[audio_features[i], text_features[i]] for i in range(text_features.shape[0])]\n",
        "fuse_targets = text_targets\n",
        "\n",
        "fuse_dep_idxs = np.where(text_targets == 1)[0]\n",
        "fuse_non_idxs = np.where(text_targets == 0)[0]"
      ],
      "metadata": {
        "id": "I26L2zOpngY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_idxs):\n",
        "    model.eval()\n",
        "    pred = torch.empty(config['batch_size'], 1).type(torch.LongTensor)\n",
        "    X_test = []\n",
        "    Y_test = []\n",
        "    for idx in test_idxs:\n",
        "        X_test.append(fuse_features[idx])\n",
        "        Y_test.append(fuse_targets[idx])\n",
        "    global max_train_acc, max_acc,max_f1\n",
        "    for i in range(0, len(X_test), config['batch_size']):\n",
        "        if i + config['batch_size'] > len(X_test):\n",
        "            x, y = X_test[i:], Y_test[i:]\n",
        "        else:\n",
        "            x, y = X_test[i:(i+config['batch_size'])], Y_test[i:(i+config['batch_size'])]\n",
        "        if config['cuda']:\n",
        "            x, y = Variable(torch.from_numpy(x).type(torch.FloatTensor), requires_grad=True).cuda(), Variable(torch.from_numpy(y)).cuda()\n",
        "        text_feature, audio_feature = model.pretrained_feature(x)\n",
        "        with torch.no_grad():\n",
        "            # concat_x = torch.cat((audio_feature, text_feature), dim=1)\n",
        "            audio_feature_norm = (audio_feature - audio_feature.mean())/audio_feature.std()\n",
        "            text_feature_norm = (text_feature - text_feature.mean())/text_feature.std()\n",
        "            concat_x = torch.cat((text_feature, audio_feature), dim=1)\n",
        "            output = model(concat_x)\n",
        "        pred = torch.cat((pred, output.data.max(1, keepdim=True)[1]))\n",
        "\n",
        "    y_test_pred, conf_matrix = model_performance(Y_test, pred[config['batch_size']:])\n",
        "    # custom evaluation metrics\n",
        "    print('Calculating additional test metrics...')\n",
        "    accuracy = float(conf_matrix[0][0] + conf_matrix[1][1]) / np.sum(conf_matrix)\n",
        "    precision = float(conf_matrix[0][0]) / (conf_matrix[0][0] + conf_matrix[0][1])\n",
        "    recall = float(conf_matrix[0][0]) / (conf_matrix[0][0] + conf_matrix[1][0])\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "    print(\"Accuracy: {}\".format(accuracy))\n",
        "    print(\"Precision: {}\".format(precision))\n",
        "    print(\"Recall: {}\".format(recall))\n",
        "    print(\"F1-Score: {}\\n\".format(f1_score))\n",
        "    print('='*89)\n",
        "\n",
        "    return precision, recall, f1_score"
      ],
      "metadata": {
        "id": "rTvKzflMoune"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ps, rs, fs = [], [], []\n",
        "for fold in range(3):\n",
        "    train_idxs_tmp = np.load(f'{BASELINE_DIR}/Features/TextWhole/{idxs_paths[fold]}', allow_pickle=True)\n",
        "    test_idxs_tmp = list(set(list(fuse_dep_idxs)+list(fuse_non_idxs)) - set(train_idxs_tmp))\n",
        "    resample_idxs = list(range(6))\n",
        "    train_idxs, test_idxs = [], []\n",
        "    # depression data augmentation\n",
        "    for idx in train_idxs_tmp:\n",
        "        if idx in fuse_dep_idxs:\n",
        "            feat = fuse_features[idx]\n",
        "            audio_perm = itertools.permutations(feat[0], 3)\n",
        "            text_perm = itertools.permutations(feat[1], 3)\n",
        "            count = 0\n",
        "            for fuse_perm in zip(audio_perm, text_perm):\n",
        "                if count in resample_idxs:\n",
        "                    fuse_features.append(fuse_perm)\n",
        "                    fuse_targets = np.hstack((fuse_targets, 1))\n",
        "                    train_idxs.append(len(fuse_features)-1)\n",
        "                count += 1\n",
        "        else:\n",
        "            train_idxs.append(idx)\n",
        "\n",
        "    for idx in test_idxs_tmp:\n",
        "        if idx in fuse_dep_idxs:\n",
        "            feat = fuse_features[idx]\n",
        "            audio_perm = itertools.permutations(feat[0], 3)\n",
        "            text_perm = itertools.permutations(feat[1], 3)\n",
        "            count = 0\n",
        "            resample_idxs = [0,1,4,5]\n",
        "            for fuse_perm in zip(audio_perm, text_perm):\n",
        "                if count in resample_idxs:\n",
        "                    fuse_features.append(fuse_perm)\n",
        "                    fuse_targets = np.hstack((fuse_targets, 1))\n",
        "                    test_idxs.append(len(fuse_features)-1)\n",
        "                count += 1\n",
        "        else:\n",
        "            test_idxs.append(idx)\n",
        "\n",
        "    fuse_model = torch.load(f'{BASELINE_DIR}/Model/ClassificationWhole/Fuse/{fuse_model_paths[fold]}')\n",
        "    p, r, f = evaluate(fuse_model, test_idxs)\n",
        "    ps.append(p)\n",
        "    rs.append(r)\n",
        "    fs.append(f)\n",
        "print('precison: {} \\n recall: {} \\n f1 score: {}'.format(np.mean(ps), np.mean(rs), np.mean(fs)))"
      ],
      "metadata": {
        "id": "_tCMMnXLfZY7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}